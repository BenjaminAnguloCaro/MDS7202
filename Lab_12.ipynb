{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDZmp2BO9KnQ"
      },
      "source": [
        "# **Laboratorio 12: 游 Despliegue 游**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicol치s Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdGqUgwX9pGQ"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
        "\n",
        "- Nombre de alumno 1: Vanessa Gonz치lez\n",
        "- Nombre de alumno 2: Benjam칤n Angulo\n",
        "\n",
        "### **Link de repositorio de GitHub:** `https://github.com/BenjaminAnguloCaro/MDS7202/tree/Lab12`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YraSOKrf9yMl"
      },
      "source": [
        "## Temas a tratar\n",
        "\n",
        "- Entrenamiento y registro de modelos usando MLFlow.\n",
        "- Despliegue de modelo usando FastAPI\n",
        "- Containerizaci칩n del proyecto usando Docker\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Generar una soluci칩n a un problema a partir de ML\n",
        "- Desplegar su soluci칩n usando MLFlow, FastAPI y Docker\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D98okEzUE8hb"
      },
      "source": [
        "# **Introducci칩n**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSiuBfGiFlQM"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExODJnMHJzNzlkNmQweXoyY3ltbnZ2ZDlxY2c0aW5jcHNzeDNtOXBsdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AbPdhwsMgjMjax5reo/giphy.gif\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPn8R-6u877j"
      },
      "source": [
        "\n",
        "\n",
        "Consumida en la tristeza el despido de Renac칤n, Smapina ha deca칤do en su desempe침o, lo que se ha traducido en un irregular tratamiento del agua. Esto ha implicado una baja en la calidad del agua, llegando a haber algunos puntos de la comuna en la que el vital elemento no es apto para el consumo humano. Es por esto que la sanitaria p칰blica de la municipalidad de Maip칰 se ha contactado con ustedes para que le entreguen una urgente soluci칩n a este problema (a la vez que dejan a Smapina, al igual que Renac칤n, sin trabajo 游땞).\n",
        "\n",
        "El problema que la empresa le ha solicitado resolver es el de elaborar un sistema que les permita saber si el agua es potable o no. Para esto, la sanitaria les ha proveido una base de datos con la lectura de m칰ltiples sensores IOT colocados en diversas ca침er칤as, conductos y estanques. Estos sensores se침alan nueve tipos de mediciones qu칤micas y m치s una etiqueta elaborada en laboratorio que indica si el agua es potable o no el agua.\n",
        "\n",
        "La idea final es que puedan, en el caso que el agua no sea potable, dar un aviso inmediato para corregir el problema. Tenga en cuenta que parte del equipo docente vive en Maip칰 y su intoxicaci칩n podr칤a implicar graves problemas para el cierre del curso.\n",
        "\n",
        "Atributos:\n",
        "\n",
        "1. pH value\n",
        "2. Hardness\n",
        "3. Solids (Total dissolved solids - TDS)\n",
        "4. Chloramines\n",
        "5. Sulfate\n",
        "6. Conductivity\n",
        "7. Organic_carbon\n",
        "8. Trihalomethanes\n",
        "9. Turbidity\n",
        "\n",
        "Variable a predecir:\n",
        "\n",
        "10. Potability (1 si es potable, 0 no potable)\n",
        "\n",
        "Descripci칩n de cada atributo se pueden encontrar en el siguiente link: [dataset](https://www.kaggle.com/adityakadiwal/water-potability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aIr6KegWsjS"
      },
      "source": [
        "# **1. Optimizaci칩n de modelos con Optuna + MLFlow (2.0 puntos)**\n",
        "\n",
        "El objetivo de esta secci칩n es que ustedes puedan combinar Optuna con MLFlow para poder realizar la optimizaci칩n de los hiperpar치metros de sus modelos.\n",
        "\n",
        "Como a칰n no hemos hablado nada sobre `MLFlow` cabe preguntarse: **춰쯈u칠 !\"#@ es `MLflow`?!**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/eusgDKT4smQAAAAC/matthew-perry-chandler-bing.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "## **MLFlow**\n",
        "\n",
        "`MLflow` es una plataforma de c칩digo abierto que simplifica la gesti칩n y seguimiento de proyectos de aprendizaje autom치tico. Con sus herramientas, los desarrolladores pueden organizar, rastrear y comparar experimentos, adem치s de registrar modelos y controlar versiones.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://spark.apache.org/images/mlflow-logo.png\" width=\"350\">\n",
        "</p>\n",
        "\n",
        "Si bien esta plataforma cuenta con un gran n칰mero de herramientas y funcionalidades, en este laboratorio trabajaremos con dos:\n",
        "1. **Runs**: Registro que constituye la informaci칩n guardada tras la ejecuci칩n de un entrenamiento. Cada `run` tiene su propio run_id, el cual sirve como identificador para el entrenamiento en s칤 mismo. Dentro de cada `run` podremos acceder a informaci칩n como los hiperpar치metros utilizados, las m칠tricas obtenidas, las librer칤as requeridas y hasta nos permite descargar el modelo entrenado.\n",
        "2. **Experiments**: Se utilizan para agrupar y organizar diferentes ejecuciones de modelos (`runs`). En ese sentido, un experimento puede agrupar 1 o m치s `runs`. De esta manera, es posible tambi칠n registrar m칠tricas, par치metros y archivos (artefactos) asociados a cada experimento.\n",
        "\n",
        "### **Todo bien pero entonces, 쯖칩mo se usa en la pr치ctica `MLflow`?**\n",
        "\n",
        "Es sencillo! Considerando un problema de machine learning gen칠rico, podemos registrar la informaci칩n relevante del entrenamiento ejecutando `mlflow.autolog()` antes entrenar nuestro modelo. Veamos este bonito ejemplo facilitado por los mismos creadores de `MLflow`:\n",
        "\n",
        "```python\n",
        "#!pip install mlflow\n",
        "import mlflow # importar mlflow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "db = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
        "\n",
        "# Create and train models.\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
        "\n",
        "mlflow.autolog() # registrar autom치ticamente informaci칩n del entrenamiento\n",
        "with mlflow.start_run(): #맋elimita inicio y fin del run\n",
        "    #마qu칤 comienza el run\n",
        "    rf.fit(X_train, y_train) # train the model\n",
        "    predictions = rf.predict(X_test) # Use the model to make predictions on the test dataset.\n",
        "    # aqu칤 termina el run\n",
        "```\n",
        "\n",
        "Si ustedes ejecutan el c칩digo anterior en sus m치quinas locales (desde un jupyter notebook por ejemplo) se dar치n cuenta que en su directorio *root* se ha creado la carpeta `mlruns`. Esta carpeta lleva el tracking de todos los entrenamientos ejecutados desde el directorio root (importante: si se cambian de directorio y vuelven a ejecutar el c칩digo anterior, se crear치 otra carpeta y no tendr치n acceso al entrenamiento anterior). Para visualizar estos entrenamientos, `MLflow` nos facilita hermosa interfaz visual a la que podemos acceder ejecutando:\n",
        "\n",
        "```\n",
        "mlflow ui\n",
        "```\n",
        "\n",
        "y luego pinchando en la ruta http://127.0.0.1:5000 que nos retorna la terminal. Veamos en vivo algunas de sus funcionalidades!\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZXVuM3A5MW1heDFpa21qbGlwN2pyc2VoNnZsMmRzODZxdnluemo2bCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o84sq21TxDH6PyYms/giphy.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Les dejamos tambi칠n algunos comandos 칰tiles:\n",
        "\n",
        "- `mlflow.create_experiment(\"nombre_experimento\")`: Les permite crear un nuevo experimento para agrupar entrenamientos\n",
        "- `mlflow.log_metric(\"nombre_m칠trica\", m칠trica)`: Les permite registrar una m칠trica *custom* bajo el nombre de \"nombre_m칠trica\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptP_ygr7S04t"
      },
      "source": [
        "## **1.1 Combinando Optuna + MLflow**\n",
        "\n",
        "Ahora que tenemos conocimiento de ambas herramientas, intentemos ahora combinarlas para **m치s sabor**. El objetivo de este apartado es simple: automatizar la optimizaci칩n de los par치metros de nuestros modelos usando `Optuna` y registrando de forma autom치tica cada resultado en `MLFlow`.\n",
        "\n",
        "Considerando el objetivo planteado, se le pide completar la funci칩n `optimize_model`, la cual debe:\n",
        "- **Optimizar los hiperpar치metros del modelo `XGBoost` usando `Optuna`.**\n",
        "- **Registrar cada entrenamiento en un experimento nuevo**, asegur치ndose de que la m칠trica `mean absolute error` se registre como `\"valid_mae\"`. No se deben guardar todos los experimentos en *Default*; en su lugar, cada `experiment` y `run` deben tener nombres interpretables, reconocibles y diferentes a los nombres por defecto (por ejemplo, para un run: \"XGBoost con lr 0.1\").\n",
        "- **Guardar los gr치ficos de Optuna** dentro de una carpeta de artefactos de Mlflow llamada `/plots`.\n",
        "- **Devolver el mejor modelo** usando la funci칩n `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
        "- **Guardar el c칩digo en `optimize.py`**. La ejecuci칩n de `python optimize.py` deber칤a ejecutar la funci칩n `optimize_model`.\n",
        "- **Guardar las versiones de las librer칤as utilizadas** en el desarrollo.\n",
        "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gr치fico dentro de la carpeta `/plots` creada anteriormente.\n",
        "\n",
        "*Hint: Le puede ser 칰til revisar los par치metros que recibe `mlflow.start_run`*\n",
        "\n",
        "```python\n",
        "def get_best_model(experiment_id):\n",
        "    runs = mlflow.search_runs(experiment_id)\n",
        "    best_model_id = runs.sort_values(\"metrics.valid_mae\")[\"run_id\"].iloc[0]\n",
        "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
        "\n",
        "    return best_model\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.14.1)\n",
            "Requirement already satisfied: Flask<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.0.3)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.0.0)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: entrypoints<1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.1.43)\n",
            "Requirement already satisfied: graphene<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.7.5)\n",
            "Requirement already satisfied: numpy<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: packaging<25 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from mlflow) (24.0)\n",
            "Requirement already satisfied: pandas<3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2.1.4)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (4.25.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (15.0.2)\n",
            "Requirement already satisfied: pytz<2025 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2024.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: querystring-parser<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.4.2)\n",
            "Requirement already satisfied: scipy<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2.0.30)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: waitress<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.0.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->mlflow) (0.4.6)\n",
            "Requirement already satisfied: pywin32>=304 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.1)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Flask<4->mlflow) (1.8.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from graphene<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from graphene<4->mlflow) (9.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow) (0.46b0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: six in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn<2->mlflow) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaleido in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow\n",
        "!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import optuna\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "df = pd.read_csv('water_potability.csv')\n",
        "\n",
        "X = df.drop(\"Potability\", axis=1)\n",
        "y = df[\"Potability\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def optimize_model(trial):\n",
        "  params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'logloss',\n",
        "        'eta': trial.suggest_loguniform('eta', 0.01, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "        'use_label_encoder': False\n",
        "    }\n",
        "  model = XGBClassifier(**params)\n",
        "\n",
        "  with mlflow.start_run(run_name=f\"XGBoost con lr {params['eta']}\"):\n",
        "        mlflow.log_params(params)\n",
        "        \n",
        "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
        "        preds = model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, preds)\n",
        "        \n",
        "        mlflow.log_metric(\"valid_mae\", mae)\n",
        "        \n",
        "        return mae\n",
        "  \n",
        "def main():\n",
        "    mlflow.set_experiment(\"XGBoost Potability Experiment\")\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(optimize_model, timeout=300)\n",
        "\n",
        "    best_trial = study.best_trial\n",
        "\n",
        "    mlflow.log_params(best_trial.params)\n",
        "    mlflow.log_metric(\"best_valid_mae\", best_trial.value)\n",
        "\n",
        "    # Guardar el mejor modelo\n",
        "    best_params = best_trial.params\n",
        "    best_model = XGBClassifier(**best_params)\n",
        "    best_model.fit(X_train, y_train)\n",
        "    \n",
        "    with open('models/best_model.pkl', 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "    mlflow.log_artifact('models/best_model.pkl')\n",
        "\n",
        "    # Guardar gr치ficos de Optuna\n",
        "    fig_history = optuna.visualization.plot_optimization_history(study)\n",
        "    fig_history.write_image(\"plots/optimization_history.png\")\n",
        "    \n",
        "    fig_importance = optuna.visualization.plot_param_importances(study)\n",
        "    fig_importance.write_image(\"plots/param_importances.png\")\n",
        "    \n",
        "    mlflow.log_artifact('plots/optimization_history.png')\n",
        "    mlflow.log_artifact('plots/param_importances.png')\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL2iG18289j9"
      },
      "source": [
        "# **2. FastAPI (2.0 puntos)**\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://media3.giphy.com/media/YQitE4YNQNahy/giphy-downsized-large.gif\" width=\"500\">\n",
        "</div>\n",
        "\n",
        "Con el modelo ya entrenado, la idea de esta secci칩n es generar una API REST a la cual se le pueda hacer *requests* para as칤 interactuar con su modelo. En particular, se le pide:\n",
        "\n",
        "- Guardar el c칩digo de esta secci칩n en el archivo `main.py`. Note que ejecutar `python main.py` deber칤a levantar el servidor en el puerto por defecto.\n",
        "- Defina `GET` con ruta tipo *home* que describa brevemente su modelo, el problema que intenta resolver, su entrada y salida.\n",
        "- Defina un `POST` a la ruta `/potabilidad/` donde utilice su mejor optimizado para predecir si una medici칩n de agua es o no potable. Por ejemplo, una llamada de esta ruta con un *body*:\n",
        "\n",
        "```json\n",
        "{\n",
        "   \"ph\":10.316400384553162,\n",
        "   \"Hardness\":217.2668424334475,\n",
        "   \"Solids\":10676.508475429378,\n",
        "   \"Chloramines\":3.445514571005745,\n",
        "   \"Sulfate\":397.7549459751925,\n",
        "   \"Conductivity\":492.20647361771086,\n",
        "   \"Organic_carbon\":12.812732207582542,\n",
        "   \"Trihalomethanes\":72.28192021570328,\n",
        "   \"Turbidity\":3.4073494284238364\n",
        "}\n",
        "```\n",
        "\n",
        "Su servidor deber칤a retornar una respuesta HTML con c칩digo 200 con:\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"potabilidad\": 0 # respuesta puede variar seg칰n el clasificador que entrenen\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi[all]\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi[all])\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (2.7.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (4.11.0)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi[all])\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi[all])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi[all])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi[all])\n",
            "  Downloading ujson-5.10.0-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: orjson>=3.2.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (3.10.3)\n",
            "Collecting email_validator>=2.0.0 (from fastapi[all])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (2.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (6.0.1)\n",
            "Collecting pydantic-settings>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_settings-2.3.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pydantic-extra-types>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_extra_types-2.9.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi[all])\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from email_validator>=2.0.0->fastapi[all]) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi-cli>=0.0.2->fastapi[all]) (0.12.3)\n",
            "Collecting anyio (from httpx>=0.23.0->fastapi[all])\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: certifi in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->fastapi[all]) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi[all])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting sniffio (from httpx>=0.23.0->fastapi[all])\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi[all])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2>=2.11.2->fastapi[all]) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (2.18.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.0->fastapi[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0->fastapi[all]) (8.1.7)\n",
            "Requirement already satisfied: colorama>=0.4 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.12.0->fastapi[all]) (0.4.6)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading httptools-0.6.1-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading watchfiles-0.22.0-cp312-none-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading websockets-12.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (0.1.2)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 75.6/75.6 kB 4.1 MB/s eta 0:00:00\n",
            "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 77.9/77.9 kB 4.2 MB/s eta 0:00:00\n",
            "Downloading pydantic_extra_types-2.9.0-py3-none-any.whl (30 kB)\n",
            "Downloading pydantic_settings-2.3.4-py3-none-any.whl (22 kB)\n",
            "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
            "Downloading ujson-5.10.0-cp312-cp312-win_amd64.whl (42 kB)\n",
            "   ---------------------------------------- 0.0/42.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 42.2/42.2 kB ? eta 0:00:00\n",
            "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "   ---------------------------------------- 0.0/62.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 62.4/62.4 kB 3.3 MB/s eta 0:00:00\n",
            "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "   ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 92.0/92.0 kB 5.1 MB/s eta 0:00:00\n",
            "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
            "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 307.7/307.7 kB 9.6 MB/s eta 0:00:00\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
            "Downloading httptools-0.6.1-cp312-cp312-win_amd64.whl (55 kB)\n",
            "   ---------------------------------------- 0.0/55.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 55.7/55.7 kB 3.0 MB/s eta 0:00:00\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading watchfiles-0.22.0-cp312-none-win_amd64.whl (280 kB)\n",
            "   ---------------------------------------- 0.0/281.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 281.0/281.0 kB 16.9 MB/s eta 0:00:00\n",
            "Downloading websockets-12.0-cp312-cp312-win_amd64.whl (124 kB)\n",
            "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 125.0/125.0 kB 7.2 MB/s eta 0:00:00\n",
            "Installing collected packages: websockets, ujson, sniffio, python-multipart, python-dotenv, httptools, h11, dnspython, uvicorn, httpcore, email_validator, anyio, watchfiles, starlette, pydantic-settings, pydantic-extra-types, httpx, fastapi-cli, fastapi\n",
            "Successfully installed anyio-4.4.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 pydantic-extra-types-2.9.0 pydantic-settings-2.3.4 python-dotenv-1.0.1 python-multipart-0.0.9 sniffio-1.3.1 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 watchfiles-0.22.0 websockets-12.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install \"fastapi[all]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSausqDJ9CQh"
      },
      "source": [
        "# **3. Docker (2 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmC483flS00"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*9rafh2W0rbRJIKJzqYc8yA.gif\" width=\"500\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niMA_qsCjqlv"
      },
      "source": [
        "Tras el 칠xito de su aplicaci칩n web para generar la salida, Smapina le solicita que genere un contenedor para poder ejecutarla en cualquier computador de la empresa de agua potable.\n",
        "\n",
        "## **3.1 Creaci칩n de Container (1 punto)**\n",
        "\n",
        "Cree un Dockerfile que use una imagen base de Python, copie los archivos del proyecto e instale las dependencias desde un `requirements.txt`. Con esto, construya y ejecute el contenedor Docker para la API configurada anteriormente. Entregue el c칩digo fuente (incluyendo `main.py`, `requirements.txt`, y `Dockerfile`) y la imagen Docker de la aplicaci칩n. Para la dockerizaci칩n, aseg칰rese de cumplir con los siguientes puntos:\n",
        "\n",
        "1. **Generar un archivo `.dockerignore`** que ignore carpetas y archivos innecesarios dentro del contenedor.\n",
        "2. **Configurar un volumen** que permita la persistencia de los datos en una ruta local del computador.\n",
        "3. **Exponer el puerto** para acceder a la ruta de la API sin tener que entrar al contenedor directamente.\n",
        "4. **Incluir im치genes en el notebook** que muestren la ejecuci칩n del contenedor y los resultados obtenidos.\n",
        "5. **Revisar y comentar los recursos utilizados por el contenedor**. Analice si los contenedores son livianos en t칠rminos de recursos.\n",
        "\n",
        "* En esta parte tuvimos problemas, porque creamos los archivos necesarios, pero ninguno de los integrantes logr칩 instalar docker en un pc porque no nos da el almacenamiento.\n",
        "\n",
        "## **3.2 Preguntas de Smapina (1 punto)**\n",
        "Tras haber experimentado con Docker, Smapina desea profundizar m치s en el tema y decide realizarle las siguientes consultas:\n",
        "\n",
        "- 쮺칩mo se diferencia Docker de una m치quina virtual (VM)?\n",
        "- 쮺u치l es la diferencia entre usar Docker y ejecutar la aplicaci칩n directamente en el sistema local?\n",
        "- 쮺칩mo asegura Docker la consistencia entre diferentes entornos de desarrollo y producci칩n?\n",
        "- 쮺칩mo se gestionan los vol칰menes en Docker para la persistencia de datos?\n",
        "- 쯈u칠 son Dockerfile y docker-compose.yml, y cu치l es su prop칩sito?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# main.py\n",
        "\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.responses import HTMLResponse\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# inicializar app\n",
        "app = FastAPI()\n",
        "\n",
        "# ruta mejor modelo\n",
        "model_path = 'models/best_model.pkl'\n",
        "if not os.path.exists(model_path):\n",
        "    raise Exception(\"Modelo no encontrado. Por favor, ejecuta optimize.py primero para entrenar y guardar el modelo.\")\n",
        "\n",
        "# cargar el modelo entrenado\n",
        "with open(model_path, 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# esquema de entrada\n",
        "class WaterMeasurement(BaseModel):\n",
        "    ph: float\n",
        "    Hardness: float\n",
        "    Solids: float\n",
        "    Chloramines: float\n",
        "    Sulfate: float\n",
        "    Conductivity: float\n",
        "    Organic_carbon: float\n",
        "    Trihalomethanes: float\n",
        "    Turbidity: float\n",
        "\n",
        "# GET\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def home():\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <body>\n",
        "            <p>API para predecir la potabilidad del agua utilizando un modelo XGBoost.</p>\n",
        "            <p>El modelo predice la potabilidad del agua en base a varias mediciones qu칤micas.</p>\n",
        "            <p>Ejemplo de entrada del modelo:</p>\n",
        "            <pre>\n",
        "                {\n",
        "                   \"ph\": 10.316,\n",
        "                   \"Hardness\": 217.266,\n",
        "                   \"Solids\": 10676.508,\n",
        "                   \"Chloramines\": 3.445,\n",
        "                   \"Sulfate\": 397.754,\n",
        "                   \"Conductivity\": 492.206,\n",
        "                   \"Organic_carbon\": 12.812,\n",
        "                   \"Trihalomethanes\": 72.281,\n",
        "                   \"Turbidity\": 3.407\n",
        "                }\n",
        "            </pre>\n",
        "            <p>Ejemplo de salida del modelo:</p>\n",
        "            <pre>\n",
        "                {\n",
        "                   \"potabilidad\": 1\n",
        "                }\n",
        "            </pre>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "# POST\n",
        "@app.post(\"/potabilidad/\")\n",
        "async def predict(data: WaterMeasurement):\n",
        "    features = [\n",
        "        data.ph, data.Hardness, data.Solids, data.Chloramines,\n",
        "        data.Sulfate, data.Conductivity, data.Organic_carbon,\n",
        "        data.Trihalomethanes, data.Turbidity\n",
        "    ]\n",
        "\n",
        "    prediction = model.predict([features])[0]\n",
        "    return HTMLResponse(content=f\"\"\"\n",
        "    <html>\n",
        "        <body>\n",
        "            <p>Resultado de la Predicci칩n de Potabilidad del Agua</p>\n",
        "            <pre>\n",
        "            {{\n",
        "                \"potabilidad\": {int(prediction)}\n",
        "            }}\n",
        "            </pre>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\", status_code=200)\n",
        "\n",
        "\n",
        "# ejecuci칩n de la app\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dockerfile\n",
        "\n",
        "# Usa una imagen base de Python\n",
        "FROM python:3.9-slim\n",
        "\n",
        "# Directorio de trabajo dentro del contenedor\n",
        "WORKDIR /app\n",
        "\n",
        "# Copiar archivos necesarios\n",
        "COPY main.py .\n",
        "COPY requirements.txt .\n",
        "\n",
        "# Instalar dependencias\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Exponer el puerto donde corre la aplicaci칩n FastAPI\n",
        "EXPOSE 8000\n",
        "\n",
        "# Comando para ejecutar la aplicaci칩n FastAPI dentro del contenedor\n",
        "CMD [\"uvicorn\", \"main:app\", \"--port\", \"8000\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# requirements.txt\n",
        "\n",
        "fastapi\n",
        "uvicorn\n",
        "pydantic\n",
        "scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .dockerignore\n",
        "\n",
        "__pycache__\n",
        "*.pyc\n",
        "*.log\n",
        "\n",
        "models/\n",
        "miruns/\n",
        "plots/\n",
        "\n",
        "README.md\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Docker y las m치quinas virtuales (VMs) son tecnolog칤as de virtualizaci칩n, pero difieren en su enfoque y arquitectura. Una m치quina virtual simula un sistema operativo completo sobre el hardware f칤sico, incluyendo un kernel propio, y ejecuta aplicaciones dentro de esta instancia virtualizada. Esto hace que las VMs sean m치s pesadas en t칠rminos de recursos, ya que cada VM necesita su propio sistema operativo completo. Por otro lado, Docker utiliza el concepto de contenedores, que son entornos ligeros y port치tiles donde las aplicaciones se ejecutan de manera aislada pero comparten el mismo kernel del sistema operativo anfitri칩n. Esto hace que los contenedores sean m치s eficientes en t칠rminos de uso de recursos y m치s r치pidos de iniciar y detener que las VMs. \n",
        "\n",
        "* Cuando ejecutas una aplicaci칩n directamente en el sistema local, dependes de la configuraci칩n y dependencias espec칤ficas de ese sistema. Esto puede llevar a problemas de compatibilidad o versiones de software que funcionan en un entorno pero no en otro. Docker, por otro lado, encapsula la aplicaci칩n y sus dependencias en un contenedor, lo que asegura que la aplicaci칩n se ejecute de manera consistente y predecible en diferentes entornos, independientemente de las configuraciones locales.\n",
        "\n",
        "* Docker asegura la consistencia entre entornos mediante la creaci칩n de im치genes de contenedor. Una imagen Docker define todas las dependencias y configuraciones necesarias para ejecutar una aplicaci칩n. Esta imagen se puede construir y probar localmente en el entorno de desarrollo. Luego, la misma imagen se puede implementar en producci칩n, garantizando que la aplicaci칩n se ejecute de la misma manera en ambos entornos. Adem치s, Docker Compose permite definir y gestionar m칰ltiples contenedores como una aplicaci칩n completa, asegurando que todos los servicios necesarios est칠n disponibles y configurados consistentemente.\n",
        "\n",
        "* En Docker, los vol칰menes son utilizados para persistir datos generados y utilizados por contenedores. Los vol칰menes Docker son directorios montados desde el sistema host o son vol칰menes administrados por Docker. Esto permite que los datos persistan incluso cuando un contenedor se detiene o se elimina. Los vol칰menes se pueden especificar al iniciar un contenedor, asegurando que los datos importantes, como bases de datos o archivos de configuraci칩n, no se pierdan entre reinicios o actualizaciones del contenedor.\n",
        "\n",
        "* Un Dockerfile es un archivo de texto que contiene instrucciones detalladas sobre c칩mo construir una imagen Docker. Define qu칠 sistema operativo base utilizar, qu칠 paquetes instalar, qu칠 archivos copiar y qu칠 comandos ejecutar al iniciar un contenedor. El prop칩sito del Dockerfile es automatizar y estandarizar el proceso de construcci칩n de im치genes Docker, asegurando que cada imagen se construya de manera consistente y reproducible. Por otro lado, un docker-compose.yml es un archivo YAML que define servicios, redes y vol칰menes para una aplicaci칩n Docker multi-contenedor. Permite definir y gestionar m칰ltiples contenedores como una aplicaci칩n 칰nica, facilitando la configuraci칩n y la interacci칩n entre diferentes servicios. El prop칩sito de docker-compose.yml es simplificar el despliegue y la gesti칩n de aplicaciones complejas que requieren m칰ltiples contenedores interconectados, como aplicaciones web con backend, base de datos y servidores de cach칠."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xJ_ZK1IfnZW"
      },
      "source": [
        "# Conclusi칩n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/84/5d/f1/845df1aefc6a5e37ae575327a0cc6e43.gif\" width=\"500\">\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
