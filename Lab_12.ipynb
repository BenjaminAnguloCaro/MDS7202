{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDZmp2BO9KnQ"
      },
      "source": [
        "# **Laboratorio 12: üöÄ Despliegue üöÄ**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicol√°s Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdGqUgwX9pGQ"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Vanessa Gonz√°lez\n",
        "- Nombre de alumno 2: Benjam√≠n Angulo\n",
        "\n",
        "### **Link de repositorio de GitHub:** `https://github.com/BenjaminAnguloCaro/MDS7202/tree/Lab12`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YraSOKrf9yMl"
      },
      "source": [
        "## Temas a tratar\n",
        "\n",
        "- Entrenamiento y registro de modelos usando MLFlow.\n",
        "- Despliegue de modelo usando FastAPI\n",
        "- Containerizaci√≥n del proyecto usando Docker\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Generar una soluci√≥n a un problema a partir de ML\n",
        "- Desplegar su soluci√≥n usando MLFlow, FastAPI y Docker\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D98okEzUE8hb"
      },
      "source": [
        "# **Introducci√≥n**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSiuBfGiFlQM"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExODJnMHJzNzlkNmQweXoyY3ltbnZ2ZDlxY2c0aW5jcHNzeDNtOXBsdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AbPdhwsMgjMjax5reo/giphy.gif\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPn8R-6u877j"
      },
      "source": [
        "\n",
        "\n",
        "Consumida en la tristeza el despido de Renac√≠n, Smapina ha deca√≠do en su desempe√±o, lo que se ha traducido en un irregular tratamiento del agua. Esto ha implicado una baja en la calidad del agua, llegando a haber algunos puntos de la comuna en la que el vital elemento no es apto para el consumo humano. Es por esto que la sanitaria p√∫blica de la municipalidad de Maip√∫ se ha contactado con ustedes para que le entreguen una urgente soluci√≥n a este problema (a la vez que dejan a Smapina, al igual que Renac√≠n, sin trabajo üòî).\n",
        "\n",
        "El problema que la empresa le ha solicitado resolver es el de elaborar un sistema que les permita saber si el agua es potable o no. Para esto, la sanitaria les ha proveido una base de datos con la lectura de m√∫ltiples sensores IOT colocados en diversas ca√±er√≠as, conductos y estanques. Estos sensores se√±alan nueve tipos de mediciones qu√≠micas y m√°s una etiqueta elaborada en laboratorio que indica si el agua es potable o no el agua.\n",
        "\n",
        "La idea final es que puedan, en el caso que el agua no sea potable, dar un aviso inmediato para corregir el problema. Tenga en cuenta que parte del equipo docente vive en Maip√∫ y su intoxicaci√≥n podr√≠a implicar graves problemas para el cierre del curso.\n",
        "\n",
        "Atributos:\n",
        "\n",
        "1. pH value\n",
        "2. Hardness\n",
        "3. Solids (Total dissolved solids - TDS)\n",
        "4. Chloramines\n",
        "5. Sulfate\n",
        "6. Conductivity\n",
        "7. Organic_carbon\n",
        "8. Trihalomethanes\n",
        "9. Turbidity\n",
        "\n",
        "Variable a predecir:\n",
        "\n",
        "10. Potability (1 si es potable, 0 no potable)\n",
        "\n",
        "Descripci√≥n de cada atributo se pueden encontrar en el siguiente link: [dataset](https://www.kaggle.com/adityakadiwal/water-potability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aIr6KegWsjS"
      },
      "source": [
        "# **1. Optimizaci√≥n de modelos con Optuna + MLFlow (2.0 puntos)**\n",
        "\n",
        "El objetivo de esta secci√≥n es que ustedes puedan combinar Optuna con MLFlow para poder realizar la optimizaci√≥n de los hiperpar√°metros de sus modelos.\n",
        "\n",
        "Como a√∫n no hemos hablado nada sobre `MLFlow` cabe preguntarse: **¬°¬øQu√© !\"#@ es `MLflow`?!**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/eusgDKT4smQAAAAC/matthew-perry-chandler-bing.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "## **MLFlow**\n",
        "\n",
        "`MLflow` es una plataforma de c√≥digo abierto que simplifica la gesti√≥n y seguimiento de proyectos de aprendizaje autom√°tico. Con sus herramientas, los desarrolladores pueden organizar, rastrear y comparar experimentos, adem√°s de registrar modelos y controlar versiones.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://spark.apache.org/images/mlflow-logo.png\" width=\"350\">\n",
        "</p>\n",
        "\n",
        "Si bien esta plataforma cuenta con un gran n√∫mero de herramientas y funcionalidades, en este laboratorio trabajaremos con dos:\n",
        "1. **Runs**: Registro que constituye la informaci√≥n guardada tras la ejecuci√≥n de un entrenamiento. Cada `run` tiene su propio run_id, el cual sirve como identificador para el entrenamiento en s√≠ mismo. Dentro de cada `run` podremos acceder a informaci√≥n como los hiperpar√°metros utilizados, las m√©tricas obtenidas, las librer√≠as requeridas y hasta nos permite descargar el modelo entrenado.\n",
        "2. **Experiments**: Se utilizan para agrupar y organizar diferentes ejecuciones de modelos (`runs`). En ese sentido, un experimento puede agrupar 1 o m√°s `runs`. De esta manera, es posible tambi√©n registrar m√©tricas, par√°metros y archivos (artefactos) asociados a cada experimento.\n",
        "\n",
        "### **Todo bien pero entonces, ¬øc√≥mo se usa en la pr√°ctica `MLflow`?**\n",
        "\n",
        "Es sencillo! Considerando un problema de machine learning gen√©rico, podemos registrar la informaci√≥n relevante del entrenamiento ejecutando `mlflow.autolog()` antes entrenar nuestro modelo. Veamos este bonito ejemplo facilitado por los mismos creadores de `MLflow`:\n",
        "\n",
        "```python\n",
        "#!pip install mlflow\n",
        "import mlflow # importar mlflow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "db = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
        "\n",
        "# Create and train models.\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
        "\n",
        "mlflow.autolog() # registrar autom√°ticamente informaci√≥n del entrenamiento\n",
        "with mlflow.start_run(): #¬†delimita inicio y fin del run\n",
        "    #¬†aqu√≠ comienza el run\n",
        "    rf.fit(X_train, y_train) # train the model\n",
        "    predictions = rf.predict(X_test) # Use the model to make predictions on the test dataset.\n",
        "    # aqu√≠ termina el run\n",
        "```\n",
        "\n",
        "Si ustedes ejecutan el c√≥digo anterior en sus m√°quinas locales (desde un jupyter notebook por ejemplo) se dar√°n cuenta que en su directorio *root* se ha creado la carpeta `mlruns`. Esta carpeta lleva el tracking de todos los entrenamientos ejecutados desde el directorio root (importante: si se cambian de directorio y vuelven a ejecutar el c√≥digo anterior, se crear√° otra carpeta y no tendr√°n acceso al entrenamiento anterior). Para visualizar estos entrenamientos, `MLflow` nos facilita hermosa interfaz visual a la que podemos acceder ejecutando:\n",
        "\n",
        "```\n",
        "mlflow ui\n",
        "```\n",
        "\n",
        "y luego pinchando en la ruta http://127.0.0.1:5000 que nos retorna la terminal. Veamos en vivo algunas de sus funcionalidades!\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZXVuM3A5MW1heDFpa21qbGlwN2pyc2VoNnZsMmRzODZxdnluemo2bCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o84sq21TxDH6PyYms/giphy.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Les dejamos tambi√©n algunos comandos √∫tiles:\n",
        "\n",
        "- `mlflow.create_experiment(\"nombre_experimento\")`: Les permite crear un nuevo experimento para agrupar entrenamientos\n",
        "- `mlflow.log_metric(\"nombre_m√©trica\", m√©trica)`: Les permite registrar una m√©trica *custom* bajo el nombre de \"nombre_m√©trica\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptP_ygr7S04t"
      },
      "source": [
        "## **1.1 Combinando Optuna + MLflow**\n",
        "\n",
        "Ahora que tenemos conocimiento de ambas herramientas, intentemos ahora combinarlas para **m√°s sabor**. El objetivo de este apartado es simple: automatizar la optimizaci√≥n de los par√°metros de nuestros modelos usando `Optuna` y registrando de forma autom√°tica cada resultado en `MLFlow`.\n",
        "\n",
        "Considerando el objetivo planteado, se le pide completar la funci√≥n `optimize_model`, la cual debe:\n",
        "- **Optimizar los hiperpar√°metros del modelo `XGBoost` usando `Optuna`.**\n",
        "- **Registrar cada entrenamiento en un experimento nuevo**, asegur√°ndose de que la m√©trica `mean absolute error` se registre como `\"valid_mae\"`. No se deben guardar todos los experimentos en *Default*; en su lugar, cada `experiment` y `run` deben tener nombres interpretables, reconocibles y diferentes a los nombres por defecto (por ejemplo, para un run: \"XGBoost con lr 0.1\").\n",
        "- **Guardar los gr√°ficos de Optuna** dentro de una carpeta de artefactos de Mlflow llamada `/plots`.\n",
        "- **Devolver el mejor modelo** usando la funci√≥n `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
        "- **Guardar el c√≥digo en `optimize.py`**. La ejecuci√≥n de `python optimize.py` deber√≠a ejecutar la funci√≥n `optimize_model`.\n",
        "- **Guardar las versiones de las librer√≠as utilizadas** en el desarrollo.\n",
        "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gr√°fico dentro de la carpeta `/plots` creada anteriormente.\n",
        "\n",
        "*Hint: Le puede ser √∫til revisar los par√°metros que recibe `mlflow.start_run`*\n",
        "\n",
        "```python\n",
        "def get_best_model(experiment_id):\n",
        "    runs = mlflow.search_runs(experiment_id)\n",
        "    best_model_id = runs.sort_values(\"metrics.valid_mae\")[\"run_id\"].iloc[0]\n",
        "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
        "\n",
        "    return best_model\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.14.1)\n",
            "Requirement already satisfied: Flask<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.0.3)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.0.0)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: entrypoints<1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.1.43)\n",
            "Requirement already satisfied: graphene<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.7.5)\n",
            "Requirement already satisfied: numpy<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: packaging<25 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from mlflow) (24.0)\n",
            "Requirement already satisfied: pandas<3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2.1.4)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (4.25.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (15.0.2)\n",
            "Requirement already satisfied: pytz<2025 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2024.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: querystring-parser<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.4.2)\n",
            "Requirement already satisfied: scipy<2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (2.0.30)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: waitress<4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mlflow) (3.0.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->mlflow) (0.4.6)\n",
            "Requirement already satisfied: pywin32>=304 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.1)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Flask<4->mlflow) (1.8.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from graphene<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from graphene<4->mlflow) (9.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow) (0.46b0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: six in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn<2->mlflow) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaleido in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow\n",
        "!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import optuna\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "df = pd.read_csv('water_potability.csv')\n",
        "\n",
        "X = df.drop(\"Potability\", axis=1)\n",
        "y = df[\"Potability\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def optimize_model(trial):\n",
        "  params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'logloss',\n",
        "        'eta': trial.suggest_loguniform('eta', 0.01, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "        'use_label_encoder': False\n",
        "    }\n",
        "  model = XGBClassifier(**params)\n",
        "\n",
        "  with mlflow.start_run(run_name=f\"XGBoost con lr {params['eta']}\"):\n",
        "        mlflow.log_params(params)\n",
        "        \n",
        "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
        "        preds = model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, preds)\n",
        "        \n",
        "        mlflow.log_metric(\"valid_mae\", mae)\n",
        "        \n",
        "        return mae\n",
        "  \n",
        "def main():\n",
        "    mlflow.set_experiment(\"XGBoost Potability Experiment\")\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(optimize_model, timeout=300)\n",
        "\n",
        "    best_trial = study.best_trial\n",
        "\n",
        "    mlflow.log_params(best_trial.params)\n",
        "    mlflow.log_metric(\"best_valid_mae\", best_trial.value)\n",
        "\n",
        "    # Guardar el mejor modelo\n",
        "    best_params = best_trial.params\n",
        "    best_model = XGBClassifier(**best_params)\n",
        "    best_model.fit(X_train, y_train)\n",
        "    \n",
        "    with open('models/best_model.pkl', 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "    mlflow.log_artifact('models/best_model.pkl')\n",
        "\n",
        "    # Guardar gr√°ficos de Optuna\n",
        "    fig_history = optuna.visualization.plot_optimization_history(study)\n",
        "    fig_history.write_image(\"plots/optimization_history.png\")\n",
        "    \n",
        "    fig_importance = optuna.visualization.plot_param_importances(study)\n",
        "    fig_importance.write_image(\"plots/param_importances.png\")\n",
        "    \n",
        "    mlflow.log_artifact('plots/optimization_history.png')\n",
        "    mlflow.log_artifact('plots/param_importances.png')\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL2iG18289j9"
      },
      "source": [
        "# **2. FastAPI (2.0 puntos)**\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://media3.giphy.com/media/YQitE4YNQNahy/giphy-downsized-large.gif\" width=\"500\">\n",
        "</div>\n",
        "\n",
        "Con el modelo ya entrenado, la idea de esta secci√≥n es generar una API REST a la cual se le pueda hacer *requests* para as√≠ interactuar con su modelo. En particular, se le pide:\n",
        "\n",
        "- Guardar el c√≥digo de esta secci√≥n en el archivo `main.py`. Note que ejecutar `python main.py` deber√≠a levantar el servidor en el puerto por defecto.\n",
        "- Defina `GET` con ruta tipo *home* que describa brevemente su modelo, el problema que intenta resolver, su entrada y salida.\n",
        "- Defina un `POST` a la ruta `/potabilidad/` donde utilice su mejor optimizado para predecir si una medici√≥n de agua es o no potable. Por ejemplo, una llamada de esta ruta con un *body*:\n",
        "\n",
        "```json\n",
        "{\n",
        "   \"ph\":10.316400384553162,\n",
        "   \"Hardness\":217.2668424334475,\n",
        "   \"Solids\":10676.508475429378,\n",
        "   \"Chloramines\":3.445514571005745,\n",
        "   \"Sulfate\":397.7549459751925,\n",
        "   \"Conductivity\":492.20647361771086,\n",
        "   \"Organic_carbon\":12.812732207582542,\n",
        "   \"Trihalomethanes\":72.28192021570328,\n",
        "   \"Turbidity\":3.4073494284238364\n",
        "}\n",
        "```\n",
        "\n",
        "Su servidor deber√≠a retornar una respuesta HTML con c√≥digo 200 con:\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"potabilidad\": 0 # respuesta puede variar seg√∫n el clasificador que entrenen\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi[all]\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi[all])\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (2.7.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (4.11.0)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi[all])\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi[all])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi[all])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi[all])\n",
            "  Downloading ujson-5.10.0-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: orjson>=3.2.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (3.10.3)\n",
            "Collecting email_validator>=2.0.0 (from fastapi[all])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (2.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi[all]) (6.0.1)\n",
            "Collecting pydantic-settings>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_settings-2.3.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pydantic-extra-types>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_extra_types-2.9.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi[all])\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from email_validator>=2.0.0->fastapi[all]) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi-cli>=0.0.2->fastapi[all]) (0.12.3)\n",
            "Collecting anyio (from httpx>=0.23.0->fastapi[all])\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: certifi in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->fastapi[all]) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi[all])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting sniffio (from httpx>=0.23.0->fastapi[all])\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi[all])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2>=2.11.2->fastapi[all]) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (2.18.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.0->fastapi[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0->fastapi[all]) (8.1.7)\n",
            "Requirement already satisfied: colorama>=0.4 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.12.0->fastapi[all]) (0.4.6)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading httptools-0.6.1-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading watchfiles-0.22.0-cp312-none-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0->fastapi[all])\n",
            "  Downloading websockets-12.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vanessa\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vanessa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi[all]) (0.1.2)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 75.6/75.6 kB 4.1 MB/s eta 0:00:00\n",
            "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 77.9/77.9 kB 4.2 MB/s eta 0:00:00\n",
            "Downloading pydantic_extra_types-2.9.0-py3-none-any.whl (30 kB)\n",
            "Downloading pydantic_settings-2.3.4-py3-none-any.whl (22 kB)\n",
            "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
            "Downloading ujson-5.10.0-cp312-cp312-win_amd64.whl (42 kB)\n",
            "   ---------------------------------------- 0.0/42.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 42.2/42.2 kB ? eta 0:00:00\n",
            "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "   ---------------------------------------- 0.0/62.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 62.4/62.4 kB 3.3 MB/s eta 0:00:00\n",
            "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "   ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 92.0/92.0 kB 5.1 MB/s eta 0:00:00\n",
            "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
            "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 307.7/307.7 kB 9.6 MB/s eta 0:00:00\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
            "Downloading httptools-0.6.1-cp312-cp312-win_amd64.whl (55 kB)\n",
            "   ---------------------------------------- 0.0/55.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 55.7/55.7 kB 3.0 MB/s eta 0:00:00\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading watchfiles-0.22.0-cp312-none-win_amd64.whl (280 kB)\n",
            "   ---------------------------------------- 0.0/281.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 281.0/281.0 kB 16.9 MB/s eta 0:00:00\n",
            "Downloading websockets-12.0-cp312-cp312-win_amd64.whl (124 kB)\n",
            "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 125.0/125.0 kB 7.2 MB/s eta 0:00:00\n",
            "Installing collected packages: websockets, ujson, sniffio, python-multipart, python-dotenv, httptools, h11, dnspython, uvicorn, httpcore, email_validator, anyio, watchfiles, starlette, pydantic-settings, pydantic-extra-types, httpx, fastapi-cli, fastapi\n",
            "Successfully installed anyio-4.4.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 pydantic-extra-types-2.9.0 pydantic-settings-2.3.4 python-dotenv-1.0.1 python-multipart-0.0.9 sniffio-1.3.1 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 watchfiles-0.22.0 websockets-12.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install \"fastapi[all]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSausqDJ9CQh"
      },
      "source": [
        "# **3. Docker (2 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmC483flS00"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*9rafh2W0rbRJIKJzqYc8yA.gif\" width=\"500\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niMA_qsCjqlv"
      },
      "source": [
        "Tras el √©xito de su aplicaci√≥n web para generar la salida, Smapina le solicita que genere un contenedor para poder ejecutarla en cualquier computador de la empresa de agua potable.\n",
        "\n",
        "## **3.1 Creaci√≥n de Container (1 punto)**\n",
        "\n",
        "Cree un Dockerfile que use una imagen base de Python, copie los archivos del proyecto e instale las dependencias desde un `requirements.txt`. Con esto, construya y ejecute el contenedor Docker para la API configurada anteriormente. Entregue el c√≥digo fuente (incluyendo `main.py`, `requirements.txt`, y `Dockerfile`) y la imagen Docker de la aplicaci√≥n. Para la dockerizaci√≥n, aseg√∫rese de cumplir con los siguientes puntos:\n",
        "\n",
        "1. **Generar un archivo `.dockerignore`** que ignore carpetas y archivos innecesarios dentro del contenedor.\n",
        "2. **Configurar un volumen** que permita la persistencia de los datos en una ruta local del computador.\n",
        "3. **Exponer el puerto** para acceder a la ruta de la API sin tener que entrar al contenedor directamente.\n",
        "4. **Incluir im√°genes en el notebook** que muestren la ejecuci√≥n del contenedor y los resultados obtenidos.\n",
        "5. **Revisar y comentar los recursos utilizados por el contenedor**. Analice si los contenedores son livianos en t√©rminos de recursos.\n",
        "\n",
        "* En esta parte tuvimos problemas, porque creamos los archivos necesarios, pero ninguno de los integrantes logr√≥ instalar docker en un pc porque no nos da el almacenamiento.\n",
        "\n",
        "## **3.2 Preguntas de Smapina (1 punto)**\n",
        "Tras haber experimentado con Docker, Smapina desea profundizar m√°s en el tema y decide realizarle las siguientes consultas:\n",
        "\n",
        "- ¬øC√≥mo se diferencia Docker de una m√°quina virtual (VM)?\n",
        "- ¬øCu√°l es la diferencia entre usar Docker y ejecutar la aplicaci√≥n directamente en el sistema local?\n",
        "- ¬øC√≥mo asegura Docker la consistencia entre diferentes entornos de desarrollo y producci√≥n?\n",
        "- ¬øC√≥mo se gestionan los vol√∫menes en Docker para la persistencia de datos?\n",
        "- ¬øQu√© son Dockerfile y docker-compose.yml, y cu√°l es su prop√≥sito?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# main.py\n",
        "\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.responses import HTMLResponse\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# inicializar app\n",
        "app = FastAPI()\n",
        "\n",
        "# ruta mejor modelo\n",
        "model_path = 'models/best_model.pkl'\n",
        "if not os.path.exists(model_path):\n",
        "    raise Exception(\"Modelo no encontrado. Por favor, ejecuta optimize.py primero para entrenar y guardar el modelo.\")\n",
        "\n",
        "# cargar el modelo entrenado\n",
        "with open(model_path, 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# esquema de entrada\n",
        "class WaterMeasurement(BaseModel):\n",
        "    ph: float\n",
        "    Hardness: float\n",
        "    Solids: float\n",
        "    Chloramines: float\n",
        "    Sulfate: float\n",
        "    Conductivity: float\n",
        "    Organic_carbon: float\n",
        "    Trihalomethanes: float\n",
        "    Turbidity: float\n",
        "\n",
        "# GET\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def home():\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <body>\n",
        "            <p>API para predecir la potabilidad del agua utilizando un modelo XGBoost.</p>\n",
        "            <p>El modelo predice la potabilidad del agua en base a varias mediciones qu√≠micas.</p>\n",
        "            <p>Ejemplo de entrada del modelo:</p>\n",
        "            <pre>\n",
        "                {\n",
        "                   \"ph\": 10.316,\n",
        "                   \"Hardness\": 217.266,\n",
        "                   \"Solids\": 10676.508,\n",
        "                   \"Chloramines\": 3.445,\n",
        "                   \"Sulfate\": 397.754,\n",
        "                   \"Conductivity\": 492.206,\n",
        "                   \"Organic_carbon\": 12.812,\n",
        "                   \"Trihalomethanes\": 72.281,\n",
        "                   \"Turbidity\": 3.407\n",
        "                }\n",
        "            </pre>\n",
        "            <p>Ejemplo de salida del modelo:</p>\n",
        "            <pre>\n",
        "                {\n",
        "                   \"potabilidad\": 1\n",
        "                }\n",
        "            </pre>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "# POST\n",
        "@app.post(\"/potabilidad/\")\n",
        "async def predict(data: WaterMeasurement):\n",
        "    features = [\n",
        "        data.ph, data.Hardness, data.Solids, data.Chloramines,\n",
        "        data.Sulfate, data.Conductivity, data.Organic_carbon,\n",
        "        data.Trihalomethanes, data.Turbidity\n",
        "    ]\n",
        "\n",
        "    prediction = model.predict([features])[0]\n",
        "    return HTMLResponse(content=f\"\"\"\n",
        "    <html>\n",
        "        <body>\n",
        "            <p>Resultado de la Predicci√≥n de Potabilidad del Agua</p>\n",
        "            <pre>\n",
        "            {{\n",
        "                \"potabilidad\": {int(prediction)}\n",
        "            }}\n",
        "            </pre>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\", status_code=200)\n",
        "\n",
        "\n",
        "# ejecuci√≥n de la app\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dockerfile\n",
        "\n",
        "# Usa una imagen base de Python\n",
        "FROM python:3.9-slim\n",
        "\n",
        "# Directorio de trabajo dentro del contenedor\n",
        "WORKDIR /app\n",
        "\n",
        "# Copiar archivos necesarios\n",
        "COPY main.py .\n",
        "COPY requirements.txt .\n",
        "\n",
        "# Instalar dependencias\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Exponer el puerto donde corre la aplicaci√≥n FastAPI\n",
        "EXPOSE 8000\n",
        "\n",
        "# Comando para ejecutar la aplicaci√≥n FastAPI dentro del contenedor\n",
        "CMD [\"uvicorn\", \"main:app\", \"--port\", \"8000\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# requirements.txt\n",
        "\n",
        "fastapi\n",
        "uvicorn\n",
        "pydantic\n",
        "scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .dockerignore\n",
        "\n",
        "__pycache__\n",
        "*.pyc\n",
        "*.log\n",
        "\n",
        "models/\n",
        "miruns/\n",
        "plots/\n",
        "\n",
        "README.md\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Docker y las m√°quinas virtuales (VMs) son tecnolog√≠as de virtualizaci√≥n, pero difieren en su enfoque y arquitectura. Una m√°quina virtual simula un sistema operativo completo sobre el hardware f√≠sico, incluyendo un kernel propio, y ejecuta aplicaciones dentro de esta instancia virtualizada. Esto hace que las VMs sean m√°s pesadas en t√©rminos de recursos, ya que cada VM necesita su propio sistema operativo completo. Por otro lado, Docker utiliza el concepto de contenedores, que son entornos ligeros y port√°tiles donde las aplicaciones se ejecutan de manera aislada pero comparten el mismo kernel del sistema operativo anfitri√≥n. Esto hace que los contenedores sean m√°s eficientes en t√©rminos de uso de recursos y m√°s r√°pidos de iniciar y detener que las VMs. \n",
        "\n",
        "* Cuando ejecutas una aplicaci√≥n directamente en el sistema local, dependes de la configuraci√≥n y dependencias espec√≠ficas de ese sistema. Esto puede llevar a problemas de compatibilidad o versiones de software que funcionan en un entorno pero no en otro. Docker, por otro lado, encapsula la aplicaci√≥n y sus dependencias en un contenedor, lo que asegura que la aplicaci√≥n se ejecute de manera consistente y predecible en diferentes entornos, independientemente de las configuraciones locales.\n",
        "\n",
        "* Docker asegura la consistencia entre entornos mediante la creaci√≥n de im√°genes de contenedor. Una imagen Docker define todas las dependencias y configuraciones necesarias para ejecutar una aplicaci√≥n. Esta imagen se puede construir y probar localmente en el entorno de desarrollo. Luego, la misma imagen se puede implementar en producci√≥n, garantizando que la aplicaci√≥n se ejecute de la misma manera en ambos entornos. Adem√°s, Docker Compose permite definir y gestionar m√∫ltiples contenedores como una aplicaci√≥n completa, asegurando que todos los servicios necesarios est√©n disponibles y configurados consistentemente.\n",
        "\n",
        "* En Docker, los vol√∫menes son utilizados para persistir datos generados y utilizados por contenedores. Los vol√∫menes Docker son directorios montados desde el sistema host o son vol√∫menes administrados por Docker. Esto permite que los datos persistan incluso cuando un contenedor se detiene o se elimina. Los vol√∫menes se pueden especificar al iniciar un contenedor, asegurando que los datos importantes, como bases de datos o archivos de configuraci√≥n, no se pierdan entre reinicios o actualizaciones del contenedor.\n",
        "\n",
        "* Un Dockerfile es un archivo de texto que contiene instrucciones detalladas sobre c√≥mo construir una imagen Docker. Define qu√© sistema operativo base utilizar, qu√© paquetes instalar, qu√© archivos copiar y qu√© comandos ejecutar al iniciar un contenedor. El prop√≥sito del Dockerfile es automatizar y estandarizar el proceso de construcci√≥n de im√°genes Docker, asegurando que cada imagen se construya de manera consistente y reproducible. Por otro lado, un docker-compose.yml es un archivo YAML que define servicios, redes y vol√∫menes para una aplicaci√≥n Docker multi-contenedor. Permite definir y gestionar m√∫ltiples contenedores como una aplicaci√≥n √∫nica, facilitando la configuraci√≥n y la interacci√≥n entre diferentes servicios. El prop√≥sito de docker-compose.yml es simplificar el despliegue y la gesti√≥n de aplicaciones complejas que requieren m√∫ltiples contenedores interconectados, como aplicaciones web con backend, base de datos y servidores de cach√©."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xJ_ZK1IfnZW"
      },
      "source": [
        "# Conclusi√≥n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/84/5d/f1/845df1aefc6a5e37ae575327a0cc6e43.gif\" width=\"500\">\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
