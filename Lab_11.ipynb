{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Aut칩nomos 游뱄</center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown",
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicol치s Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown",
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1: Vanessa Gonz치lez \n",
        "- Nombre de alumno 2: Benjam칤n Angulo\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no ser치n revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown",
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/BenjaminAnguloCaro/MDS7202/tree/Lab11`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown",
        "id": "EcnsiQMkzAHr"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcci칩n del laboratorio](#Descripci칩n-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown",
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementaci칩n de modelos de LLM y Reinforcement Learning.\n",
        "- Utilizaci칩n e implementaci칩n de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 d칤as desde la publicaci칩n, 3 d칤as de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia ser치 debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est칠n en u-cursos no ser치n revisados. Recuerden que el repositorio tambi칠n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is4P4NDMurx6"
      },
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ3yV96HwN75"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB8z1qrGww4o"
      },
      "source": [
        "Joaqu칤n no es un aficionado del cine, pero a principios de a침o, se propuso ver m치s peliculas para poder tener m치s temas de conversaci칩n con sus amigos y familia. Sin embargo, ya es junio y Joaqu칤n no ha visto ninguna pelicula nueva o relevante de las que ten칤a en su lista y su reuni칩n familiar bi-anual se acerca y necesita la mayor informaci칩n que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compa침erx, tendr치 que crear una aplicaci칩n utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      },
      "source": [
        "**Instalaci칩n de librer칤as**\n",
        "\n",
        "Para la creaci칩n de la aplicaci칩n, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizar치 la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ah칤, ir a la pesta침a superior y seleccione la opci칩n que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el bot칩n que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podr치 consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor informaci칩n sobre **LangChain**, pueden revisar la documentaci칩n en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install beautifulsoup4 html5lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\benja\\OneDrive\\Escritorio\\MDS7202\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDtqofHPr88_QSyHbTl3aXWQdQF3FpPyZM\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUgbzVtWUYq2"
      },
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I10Li9a7nez"
      },
      "source": [
        "Para iniciar su titanica tarea de ense침arle a Joaqu칤n sobre las mejores peliculas del 칰ltimo tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "Debe encontrar un patr칩n y obtener solamente el gui칩n de las pel칤culas. Para ello se recomienda utilizar m칠todos de b칰squeda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patr칩n se repite y es generalizable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "outputs": [],
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XUfvpxPD8v5X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Funci칩n para cargar el script\n",
        "def load_website_data(url): \n",
        "  loader = WebBaseLoader(url)\n",
        "  website_data = loader.load()\n",
        "  return website_data\n",
        "\n",
        "def remove_text_before_marker(text, marker = \"| Transcript \\n\"):# Se define un marcador que se encuentra en el inicio de todos los scripts antes del gui칩n propiamente tal \n",
        "  splitter = RecursiveCharacterTextSplitter([marker]) # Se crea el splitter que dividir치 el texto en dos en el punto del marcador\n",
        "  output_text = splitter.split_documents(text) # Se divide el texto en dos partes\n",
        "  return [output_text[1]] # Recuperamos la parte de despu칠s del marcador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "dune2_data = load_website_data(dune2_script)\n",
        "underparis_data = load_website_data(underparis_script)\n",
        "joker_data = load_website_data(joker_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dune2_cleaned = remove_text_before_marker(dune2_data)\n",
        "underparis_cleaned = remove_text_before_marker(underparis_data)\n",
        "joker_cleaned = remove_text_before_marker(joker_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Btad-nZ9EyS"
      },
      "source": [
        "### **1.2 Aplicaci칩n (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicaic칩n deseada con el LLM. Esta aplicaci칩n tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la pel칤cula.\n",
        "\n",
        "2. Genere un resumen en espa침ol de la pel칤cula y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 p치rrafos. Adem치s, obtener una evaluaci칩n de la pel칤cula con una calificaci칩n del 1 al 10, utilizando una LLM y el contexto entregado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcS80oN2-Gq4"
      },
      "source": [
        "#### **1.2.1 T칤tulo de la pel칤cula (0.5 puntos)**\n",
        "\n",
        "Para obtener el t칤tulo, utilic칠 la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "outputs": [],
      "source": [
        "def get_movie_title(script_path_url):\n",
        "  # Se define el template\n",
        "  template = \"\"\"\n",
        "    What is the movie that appears in the description of this file or url?\n",
        "    You only give me the movie name, nothing more.\n",
        "    document/url: {script_path_url}\n",
        "    \"\"\"\n",
        "  # Se crea el prompt con el template dado y el url del script\n",
        "  prompt = template.format(script_path_url=script_path_url)\n",
        "  # Se realiza la predicci칩n del t칤tulo de la pel칤cula\n",
        "  result = llm.predict(prompt)\n",
        "  return result.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\benja\\OneDrive\\Escritorio\\MDS7202\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dune: Part Two\n",
            "Under Paris\n",
            "Joker\n"
          ]
        }
      ],
      "source": [
        "dune2_title = get_movie_title(dune2_script)\n",
        "underparis_title = get_movie_title(underparis_script)\n",
        "joker_title = get_movie_title(joker_script)\n",
        "\n",
        "print(dune2_title)\n",
        "print(underparis_title)\n",
        "print(joker_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muDXLfr0CabX"
      },
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)**\n",
        "\n",
        "Como se vi칩 en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tama침o del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jkxFMnCFDcgl"
      },
      "outputs": [],
      "source": [
        "#No cambiar funci칩n\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "  # Map\n",
        "  \"\"\"\n",
        "  map_prompt, crear el prompt desde el template\n",
        "  map_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  map_prompt = PromptTemplate(input_variables = [\"text\"], template = map_template)\n",
        "  map_chain = LLMChain(llm = llm, prompt = map_prompt)\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  reduce_prompt, crear el prompt desde el template\n",
        "  reduce_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  reduce_prompt = PromptTemplate(input_variables = [\"text\"], template = reduce_template)\n",
        "  reduce_chain = LLMChain(llm = llm, prompt = reduce_prompt)\n",
        "\n",
        "  # Combine\n",
        "  \"\"\"\n",
        "  Combinar y reducir los documentos, utilizar StuffDocumentsChain\n",
        "  y ReduceDocuentsChain con un m치ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "  stuff_chain = StuffDocumentsChain(llm_chain = reduce_chain)\n",
        "  reduce_documents_chain = ReduceDocumentsChain(\n",
        "        combine_documents_chain = stuff_chain,\n",
        "        token_max = 4000\n",
        "    )\n",
        "\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "  map_reduce_chain = MapReduceDocumentsChain(\n",
        "        llm_chain = map_chain,\n",
        "        reduce_documents_chain = reduce_documents_chain\n",
        "    )\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "  dune2_cleaned\n",
        "  split_script = text_splitter.split_documents(script)\n",
        "\n",
        "  # resultado\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "  return result[\"output_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "outputs": [],
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"\n",
        "Summarize the following text in 3-4 sentences, keeping the key points and the essence of the content.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_summary = \"\"\"\n",
        "Combine the following summaries into a single coherent summary that retains the key points and essence of the content.\n",
        "\n",
        "Summaries:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "answer_summary = \"\"\"\n",
        "Summarize the following text adding an introduction and a conclusion:\n",
        "\n",
        "{text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ijib42GaIFSI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\benja\\OneDrive\\Escritorio\\MDS7202\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Gemini produced an empty response. Continuing with empty message\n",
            "Feedback: block_reason: OTHER\n",
            "\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ],
      "source": [
        "resumen_dune2 = map_reduce_text(dune2_cleaned, map_template_summary, reduce_template_summary)\n",
        "resumen_underparis = map_reduce_text(underparis_cleaned, map_template_summary, reduce_template_summary)\n",
        "resumen_joker = map_reduce_text(joker_cleaned, map_template_summary, reduce_template_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumen Dune 2: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "The story of Dune unfolds on Arrakis, a desert planet rich in the spice melange, where the Harkonnen family has seized control after destroying House Atreides. Paul Atreides, heir to the throne of Arrakis, seeks vengeance for his family and finds refuge among the Fremen, a desert-dwelling people who see him as their prophesied leader, Muad'Dib.  \n",
            "\n",
            "Paul's journey is fraught with danger and internal conflict. He faces threats from the Harkonnens, who are determined to eliminate any remaining Atreides survivors, and navigates the harsh desert environment with the help of the Fremen.  He struggles with his newfound status, torn between revenge and the weight of prophecy, and his connection to the Bene Gesserit, a powerful organization known for manipulation, fuels the Fremen's belief in his destiny. \n",
            "\n",
            "Paul's journey involves physical and mental trials, including Fremen initiation rituals, learning to ride sandworms, and battling Harkonnen soldiers. His love for Chani, a Fremen woman, deepens his connection to the desert people and fuels his determination to fight for their freedom.\n",
            "\n",
            "Meanwhile, the Harkonnens, led by the cruel Rabban, struggle to maintain control over Arrakis. The Fremen's resistance, combined with the harsh desert environment, weakens their grip on the planet. The Emperor, observing the conflict, sees an opportunity to solidify his power by manipulating the situation.\n",
            "\n",
            "The Bene Gesserit, seeking to influence the outcome, see Feyd-Rautha Harkonnen, the Baron's nephew, as a potential alternative to Paul, despite his violent tendencies.  Their attempts to control him are met with challenges due to his ruthlessness.\n",
            "\n",
            "The story culminates in a clash between the Fremen and the Harkonnens, with Paul, now Muad'Dib, leading the Fremen's fight for freedom. The Emperor and Princess Irulan recognize the rising power of the Fremen and their enigmatic leader.  The fate of Arrakis hangs in the balance as the forces of destiny and ambition collide.\n",
            "\n",
            "Paul's journey is marked by internal conflict as he grapples with his prophetic visions, his immense power, and the responsibility that comes with his destiny. He is driven by revenge and ambition, but also aware of the potential for destruction his actions could unleash. His relationship with the Fremen is complex, marked by mutual respect but also tension due to their fundamentalist beliefs. The Harkonnens, led by the ruthless Baron and his cunning heir Feyd-Rautha, seek to maintain control over Arrakis and the spice trade, driven by greed and a desire for power.  The Bene Gesserit, with their long history of manipulation, are also involved, seeking to control the destiny of Arrakis and Paul's future. The story unfolds through tense encounters and battles, with Paul and the Fremen facing off against the Harkonnens and their allies, as the threat of a full-scale invasion looms.  Paul must navigate the complex power dynamics and alliances, ultimately facing a choice between embracing his destiny or succumbing to the forces of destruction. \n",
            "\n",
            " \n",
            "\n",
            "Resumen Under Paris: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "\"Under Paris\" plunges viewers into a terrifying scenario where a new, rapidly reproducing species of freshwater shark, Lilith, has invaded the Seine River, turning the iconic waterway into a deadly threat. The film's narrative unfolds through multiple interconnected storylines, highlighting the city's vulnerability and the characters' desperate struggle for survival.\n",
            "\n",
            "Scientist Sophia, grappling with personal grief, leads a team of experts in investigating Lilith's unusual behavior and rapid growth, while grappling with their own fears and past traumas.  Meanwhile, a group of police officers, led by Adil, a former soldier haunted by past trauma, investigate a series of mysterious events in the city, including the discovery of WWII shells and disappearances in the Seine.\n",
            "\n",
            "The film's suspense is heightened by the mayor's dismissive attitude towards the threat, prioritizing a major triathlon event over informing the public.  This negligence sets the stage for a terrifying spectacle during the triathlon, as Lilith's presence throws the event into chaos and panic.  \n",
            "\n",
            "The narrative interweaves action-packed sequences, including a dangerous rescue mission in the Paris catacombs and a desperate fight for survival amidst explosions and an unknown, menacing force.  The film ends with a climactic moment of destruction and loss, leaving viewers to contemplate the consequences of the mayor's negligence and the lasting impact of trauma on the characters. \n",
            "\n",
            "\"Under Paris\" serves as a cautionary tale, highlighting the interconnectedness of human actions and the environment.  The film underscores the dangers of environmental degradation, symbolized by the proliferation of Lilith, and the consequences of ignoring warnings about the potential for catastrophic events.  The tragic loss of two crew members during filming adds a poignant layer of reflection to the film's themes of survival, sacrifice, and the fragility of life.\n",
            "\n",
            "\n",
            "\n",
            "Resumen Joker: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "\"Joker\" (2019) is a dark and gritty crime thriller that delves into the descent into madness of Arthur Fleck, a mentally ill clown living in a decaying Gotham City. The film explores the impact of societal neglect and bullying on Arthur, ultimately leading him to embrace his alter ego, the Joker. \n",
            "\n",
            "The narrative unfolds against a backdrop of urban decay and social unrest, marked by a severe sanitation crisis, rising heating oil prices, and a surge in violent crime. Arthur, struggling with mental health challenges and seeking a career in stand-up comedy, is caught in a cycle of despair, struggling to access medication and navigate a system that seems indifferent to his needs. \n",
            "\n",
            "The film highlights the stark contrast between Arthur's comedic aspirations and the harsh realities of his life. He experiences ridicule and rejection, facing hostility from colleagues and violent encounters. His attempts to connect with his mother and seek help from a social worker are met with frustration and lack of support. \n",
            "\n",
            "A series of events push Arthur to the edge. A violent confrontation with Thomas Wayne, a wealthy businessman, fuels Arthur's resentment and fuels his descent into madness. The film culminates in a chaotic and tragic climax, where Arthur, embracing his Joker persona, becomes a symbol of societal breakdown and the consequences of ignoring mental health and social inequality. \n",
            "\n",
            "The film explores themes of dark humor, absurdity, and resilience. Arthur's actions, fueled by his warped sense of humor, highlight the tension between dark humor and the boundaries of acceptable comedy. His detachment from reality is further emphasized in scenes where he sets a city on fire and finds amusement in the ensuing chaos. \n",
            "\n",
            "However, the narrative also presents a contrasting perspective on resilience. A song within the story celebrates the power of perseverance and optimism in the face of life's challenges, encouraging listeners to find strength in beauty and refuse to let negativity define their experience. \n",
            "\n",
            "The film's themes are further explored in other works, such as \"The Box\" (2009), which uses a mysterious box as a metaphor for grappling with loss and searching for meaning. \"Scraps from the Loft,\" a weekly magazine offering curated content, provides a platform for exploring various themes, including those presented in the film transcripts, through a diverse selection of articles. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "resumen_dune2 = answer_summary.format(text = resumen_dune2)\n",
        "resumen_underparis = answer_summary.format(text = resumen_underparis)\n",
        "resumen_joker = answer_summary.format(text = resumen_joker)\n",
        "\n",
        "# imprimir resumenes de pel칤culas.\n",
        "print(f\"Resumen Dune 2: \\n {resumen_dune2} \\n\")\n",
        "\n",
        "print(f\"Resumen Under Paris: \\n {resumen_underparis}\\n\")\n",
        "\n",
        "print(f\"Resumen Joker: \\n {resumen_joker}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      },
      "source": [
        "Adicionalmente, Joaqu칤n sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustar칤a tener mayor informaci칩n al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gr치fico que muestre los personajes de la pel칤cula con m치s apariciones en la misma.\n",
        "4. Genere una tabla en pandas con los 3 personajes que m치s aparecen, indicando el nombre del actor y su edad actual m치s uno (ojo edad + 1).\n",
        "5. Cree una funci칩n que responda preguntas sobre la pel칤cula bas치ndose en la informaci칩n del texto entregado (OJO: las preguntas y salidas deben ser en espa침ol). Luego, responda las siguientes preguntas:\n",
        "* 쯈u칠 y qui칠n es Lisan al-Gaib?\n",
        "* 쯈u칠 personaje no cree en la profec칤a pero es parte de ella?\n",
        "* 쮺u치l es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que m치s aparecen en la pel칤cula, genere con el modelo LLM y utilizando el contexto del guion, las 6 estad칤sticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_vdMMceJZBu"
      },
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente secci칩n, tiene que entregar un template de personajes y redicci칩n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fIM5JVC5JWNt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ],
      "source": [
        "map_template_characters = \"\"\"\n",
        "Extract the list of characters from the following text. Include only the names of the characters and nothing else:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"\n",
        "Combine the following lists of characters into a single list without duplicates but including the times they appear on the script:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    dune2_cleaned,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the combined list of characters, removing duplicates and including their appearance count:\n",
            "\n",
            "* **Paul Atreides:** 26\n",
            "* **Chani:** 24\n",
            "* **Jessica:** 21\n",
            "* **Stilgar:** 20\n",
            "* **Gurney:** 12\n",
            "* **Harkonnen soldier:** 6\n",
            "* **Rabban:** 6\n",
            "* **Feyd-Rautha:** 6\n",
            "* **Usul:** 5\n",
            "* **Shishakli:** 5\n",
            "* **Reverend Mother Mohiam:** 5\n",
            "* **Muad'Dib:** 5\n",
            "* **Irulan:** 4\n",
            "* **Harkonnen commander:** 2\n",
            "* **Jamis:** 2\n",
            "* **Lisan al-Gaib:** 2\n",
            "* **Fremen:** 2\n",
            "* **Baron Harkonnen:** 2\n",
            "* **Emperor:** 2\n",
            "* **Bene Gesserit:** 2\n",
            "* **Oldest elder:** 1\n",
            "* **Harkonnen lieutenant:** 1\n",
            "* **Harkonnen sniper:** 1\n",
            "* **Fremen sentinel:** 1\n",
            "* **Sentinel leader:** 1\n",
            "* **Mahdi:** 1\n",
            "* **Janis:** 1\n",
            "* **Old watermaster:** 1\n",
            "* **Fedaykin fighter:** 1\n",
            "* **Fedaykin:** 1\n",
            "* **Sihaya:** 1\n",
            "* **Shai-Hulud:** 1\n",
            "* **She:** 1\n",
            "* **You:** 1\n",
            "* **Our mother:** 1\n",
            "* **They:** 1\n",
            "* **Your people:** 1\n",
            "* **Princess Irulan:** 1\n",
            "* **na-Baron:** 1\n",
            "* **Lady Margot Fenring:** 1\n",
            "* **Man 1:** 1\n",
            "* **Man 2:** 1\n",
            "* **Maker Keeper:** 1\n",
            "* **Alia:** 1\n",
            "* **Denis Villeneuve:** 1\n",
            "* **Ezra:** 1\n",
            "* **Max:** 1\n",
            "* **Jenna:** 1\n",
            "* **All of Us Strangers:** 1\n",
            "* **Mahito:** 1\n",
            "* **Duke Leto Atreides:** 1\n",
            "* **Harkonnen:** 1\n",
            "* **Atreides:** 1\n",
            "* **Female Fremen:** 1\n",
            "* **My Lord:** 1\n",
            "* **Leto Atreides:** 1\n",
            "* **Bashar:** 1\n",
            "\n",
            "This list includes every character mentioned in the provided text, with their respective appearance counts. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(answer_character_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  answer_character_list = answer_character_list.split('\\n')\n",
        "  pattern = r'\\*\\*([^*]+)\\*\\*' # Expresi칩n regular para obtener los nombres de los personajes que se encuentran entre ** ** de la forma en que es entregado por el modelo\n",
        "  num_pattern = r'\\*\\*[^*]+\\*\\*|\\b(\\d+)\\b' # Expresi칩n regular para extraer el n칰mero de apariciones de los personajes\n",
        "  characters = {}\n",
        "\n",
        "  for item in answer_character_list:\n",
        "        matches = re.findall(pattern, item) # Se realizan los matches para los personajes\n",
        "        matches_num = re.findall(num_pattern, item) # Se realizan los matches para los n칰meros\n",
        "        matches_num = [num for num in matches_num if num.isdigit()] # Se limpia el match de los n칰meros para obtener solo el valor que se necesita de las apariciones\n",
        "        \n",
        "        if matches and matches_num: # Se confirma que existan los valores\n",
        "            clean_match = re.sub(r':', '', matches[0]) # Se eliminan los : de los nombres de los personajes\n",
        "            characters[clean_match.strip()] = int(matches_num[0]) #Se crea el diccionario con los nombres y n칰mero de apariciones\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame(list(characters.items()), columns=['Character', 'Appearances'])\n",
        "\n",
        "  # Graficar datos\n",
        "  fig = px.bar(df, x='Character', y='Appearances', title='Character Appearances', \n",
        "                 labels={'Character': 'Character', 'Appearances': 'Number of Appearances'})\n",
        "  fig.show()\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return characters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "alignmentgroup": "True",
                  "hovertemplate": "Character=%{x}<br>Number of Appearances=%{y}<extra></extra>",
                  "legendgroup": "",
                  "marker": {
                    "color": "#636efa",
                    "pattern": {
                      "shape": ""
                    }
                  },
                  "name": "",
                  "offsetgroup": "",
                  "orientation": "v",
                  "showlegend": false,
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    "Paul Atreides",
                    "Chani",
                    "Jessica",
                    "Stilgar",
                    "Gurney",
                    "Harkonnen soldier",
                    "Rabban",
                    "Feyd-Rautha",
                    "Usul",
                    "Shishakli",
                    "Reverend Mother Mohiam",
                    "Muad'Dib",
                    "Irulan",
                    "Harkonnen commander",
                    "Jamis",
                    "Lisan al-Gaib",
                    "Fremen",
                    "Baron Harkonnen",
                    "Emperor",
                    "Bene Gesserit",
                    "Oldest elder",
                    "Harkonnen lieutenant",
                    "Harkonnen sniper",
                    "Fremen sentinel",
                    "Sentinel leader",
                    "Mahdi",
                    "Janis",
                    "Old watermaster",
                    "Fedaykin fighter",
                    "Fedaykin",
                    "Sihaya",
                    "Shai-Hulud",
                    "She",
                    "You",
                    "Our mother",
                    "They",
                    "Your people",
                    "Princess Irulan",
                    "na-Baron",
                    "Lady Margot Fenring",
                    "Man 1",
                    "Man 2",
                    "Maker Keeper",
                    "Alia",
                    "Denis Villeneuve",
                    "Ezra",
                    "Max",
                    "Jenna",
                    "All of Us Strangers",
                    "Mahito",
                    "Duke Leto Atreides",
                    "Harkonnen",
                    "Atreides",
                    "Female Fremen",
                    "My Lord",
                    "Leto Atreides",
                    "Bashar"
                  ],
                  "xaxis": "x",
                  "y": [
                    26,
                    24,
                    21,
                    20,
                    12,
                    6,
                    6,
                    6,
                    5,
                    5,
                    5,
                    5,
                    4,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "barmode": "relative",
                "legend": {
                  "tracegroupgap": 0
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Character Appearances"
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Character"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Number of Appearances"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Paul Atreides': 26,\n",
              " 'Chani': 24,\n",
              " 'Jessica': 21,\n",
              " 'Stilgar': 20,\n",
              " 'Gurney': 12,\n",
              " 'Harkonnen soldier': 6,\n",
              " 'Rabban': 6,\n",
              " 'Feyd-Rautha': 6,\n",
              " 'Usul': 5,\n",
              " 'Shishakli': 5,\n",
              " 'Reverend Mother Mohiam': 5,\n",
              " \"Muad'Dib\": 5,\n",
              " 'Irulan': 4,\n",
              " 'Harkonnen commander': 2,\n",
              " 'Jamis': 2,\n",
              " 'Lisan al-Gaib': 2,\n",
              " 'Fremen': 2,\n",
              " 'Baron Harkonnen': 2,\n",
              " 'Emperor': 2,\n",
              " 'Bene Gesserit': 2,\n",
              " 'Oldest elder': 1,\n",
              " 'Harkonnen lieutenant': 1,\n",
              " 'Harkonnen sniper': 1,\n",
              " 'Fremen sentinel': 1,\n",
              " 'Sentinel leader': 1,\n",
              " 'Mahdi': 1,\n",
              " 'Janis': 1,\n",
              " 'Old watermaster': 1,\n",
              " 'Fedaykin fighter': 1,\n",
              " 'Fedaykin': 1,\n",
              " 'Sihaya': 1,\n",
              " 'Shai-Hulud': 1,\n",
              " 'She': 1,\n",
              " 'You': 1,\n",
              " 'Our mother': 1,\n",
              " 'They': 1,\n",
              " 'Your people': 1,\n",
              " 'Princess Irulan': 1,\n",
              " 'na-Baron': 1,\n",
              " 'Lady Margot Fenring': 1,\n",
              " 'Man 1': 1,\n",
              " 'Man 2': 1,\n",
              " 'Maker Keeper': 1,\n",
              " 'Alia': 1,\n",
              " 'Denis Villeneuve': 1,\n",
              " 'Ezra': 1,\n",
              " 'Max': 1,\n",
              " 'Jenna': 1,\n",
              " 'All of Us Strangers': 1,\n",
              " 'Mahito': 1,\n",
              " 'Duke Leto Atreides': 1,\n",
              " 'Harkonnen': 1,\n",
              " 'Atreides': 1,\n",
              " 'Female Fremen': 1,\n",
              " 'My Lord': 1,\n",
              " 'Leto Atreides': 1,\n",
              " 'Bashar': 1}"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_characters(answer_character_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G2dx0XoLis4"
      },
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja informaci칩n de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar b칰squedas que nos ayuden a completar la informaci칩n consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "outputs": [],
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "outputs": [],
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = # ...\n",
        "  agent = # ...\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Crear prompt y usar agente para la b칰squeda.\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpf9H61qMxal"
      },
      "source": [
        "**Explicar metodolog칤a utilizada**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQqA40sM09E"
      },
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estad칤sticas basandonos en una b칰squeda por map/reduce.\n",
        "\n",
        "Tras la b칰squeda, la idea es tener una funci칩n de Python que nos permita generar el gr치fico deseado y tener el resumen de los personajes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducci칩n.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un m치ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "outputs": [],
      "source": [
        "# Escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "outputs": [],
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "outputs": [],
      "source": [
        "print(final_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "outputs": [],
      "source": [
        "# Funci칩n para gr치ficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_APhHBPXQXTX"
      },
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodolog칤a y secuencia l칩gica de cada una de las respuestas. Adem치s responda:\n",
        "\n",
        "* 쯈u칠 otras tareas se podr칤a realizar? De dos ejemplos con la metodolog칤a asociada.\n",
        "\n",
        "* 쮺ual es la importancia de los prompt y como estos afectan al desempe침o de los LLM?\n",
        "\n",
        "* 쮸lguna de sus respuestas fue una 'alucinaci칩n'? 쯇or qu칠 sucede esto?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci칩n van a usar m칠todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "8445bc8e-2de6-4342-f789-1c3ce6d18cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaqu칤n es fan치tico del Blackjack, por lo que en esta subsecci칩n implementar치n m칠todos de RL y as칤 generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c칩digo transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **2.1.1 Descripci칩n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci칩n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "`Escriba su respuesta ac치`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulaci칩n 5000 veces y reporte el promedio y desviaci칩n de las recompensas.\n",
        "* 쮺칩mo calificar칤a el performance de esta pol칤tica?\n",
        "* 쮺칩mo podr칤a interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHCfKN7NGi1K"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0sp8XWsGg4P"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **2.1.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* 쮺칩mo es el performance de su agente?\n",
        "* 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7jdmnTwGePD"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una funci칩n que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta funci칩n para entregar la acci칩n escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* 쯉on coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: 쮸 que clase de python pertenecen los estados? Pruebe a usar el m칠todo `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lssdp7AvGaRh"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci칩n 2.1, en esta secci칩n usted se encargar치 de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **2.2.1 Descripci칩n de MDP (0.2 puntos)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvAVq1wQIjLc"
      },
      "source": [
        "Comencemos preparando el ambiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par치metro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNERH-m8JYQb"
      },
      "source": [
        "* Entregue una breve descripci칩n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* 쮺omo se distinguen las acciones de este ambiente en comparaci칩n a `Blackjack`?\n",
        "* En la preparaci칩n del ambiente se especifica el par치metro `continuous = True`. 쯈ue implicancias tiene esto sobre el ambiente?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpGahPcHAje"
      },
      "source": [
        "`Escriba su respuesta ac치`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 10 veces y reporte el promedio y desviaci칩n de las recompensas.\n",
        "* 쮺칩mo calificar칤a el performance de esta pol칤tica?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNMT_GORIreW"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg0epSnLKfy6"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **2.2.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWVY1a39KeRs"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **2.2.5 Optimizaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par치metros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la funci칩n `export_gif` entregada para estudiar el comportamiento de su agente en la resoluci칩n del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, adem치s, adjuntan el gif en el markdown tendr치n un bonus de 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag-QIrmhLIY_"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci칩n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac치"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
