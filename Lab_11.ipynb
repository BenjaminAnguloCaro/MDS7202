{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Aut√≥nomos ü§ñ</center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown",
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicol√°s Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown",
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1: Vanessa Gonz√°lez \n",
        "- Nombre de alumno 2: Benjam√≠n Angulo\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no ser√°n revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown",
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/BenjaminAnguloCaro/MDS7202/tree/Lab11`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown",
        "id": "EcnsiQMkzAHr"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcci√≥n del laboratorio](#Descripci√≥n-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown",
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementaci√≥n de modelos de LLM y Reinforcement Learning.\n",
        "- Utilizaci√≥n e implementaci√≥n de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 d√≠as desde la publicaci√≥n, 3 d√≠as de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is4P4NDMurx6"
      },
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ3yV96HwN75"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB8z1qrGww4o"
      },
      "source": [
        "Joaqu√≠n no es un aficionado del cine, pero a principios de a√±o, se propuso ver m√°s peliculas para poder tener m√°s temas de conversaci√≥n con sus amigos y familia. Sin embargo, ya es junio y Joaqu√≠n no ha visto ninguna pelicula nueva o relevante de las que ten√≠a en su lista y su reuni√≥n familiar bi-anual se acerca y necesita la mayor informaci√≥n que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compa√±erx, tendr√° que crear una aplicaci√≥n utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      },
      "source": [
        "**Instalaci√≥n de librer√≠as**\n",
        "\n",
        "Para la creaci√≥n de la aplicaci√≥n, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizar√° la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ah√≠, ir a la pesta√±a superior y seleccione la opci√≥n que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el bot√≥n que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podr√° consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor informaci√≥n sobre **LangChain**, pueden revisar la documentaci√≥n en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install beautifulsoup4 html5lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDtqofHPr88_QSyHbTl3aXWQdQF3FpPyZM\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUgbzVtWUYq2"
      },
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I10Li9a7nez"
      },
      "source": [
        "Para iniciar su titanica tarea de ense√±arle a Joaqu√≠n sobre las mejores peliculas del √∫ltimo tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "Debe encontrar un patr√≥n y obtener solamente el gui√≥n de las pel√≠culas. Para ello se recomienda utilizar m√©todos de b√∫squeda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patr√≥n se repite y es generalizable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "outputs": [],
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XUfvpxPD8v5X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Funci√≥n para cargar el script\n",
        "def load_website_data(url): \n",
        "  loader = WebBaseLoader(url)\n",
        "  website_data = loader.load()\n",
        "  return website_data\n",
        "\n",
        "def remove_text_before_marker(text, marker = \"| Transcript \\n\"):# Se define un marcador que se encuentra en el inicio de todos los scripts antes del gui√≥n propiamente tal \n",
        "  splitter = RecursiveCharacterTextSplitter([marker]) # Se crea el splitter que dividir√° el texto en dos en el punto del marcador\n",
        "  output_text = splitter.split_documents(text) # Se divide el texto en dos partes\n",
        "  return [output_text[1]] # Recuperamos la parte de despu√©s del marcador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dune2_data = load_website_data(dune2_script)\n",
        "underparis_data = load_website_data(underparis_script)\n",
        "joker_data = load_website_data(joker_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dune2_cleaned = remove_text_before_marker(dune2_data)\n",
        "underparis_cleaned = remove_text_before_marker(underparis_data)\n",
        "joker_cleaned = remove_text_before_marker(joker_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Btad-nZ9EyS"
      },
      "source": [
        "### **1.2 Aplicaci√≥n (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicaic√≥n deseada con el LLM. Esta aplicaci√≥n tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la pel√≠cula.\n",
        "\n",
        "2. Genere un resumen en espa√±ol de la pel√≠cula y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 p√°rrafos. Adem√°s, obtener una evaluaci√≥n de la pel√≠cula con una calificaci√≥n del 1 al 10, utilizando una LLM y el contexto entregado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcS80oN2-Gq4"
      },
      "source": [
        "#### **1.2.1 T√≠tulo de la pel√≠cula (0.5 puntos)**\n",
        "\n",
        "Para obtener el t√≠tulo, utilic√© la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "outputs": [],
      "source": [
        "def get_movie_title(script_path_url):\n",
        "  # Se define el template\n",
        "  template = \"\"\"\n",
        "    What is the movie that appears in the description of this file or url?\n",
        "    You only give me the movie name, nothing more.\n",
        "    document/url: {script_path_url}\n",
        "    \"\"\"\n",
        "  # Se crea el prompt con el template dado y el url del script\n",
        "  prompt = template.format(script_path_url=script_path_url)\n",
        "  # Se realiza la predicci√≥n del t√≠tulo de la pel√≠cula\n",
        "  result = llm.predict(prompt)\n",
        "  return result.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vanessa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dune: Part Two\n",
            "Under Paris\n",
            "Joker\n"
          ]
        }
      ],
      "source": [
        "dune2_title = get_movie_title(dune2_script)\n",
        "underparis_title = get_movie_title(underparis_script)\n",
        "joker_title = get_movie_title(joker_script)\n",
        "\n",
        "print(dune2_title)\n",
        "print(underparis_title)\n",
        "print(joker_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muDXLfr0CabX"
      },
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)**\n",
        "\n",
        "Como se vi√≥ en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tama√±o del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jkxFMnCFDcgl"
      },
      "outputs": [],
      "source": [
        "#No cambiar funci√≥n\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "  # Map\n",
        "  \"\"\"\n",
        "  map_prompt, crear el prompt desde el template\n",
        "  map_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  map_prompt = PromptTemplate(input_variables = [\"text\"], template = map_template)\n",
        "  map_chain = LLMChain(llm = llm, prompt = map_prompt)\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  reduce_prompt, crear el prompt desde el template\n",
        "  reduce_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  reduce_prompt = PromptTemplate(input_variables = [\"text\"], template = reduce_template)\n",
        "  reduce_chain = LLMChain(llm = llm, prompt = reduce_prompt)\n",
        "\n",
        "  # Combine\n",
        "  \"\"\"\n",
        "  Combinar y reducir los documentos, utilizar StuffDocumentsChain\n",
        "  y ReduceDocuentsChain con un m√°ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "  stuff_chain = StuffDocumentsChain(llm_chain = reduce_chain)\n",
        "  reduce_documents_chain = ReduceDocumentsChain(\n",
        "        combine_documents_chain = stuff_chain,\n",
        "        token_max = 4000\n",
        "    )\n",
        "\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "  map_reduce_chain = MapReduceDocumentsChain(\n",
        "        llm_chain = map_chain,\n",
        "        reduce_documents_chain = reduce_documents_chain\n",
        "    )\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "  dune2_cleaned\n",
        "  split_script = text_splitter.split_documents(script)\n",
        "\n",
        "  # resultado\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "  return result[\"output_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "outputs": [],
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"\n",
        "Summarize the following text in 3-4 sentences, keeping the key points and the essence of the content.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_summary = \"\"\"\n",
        "Combine the following summaries into a single coherent summary that retains the key points and essence of the content.\n",
        "\n",
        "Summaries:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "answer_summary = \"\"\"\n",
        "Summarize the following text adding an introduction and a conclusion:\n",
        "\n",
        "{text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ijib42GaIFSI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vanessa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Gemini produced an empty response. Continuing with empty message\n",
            "Feedback: block_reason: OTHER\n",
            "\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ],
      "source": [
        "resumen_dune2 = map_reduce_text(dune2_cleaned, map_template_summary, reduce_template_summary)\n",
        "resumen_underparis = map_reduce_text(underparis_cleaned, map_template_summary, reduce_template_summary)\n",
        "resumen_joker = map_reduce_text(joker_cleaned, map_template_summary, reduce_template_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumen Dune 2: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "The story of \"Dune\" unfolds on the harsh desert planet of Arrakis, where the precious spice melange fuels galactic power and political intrigue.  Paul Atreides, heir to the destroyed House Atreides, seeks vengeance against the Harkonnens, who orchestrated their downfall.  He finds refuge among the Fremen, desert dwellers who believe him to be the prophesied Lisan al-Gaib, a savior destined to unite them.\n",
            "\n",
            "Paul's journey is fraught with challenges. He grapples with the complexities of Fremen culture, the pressure of his destiny, and the potential for immense power. His mother, Jessica, undergoes a perilous transformation into a Reverend Mother, a powerful figure within the Bene Gesserit, a sisterhood that manipulates events for their own ends. The Harkonnens, led by the cruel Baron and his ruthless nephew Feyd-Rautha, remain a constant threat, vying for control of the spice and seeking Paul's demise.\n",
            "\n",
            "Paul's alliance with the Fremen grows stronger, marked by trials and tribulations. He earns the name \"Muad'Dib\" and becomes a symbol of hope and resistance against the Harkonnens. The Fremen's religious fervor intensifies, further complicating the political landscape, as does the Emperor's desire to control the spice. Paul's father's hidden atomic arsenal adds a layer of dangerous potential, while the Bene Gesserit's machinations continue to influence events.\n",
            "\n",
            "The narrative culminates in a climactic battle for control of Arrakis, where Paul, with his Fremen allies, confronts the Emperor and the Great Houses. The outcome of this conflict will determine the fate of the planet and the balance of power in the universe.  Paul's journey is a complex one, marked by ambition, duty, and the profound impact of his destiny on the people of Arrakis. \n",
            "\n",
            " \n",
            "\n",
            "Resumen Under Paris: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "\"Under Paris (2024)\" is a suspenseful film set against the backdrop of a triathlon in Paris, where a giant shark named Lilith has unexpectedly appeared in the Seine River. This environmental crisis, a direct consequence of climate change and pollution, threatens the city and its inhabitants, forcing marine biologist Sophia and her team, including the River Brigade, to investigate and find a solution. \n",
            "\n",
            "The film follows Sophia and Adil, a former soldier haunted by his past, as they navigate a series of dangerous situations.  Despite the evident danger, the mayor prioritizes the triathlon, highlighting a disregard for public safety and a focus on appearances.  The event is disrupted by a string of unforeseen events, including a mysterious disappearance, a collapsing building, and a chaotic escape. \n",
            "\n",
            "Sophia's investigation reveals Lilith is not alone, but part of a new species that reproduces through parthenogenesis, making them a rapidly growing threat.  The team faces skepticism and fear, but their dedication to protecting both humans and marine life drives them forward. The film explores themes of environmental impact, human responsibility, and the delicate balance of nature, culminating in a tense climax as the threat of Lilith and her offspring grows.  \n",
            "\n",
            "\"Under Paris (2024)\" is a gripping and suspenseful film that blends action, mystery, and drama, leaving Sophia's fate uncertain and hinting at a sinister threat to their safety. The film's exploration of trauma, loss, and the consequences of past actions, alongside the stark realities of environmental crisis, make it a compelling and memorable experience. \n",
            "\n",
            "\n",
            "\n",
            "Resumen Joker: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "\"Joker\" (2019) is a dark psychological thriller that explores the descent of Arthur Fleck, a struggling clown, into madness. Set against the backdrop of a decaying Gotham City, the film paints a chilling portrait of societal apathy and individual despair. Arthur, grappling with mental illness, societal neglect, and a troubled past, seeks solace in humor and medication, but ultimately succumbs to his internal struggles and the city's dysfunction. \n",
            "\n",
            "The film delves into themes of social inequality, mental illness, and the thin line between humor and violence. Arthur's transformation into the iconic villain, \"Joker,\" is a gradual process fueled by his internal turmoil, his interactions with a society that seems to have abandoned him, and the escalating chaos in Gotham. This culminates in a climactic scene where Arthur, now Joker, becomes a symbol of the city's unrest, orchestrating a riot that reflects the simmering rage and despair beneath the surface of Gotham. \n",
            "\n",
            "\"Joker\" offers a disturbingly relevant commentary on the consequences of societal neglect and the potential for individuals to be driven to extremes when faced with systemic apathy and personal despair. It leaves the viewer questioning the nature of humor, the boundaries of sanity, and the potential for violence to erupt when hope is lost. \n",
            "\n",
            "This exploration of destruction, resilience, and loss is further highlighted through a chilling depiction of a city in flames, likely caused by Arthur, who laughs gleefully amidst the chaos. This scene underscores Arthur's detachment and lack of remorse. However, the text also presents a counterpoint through a song that, despite its upbeat tone, reveals a poignant message of resilience in the face of adversity. The lyrics express a determination to find beauty and hope amidst destruction, offering a glimmer of optimism amidst the bleakness of Arthur's actions. \n",
            "\n",
            "The text then expands upon these themes by referencing other films, including \"The Boy and the Heron\" (2023), which explores themes of grief and loss in the aftermath of war. This reinforces the overarching message of resilience and the human capacity to find hope even in the face of profound loss. Ultimately, the text presents a multifaceted exploration of human nature, showcasing both the capacity for destruction and the unwavering spirit of resilience that allows us to navigate even the most challenging circumstances. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "resumen_dune2 = answer_summary.format(text = resumen_dune2)\n",
        "resumen_underparis = answer_summary.format(text = resumen_underparis)\n",
        "resumen_joker = answer_summary.format(text = resumen_joker)\n",
        "\n",
        "# imprimir resumenes de pel√≠culas.\n",
        "print(f\"Resumen Dune 2: \\n {resumen_dune2} \\n\")\n",
        "\n",
        "print(f\"Resumen Under Paris: \\n {resumen_underparis}\\n\")\n",
        "\n",
        "print(f\"Resumen Joker: \\n {resumen_joker}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      },
      "source": [
        "Adicionalmente, Joaqu√≠n sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustar√≠a tener mayor informaci√≥n al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gr√°fico que muestre los personajes de la pel√≠cula con m√°s apariciones en la misma.\n",
        "4. Genere una tabla en pandas con los 3 personajes que m√°s aparecen, indicando el nombre del actor y su edad actual m√°s uno (ojo edad + 1).\n",
        "5. Cree una funci√≥n que responda preguntas sobre la pel√≠cula bas√°ndose en la informaci√≥n del texto entregado (OJO: las preguntas y salidas deben ser en espa√±ol). Luego, responda las siguientes preguntas:\n",
        "* ¬øQu√© y qui√©n es Lisan al-Gaib?\n",
        "* ¬øQu√© personaje no cree en la profec√≠a pero es parte de ella?\n",
        "* ¬øCu√°l es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que m√°s aparecen en la pel√≠cula, genere con el modelo LLM y utilizando el contexto del guion, las 6 estad√≠sticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_vdMMceJZBu"
      },
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente secci√≥n, tiene que entregar un template de personajes y redicci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fIM5JVC5JWNt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ],
      "source": [
        "map_template_characters = \"\"\"\n",
        "Extract the list of characters from the following text. Include only the names of the characters and nothing else:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"\n",
        "Combine the following lists of characters into a single list without duplicates but including the times they appear on the script:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    dune2_cleaned,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the combined list of characters, including their appearances in the script, without duplicates:\n",
            "\n",
            "1. **Paul Atreides**: 17\n",
            "2. **Chani**: 24\n",
            "3. **Jessica**: 20\n",
            "4. **Stilgar**: 22\n",
            "5. **Harkonnen**: 11\n",
            "6. **Harkonnen soldier**: 8\n",
            "7. **Fremen**: 8\n",
            "8. **Rabban**: 8\n",
            "9. **Harkonnen commander**: 3\n",
            "10. **Fremen sentinel**: 1\n",
            "11. **sentinel leader**: 1\n",
            "12. **Jamis**: 4\n",
            "13. **Lisan al-Gaib**: 4\n",
            "14. **Mahdi**: 1\n",
            "15. **Oldest elder**: 1\n",
            "16. **Janis**: 1\n",
            "17. **Shishakli**: 7\n",
            "18. **Old watermaster**: 1\n",
            "19. **Fedaykin fighter**: 1\n",
            "20. **Muad‚ÄôDib**: 11\n",
            "21. **Usul**: 4\n",
            "22. **Sihaya**: 1\n",
            "23. **Baron Harkonnen**: 7\n",
            "24. **Shai-Hulud**: 1\n",
            "25. **She**: 1\n",
            "26. **You**: 1\n",
            "27. **Our mother**: 1\n",
            "28. **They**: 1\n",
            "29. **Your people**: 1\n",
            "30. **Emperor**: 4\n",
            "31. **Princess Irulan**: 4\n",
            "32. **Reverend Mother**: 5\n",
            "33. **Reverend Mother Mohiam**: 5\n",
            "34. **Feyd-Rautha Harkonnen**: 8\n",
            "35. **na-Baron**: 3\n",
            "36. **Bene Gesserit**: 2\n",
            "37. **Bene Gesserit sister 1**: 1\n",
            "38. **slave master**: 1\n",
            "39. **gladiator arena announcer**: 1\n",
            "40. **Atreides**: 1\n",
            "41. **Lady Margot Fenring**: 3\n",
            "42. **Gurney**: 8\n",
            "43. **man 1**: 1\n",
            "44. **man 2**: 1\n",
            "45. **Commander (Harkonnen)**: 1\n",
            "46. **Translator**: 1\n",
            "47. **Maker Keeper (Chakobsa)**: 1\n",
            "48. **Ancient Voices (Chakobsa)**: 1\n",
            "49. **Alia**: 1\n",
            "50. **Leto Atreides**: 4\n",
            "51. **Bashar**: 2\n",
            "52. **Denis Villeneuve**: 1\n",
            "53. **Ezra**: 1\n",
            "54. **Max**: 1\n",
            "55. **Jenna**: 1\n",
            "56. **All of Us Strangers**: 1\n",
            "57. **Mahito**: 1 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(answer_character_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  answer_character_list = answer_character_list.split('\\n')\n",
        "  pattern = r'\\*\\*([^*]+)\\*\\*' # Expresi√≥n regular para obtener los nombres de los personajes que se encuentran entre ** ** de la forma en que es entregado por el modelo\n",
        "  num_pattern = r'\\*\\*[^*]+\\*\\*|\\b(\\d+)\\b' # Expresi√≥n regular para extraer el n√∫mero de apariciones de los personajes\n",
        "  characters = {}\n",
        "\n",
        "  for item in answer_character_list:\n",
        "        matches = re.findall(pattern, item) # Se realizan los matches para los personajes\n",
        "        matches_num = re.findall(num_pattern, item) # Se realizan los matches para los n√∫meros\n",
        "        matches_num = [num for num in matches_num if num.isdigit()] # Se limpia el match de los n√∫meros para obtener solo el valor que se necesita de las apariciones\n",
        "        \n",
        "        if matches and matches_num: # Se confirma que existan los valores\n",
        "            clean_match = re.sub(r':', '', matches[0]) # Se eliminan los : de los nombres de los personajes\n",
        "            characters[clean_match.strip()] = int(matches_num[0]) #Se crea el diccionario con los nombres y n√∫mero de apariciones\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame(list(characters.items()), columns=['Character', 'Appearances'])\n",
        "\n",
        "  # Graficar datos\n",
        "  fig = px.bar(df, x='Character', y='Appearances', title='Character Appearances', \n",
        "                 labels={'Character': 'Character', 'Appearances': 'Number of Appearances'})\n",
        "  fig.show()\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "alignmentgroup": "True",
                  "hovertemplate": "Character=%{x}<br>Number of Appearances=%{y}<extra></extra>",
                  "legendgroup": "",
                  "marker": {
                    "color": "#636efa",
                    "pattern": {
                      "shape": ""
                    }
                  },
                  "name": "",
                  "offsetgroup": "",
                  "orientation": "v",
                  "showlegend": false,
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    "Paul Atreides",
                    "Chani",
                    "Jessica",
                    "Stilgar",
                    "Harkonnen",
                    "Harkonnen soldier",
                    "Fremen",
                    "Rabban",
                    "Harkonnen commander",
                    "Fremen sentinel",
                    "sentinel leader",
                    "Jamis",
                    "Lisan al-Gaib",
                    "Mahdi",
                    "Oldest elder",
                    "Janis",
                    "Shishakli",
                    "Old watermaster",
                    "Fedaykin fighter",
                    "Muad‚ÄôDib",
                    "Usul",
                    "Sihaya",
                    "Baron Harkonnen",
                    "Shai-Hulud",
                    "She",
                    "You",
                    "Our mother",
                    "They",
                    "Your people",
                    "Emperor",
                    "Princess Irulan",
                    "Reverend Mother",
                    "Reverend Mother Mohiam",
                    "Feyd-Rautha Harkonnen",
                    "na-Baron",
                    "Bene Gesserit",
                    "Bene Gesserit sister 1",
                    "slave master",
                    "gladiator arena announcer",
                    "Atreides",
                    "Lady Margot Fenring",
                    "Gurney",
                    "man 1",
                    "man 2",
                    "Commander (Harkonnen)",
                    "Translator",
                    "Maker Keeper (Chakobsa)",
                    "Ancient Voices (Chakobsa)",
                    "Alia",
                    "Leto Atreides",
                    "Bashar",
                    "Denis Villeneuve",
                    "Ezra",
                    "Max",
                    "Jenna",
                    "All of Us Strangers",
                    "Mahito"
                  ],
                  "xaxis": "x",
                  "y": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49,
                    50,
                    51,
                    52,
                    53,
                    54,
                    55,
                    56,
                    57
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "barmode": "relative",
                "legend": {
                  "tracegroupgap": 0
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Character Appearances"
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Character"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Number of Appearances"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "characters = plot_characters(answer_character_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G2dx0XoLis4"
      },
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja informaci√≥n de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar b√∫squedas que nos ayuden a completar la informaci√≥n consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "outputs": [],
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "outputs": [],
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = load_tools([\"google-serper\"], llm=llm)\n",
        "  agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.OPENAI_FUNCTIONS)\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"\n",
        "  Get the name of the actor who played {character} in Dune 2 and their age. Structured like [name,age].\n",
        "  \"\"\"\n",
        "\n",
        "  # Crear prompt y usar agente para la b√∫squeda.\n",
        "  prompt = query_template.format(character=character)\n",
        "  response = agent.run(prompt)\n",
        "  response = response.strip().strip('[]').split(',')\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "  data = {'Name': [response[0]],\n",
        "          'Age': [int(response[1]) + 1]}\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Character</th>\n",
              "      <th>Appearances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Paul Atreides</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chani</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jessica</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Character  Appearances\n",
              "0  Paul Atreides           26\n",
              "1          Chani           24\n",
              "2        Jessica           21"
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se revisa cuales son los 3 personajes con m√°s apariciones\n",
        "characters.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se aplica la funci√≥n para esos personajes\n",
        "top1_actor = get_actors_and_age(\"Paul Atreides\")\n",
        "top2_actor = get_actors_and_age(\"Chani\")\n",
        "top3_actor = get_actors_and_age(\"Jessica\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Character</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Timoth√©e Chalamet</td>\n",
              "      <td>28</td>\n",
              "      <td>Paul Atreides</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zendaya</td>\n",
              "      <td>28</td>\n",
              "      <td>Chani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rebecca Ferguson</td>\n",
              "      <td>39</td>\n",
              "      <td>Jessica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name  Age      Character\n",
              "0  Timoth√©e Chalamet   28  Paul Atreides\n",
              "0            Zendaya   28          Chani\n",
              "0   Rebecca Ferguson   39        Jessica"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se crea un dataframe con los 3 personajes, sus actores y edades\n",
        "top3_characters = characters.head(3)[\"Character\"]\n",
        "df = pd.concat([top1_actor, top2_actor, top3_actor])\n",
        "df[\"Character\"] = top3_characters.to_list()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpf9H61qMxal"
      },
      "source": [
        "**Explicar metodolog√≠a utilizada**\n",
        "\n",
        "Se utiliza la API de google serper como herramienta, para luego usar como agente OPENAI ya que este pudo proporcionar las edades de los actores exitosamente, mientras que otras como ZERO_SHOT_REACT_DESCRIPTION solo se lograba obtener el nombre de los actores. De este modo se solicit√≥ en la query que se entregaran los nombres y edades de la forma [nombre, edad] para poder manejarlos con mayor facilidad. Luego de esto se aplic√≥ este prompt y se convirti√≥ la respuesta en una lista con el nombre y la edad, cosa que se convirti√≥ a un dataframe sum√°ndole 1 a la edad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQqA40sM09E"
      },
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estad√≠sticas basandonos en una b√∫squeda por map/reduce.\n",
        "\n",
        "Tras la b√∫squeda, la idea es tener una funci√≥n de Python que nos permita generar el gr√°fico deseado y tener el resumen de los personajes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducci√≥n.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un m√°ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "outputs": [],
      "source": [
        "# Escriba su respuesta ac√°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "outputs": [],
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "outputs": [],
      "source": [
        "print(final_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n para gr√°ficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_APhHBPXQXTX"
      },
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodolog√≠a y secuencia l√≥gica de cada una de las respuestas. Adem√°s responda:\n",
        "\n",
        "* ¬øQu√© otras tareas se podr√≠a realizar? De dos ejemplos con la metodolog√≠a asociada.\n",
        "\n",
        "* ¬øCual es la importancia de los prompt y como estos afectan al desempe√±o de los LLM?\n",
        "\n",
        "* ¬øAlguna de sus respuestas fue una 'alucinaci√≥n'? ¬øPor qu√© sucede esto?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci√≥n van a usar m√©todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "8445bc8e-2de6-4342-f789-1c3ce6d18cdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\n"
          ]
        }
      ],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaqu√≠n es fan√°tico del Blackjack, por lo que en esta subsecci√≥n implementar√°n m√©todos de RL y as√≠ generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c√≥digo transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **2.1.1 Descripci√≥n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci√≥n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "En un Proceso de Decisi√≥n de Markov se tienen 3 elementos: estados (informaci√≥n que obtiene el agente del ambiente), acciones (set de acciones posibles a realizar por el agente) y recompensas (feedback otorgado al agente al ejecutar una acci√≥n a en un estado s). En el caso de Blackjack se tiene que:\n",
        "\n",
        "* El estado est√° compuesto de 3 variables: la suma actual del jugador, el valor de la √∫nica carta que muestra el crupier (1-10 donde 1 es el as) y si el jugador tiene un as utilizable (0 o 1).\n",
        "* Hay 2 acciones posibles: 0 o stick (mantener su mano actual y pasar el turno al crupier) y 1 o hit (tomar carta adicional).\n",
        "* Existen 4 recompensas: ganar juego (+1), perder juego (-1), empate (0) y ganar juego con blackjack natural (+1.5 si natural es verdadero y +1 si natural es falso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Discrete(2)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiDiscrete([32 11  2])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([15, 10,  0]), 0.0, False, False, {})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reset()\n",
        "env.step(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulaci√≥n 5000 veces y reporte el promedio y desviaci√≥n de las recompensas.\n",
        "* ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?\n",
        "* ¬øC√≥mo podr√≠a interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RHCfKN7NGi1K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio de Recompensa: -0.3968\n",
            "Desviaci√≥n Est√°ndar: 0.8947344634024107\n"
          ]
        }
      ],
      "source": [
        "# n√∫mero de simulaciones\n",
        "num_simulations = 5000\n",
        "\n",
        "# lista para almacenar las recompensas\n",
        "rewards = []\n",
        "\n",
        "# aimular acciones aleatorias\n",
        "for _ in range(num_simulations):\n",
        "    # Reiniciar el entorno y obtener el estado inicial\n",
        "    observation, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = env.action_space.sample()  # elegimos una acci√≥n aleatoria\n",
        "        observation, reward, terminated, truncated, info = env.step(action)   # ejecutar la acci√≥n en el entorno\n",
        "        total_reward += reward   # sumamos la recompensa\n",
        "        done = terminated or truncated   # el episodio se considera terminado si `terminated` o `truncated` es True\n",
        "    # agregar la recompensa total de la simulaci√≥n a la lista\n",
        "    rewards.append(total_reward)\n",
        "\n",
        "# calcular el promedio y la desviaci√≥n est√°ndar\n",
        "average_reward = np.mean(rewards)\n",
        "std_deviation = np.std(rewards)\n",
        "\n",
        "print(f\"Promedio de Recompensa: {average_reward}\")\n",
        "print(f\"Desviaci√≥n Est√°ndar: {std_deviation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estos resultados provienen de ejecutar 5000 simulaciones con una pol√≠tica que escoge acciones de manera aleatoria en el entorno de Blackjack. Un promedio de recompensa negativo indica que, en general, la pol√≠tica aleatoria tiende a perder m√°s de lo que gana. Este valor negativo sugiere que el agente pierde en promedio cerca de 0.4 puntos por simulaci√≥n. Considerando que en Blackjack la idea es maximizar las ganancias, o al menos minimizar las p√©rdidas, este rendimiento es sub√≥ptimo. Sin embargo, la pol√≠tica aleatoria no considera las probabilidades ni las estrategias √≥ptimas, por lo que no se espera que tenga un buen rendimiento.\n",
        "\n",
        "En cuanto a la desviaci√≥n est√°ndar, su valor muestra una variabilidad considerable en las recompensas obtenidas. Esto significa que aunque el promedio es negativo, algunas partidas pueden tener recompensas positivas, y otras pueden tener p√©rdidas mayores. Esta alta variabilidad es esperada en pol√≠ticas que no siguen ninguna estrategia espec√≠fica y se basan en decisiones aleatorias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0sp8XWsGg4P"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac√°\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **2.1.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* ¬øC√≥mo es el performance de su agente?\n",
        "* ¬øEs mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7jdmnTwGePD"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una funci√≥n que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta funci√≥n para entregar la acci√≥n escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* ¬øSon coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¬øA que clase de python pertenecen los estados? Pruebe a usar el m√©todo `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lssdp7AvGaRh"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci√≥n 2.1, en esta secci√≥n usted se encargar√° de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **2.2.1 Descripci√≥n de MDP (0.2 puntos)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvAVq1wQIjLc"
      },
      "source": [
        "Comencemos preparando el ambiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par√°metro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNERH-m8JYQb"
      },
      "source": [
        "* Entregue una breve descripci√≥n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* ¬øComo se distinguen las acciones de este ambiente en comparaci√≥n a `Blackjack`?\n",
        "* En la preparaci√≥n del ambiente se especifica el par√°metro `continuous = True`. ¬øQue implicancias tiene esto sobre el ambiente?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpGahPcHAje"
      },
      "source": [
        "`Escriba su respuesta ac√°`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci√≥n 10 veces y reporte el promedio y desviaci√≥n de las recompensas.\n",
        "* ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNMT_GORIreW"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg0epSnLKfy6"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **2.2.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* ¬øC√≥mo es el performance de su agente? ¬øEs mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWVY1a39KeRs"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **2.2.5 Optimizaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par√°metros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la funci√≥n `export_gif` entregada para estudiar el comportamiento de su agente en la resoluci√≥n del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, adem√°s, adjuntan el gif en el markdown tendr√°n un bonus de 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag-QIrmhLIY_"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci√≥n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta ac√°"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
