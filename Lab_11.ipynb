{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Autónomos 🤖</center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown",
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicolás Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown",
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1: Vanessa González \n",
        "- Nombre de alumno 2: Benjamín Angulo\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no serán revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown",
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/BenjaminAnguloCaro/MDS7202/tree/Lab11`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown",
        "id": "EcnsiQMkzAHr"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcción del laboratorio](#Descripción-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown",
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementación de modelos de LLM y Reinforcement Learning.\n",
        "- Utilización e implementación de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 días desde la publicación, 3 días de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia será debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no estén en u-cursos no serán revisados. Recuerden que el repositorio también tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is4P4NDMurx6"
      },
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ3yV96HwN75"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB8z1qrGww4o"
      },
      "source": [
        "Joaquín no es un aficionado del cine, pero a principios de año, se propuso ver más peliculas para poder tener más temas de conversación con sus amigos y familia. Sin embargo, ya es junio y Joaquín no ha visto ninguna pelicula nueva o relevante de las que tenía en su lista y su reunión familiar bi-anual se acerca y necesita la mayor información que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compañerx, tendrá que crear una aplicación utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      },
      "source": [
        "**Instalación de librerías**\n",
        "\n",
        "Para la creación de la aplicación, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizará la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ahí, ir a la pestaña superior y seleccione la opción que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el botón que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podrá consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor información sobre **LangChain**, pueden revisar la documentación en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install beautifulsoup4 html5lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDtqofHPr88_QSyHbTl3aXWQdQF3FpPyZM\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUgbzVtWUYq2"
      },
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I10Li9a7nez"
      },
      "source": [
        "Para iniciar su titanica tarea de enseñarle a Joaquín sobre las mejores peliculas del último tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "Debe encontrar un patrón y obtener solamente el guión de las películas. Para ello se recomienda utilizar métodos de búsqueda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patrón se repite y es generalizable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "outputs": [],
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XUfvpxPD8v5X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Función para cargar el script\n",
        "def load_website_data(url): \n",
        "  loader = WebBaseLoader(url)\n",
        "  website_data = loader.load()\n",
        "  return website_data\n",
        "\n",
        "def remove_text_before_marker(text, marker = \"| Transcript \\n\"):# Se define un marcador que se encuentra en el inicio de todos los scripts antes del guión propiamente tal \n",
        "  splitter = RecursiveCharacterTextSplitter([marker]) # Se crea el splitter que dividirá el texto en dos en el punto del marcador\n",
        "  output_text = splitter.split_documents(text) # Se divide el texto en dos partes\n",
        "  return [output_text[1]] # Recuperamos la parte de después del marcador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dune2_data = load_website_data(dune2_script)\n",
        "underparis_data = load_website_data(underparis_script)\n",
        "joker_data = load_website_data(joker_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dune2_cleaned = remove_text_before_marker(dune2_data)\n",
        "underparis_cleaned = remove_text_before_marker(underparis_data)\n",
        "joker_cleaned = remove_text_before_marker(joker_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Btad-nZ9EyS"
      },
      "source": [
        "### **1.2 Aplicación (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicaicón deseada con el LLM. Esta aplicación tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la película.\n",
        "\n",
        "2. Genere un resumen en español de la película y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 párrafos. Además, obtener una evaluación de la película con una calificación del 1 al 10, utilizando una LLM y el contexto entregado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcS80oN2-Gq4"
      },
      "source": [
        "#### **1.2.1 Título de la película (0.5 puntos)**\n",
        "\n",
        "Para obtener el título, utilicé la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "outputs": [],
      "source": [
        "def get_movie_title(script_path_url):\n",
        "  # Se define el template\n",
        "  template = \"\"\"\n",
        "    What is the movie that appears in the description of this file or url?\n",
        "    You only give me the movie name, nothing more.\n",
        "    document/url: {script_path_url}\n",
        "    \"\"\"\n",
        "  # Se crea el prompt con el template dado y el url del script\n",
        "  prompt = template.format(script_path_url=script_path_url)\n",
        "  # Se realiza la predicción del título de la película\n",
        "  result = llm.predict(prompt)\n",
        "  return result.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vanessa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dune: Part Two\n",
            "Under Paris\n",
            "Joker\n"
          ]
        }
      ],
      "source": [
        "dune2_title = get_movie_title(dune2_script)\n",
        "underparis_title = get_movie_title(underparis_script)\n",
        "joker_title = get_movie_title(joker_script)\n",
        "\n",
        "print(dune2_title)\n",
        "print(underparis_title)\n",
        "print(joker_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muDXLfr0CabX"
      },
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)**\n",
        "\n",
        "Como se vió en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tamaño del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jkxFMnCFDcgl"
      },
      "outputs": [],
      "source": [
        "#No cambiar función\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "  # Map\n",
        "  \"\"\"\n",
        "  map_prompt, crear el prompt desde el template\n",
        "  map_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  map_prompt = PromptTemplate(input_variables = [\"text\"], template = map_template)\n",
        "  map_chain = LLMChain(llm = llm, prompt = map_prompt)\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  reduce_prompt, crear el prompt desde el template\n",
        "  reduce_chain, crear la cadena desde el prompt\n",
        "  \"\"\"\n",
        "  reduce_prompt = PromptTemplate(input_variables = [\"text\"], template = reduce_template)\n",
        "  reduce_chain = LLMChain(llm = llm, prompt = reduce_prompt)\n",
        "\n",
        "  # Combine\n",
        "  \"\"\"\n",
        "  Combinar y reducir los documentos, utilizar StuffDocumentsChain\n",
        "  y ReduceDocuentsChain con un máximo de 4000 tokens\n",
        "  \"\"\"\n",
        "  stuff_chain = StuffDocumentsChain(llm_chain = reduce_chain)\n",
        "  reduce_documents_chain = ReduceDocumentsChain(\n",
        "        combine_documents_chain = stuff_chain,\n",
        "        token_max = 4000\n",
        "    )\n",
        "\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "  map_reduce_chain = MapReduceDocumentsChain(\n",
        "        llm_chain = map_chain,\n",
        "        reduce_documents_chain = reduce_documents_chain\n",
        "    )\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "  dune2_cleaned\n",
        "  split_script = text_splitter.split_documents(script)\n",
        "\n",
        "  # resultado\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "  return result[\"output_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "outputs": [],
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"\n",
        "Summarize the following text in 3-4 sentences, keeping the key points and the essence of the content.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_summary = \"\"\"\n",
        "Combine the following summaries into a single coherent summary that retains the key points and essence of the content.\n",
        "\n",
        "Summaries:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "answer_summary = \"\"\"\n",
        "Summarize the following text adding an introduction and a conclusion:\n",
        "\n",
        "{text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ijib42GaIFSI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vanessa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Gemini produced an empty response. Continuing with empty message\n",
            "Feedback: block_reason: OTHER\n",
            "\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ],
      "source": [
        "resumen_dune2 = map_reduce_text(dune2_cleaned, map_template_summary, reduce_template_summary)\n",
        "resumen_underparis = map_reduce_text(underparis_cleaned, map_template_summary, reduce_template_summary)\n",
        "resumen_joker = map_reduce_text(joker_cleaned, map_template_summary, reduce_template_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumen Dune 2: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "The story of \"Dune\" unfolds on the harsh desert planet of Arrakis, where the precious spice melange fuels galactic power and political intrigue.  Paul Atreides, heir to the destroyed House Atreides, seeks vengeance against the Harkonnens, who orchestrated their downfall.  He finds refuge among the Fremen, desert dwellers who believe him to be the prophesied Lisan al-Gaib, a savior destined to unite them.\n",
            "\n",
            "Paul's journey is fraught with challenges. He grapples with the complexities of Fremen culture, the pressure of his destiny, and the potential for immense power. His mother, Jessica, undergoes a perilous transformation into a Reverend Mother, a powerful figure within the Bene Gesserit, a sisterhood that manipulates events for their own ends. The Harkonnens, led by the cruel Baron and his ruthless nephew Feyd-Rautha, remain a constant threat, vying for control of the spice and seeking Paul's demise.\n",
            "\n",
            "Paul's alliance with the Fremen grows stronger, marked by trials and tribulations. He earns the name \"Muad'Dib\" and becomes a symbol of hope and resistance against the Harkonnens. The Fremen's religious fervor intensifies, further complicating the political landscape, as does the Emperor's desire to control the spice. Paul's father's hidden atomic arsenal adds a layer of dangerous potential, while the Bene Gesserit's machinations continue to influence events.\n",
            "\n",
            "The narrative culminates in a climactic battle for control of Arrakis, where Paul, with his Fremen allies, confronts the Emperor and the Great Houses. The outcome of this conflict will determine the fate of the planet and the balance of power in the universe.  Paul's journey is a complex one, marked by ambition, duty, and the profound impact of his destiny on the people of Arrakis. \n",
            "\n",
            " \n",
            "\n",
            "Resumen Under Paris: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "\"Under Paris (2024)\" is a suspenseful film set against the backdrop of a triathlon in Paris, where a giant shark named Lilith has unexpectedly appeared in the Seine River. This environmental crisis, a direct consequence of climate change and pollution, threatens the city and its inhabitants, forcing marine biologist Sophia and her team, including the River Brigade, to investigate and find a solution. \n",
            "\n",
            "The film follows Sophia and Adil, a former soldier haunted by his past, as they navigate a series of dangerous situations.  Despite the evident danger, the mayor prioritizes the triathlon, highlighting a disregard for public safety and a focus on appearances.  The event is disrupted by a string of unforeseen events, including a mysterious disappearance, a collapsing building, and a chaotic escape. \n",
            "\n",
            "Sophia's investigation reveals Lilith is not alone, but part of a new species that reproduces through parthenogenesis, making them a rapidly growing threat.  The team faces skepticism and fear, but their dedication to protecting both humans and marine life drives them forward. The film explores themes of environmental impact, human responsibility, and the delicate balance of nature, culminating in a tense climax as the threat of Lilith and her offspring grows.  \n",
            "\n",
            "\"Under Paris (2024)\" is a gripping and suspenseful film that blends action, mystery, and drama, leaving Sophia's fate uncertain and hinting at a sinister threat to their safety. The film's exploration of trauma, loss, and the consequences of past actions, alongside the stark realities of environmental crisis, make it a compelling and memorable experience. \n",
            "\n",
            "\n",
            "\n",
            "Resumen Joker: \n",
            " \n",
            "Summarize the following text adding an introduction and a conclusion:\n",
            "\n",
            "\"Joker\" (2019) is a dark psychological thriller that explores the descent of Arthur Fleck, a struggling clown, into madness. Set against the backdrop of a decaying Gotham City, the film paints a chilling portrait of societal apathy and individual despair. Arthur, grappling with mental illness, societal neglect, and a troubled past, seeks solace in humor and medication, but ultimately succumbs to his internal struggles and the city's dysfunction. \n",
            "\n",
            "The film delves into themes of social inequality, mental illness, and the thin line between humor and violence. Arthur's transformation into the iconic villain, \"Joker,\" is a gradual process fueled by his internal turmoil, his interactions with a society that seems to have abandoned him, and the escalating chaos in Gotham. This culminates in a climactic scene where Arthur, now Joker, becomes a symbol of the city's unrest, orchestrating a riot that reflects the simmering rage and despair beneath the surface of Gotham. \n",
            "\n",
            "\"Joker\" offers a disturbingly relevant commentary on the consequences of societal neglect and the potential for individuals to be driven to extremes when faced with systemic apathy and personal despair. It leaves the viewer questioning the nature of humor, the boundaries of sanity, and the potential for violence to erupt when hope is lost. \n",
            "\n",
            "This exploration of destruction, resilience, and loss is further highlighted through a chilling depiction of a city in flames, likely caused by Arthur, who laughs gleefully amidst the chaos. This scene underscores Arthur's detachment and lack of remorse. However, the text also presents a counterpoint through a song that, despite its upbeat tone, reveals a poignant message of resilience in the face of adversity. The lyrics express a determination to find beauty and hope amidst destruction, offering a glimmer of optimism amidst the bleakness of Arthur's actions. \n",
            "\n",
            "The text then expands upon these themes by referencing other films, including \"The Boy and the Heron\" (2023), which explores themes of grief and loss in the aftermath of war. This reinforces the overarching message of resilience and the human capacity to find hope even in the face of profound loss. Ultimately, the text presents a multifaceted exploration of human nature, showcasing both the capacity for destruction and the unwavering spirit of resilience that allows us to navigate even the most challenging circumstances. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "resumen_dune2 = answer_summary.format(text = resumen_dune2)\n",
        "resumen_underparis = answer_summary.format(text = resumen_underparis)\n",
        "resumen_joker = answer_summary.format(text = resumen_joker)\n",
        "\n",
        "# imprimir resumenes de películas.\n",
        "print(f\"Resumen Dune 2: \\n {resumen_dune2} \\n\")\n",
        "\n",
        "print(f\"Resumen Under Paris: \\n {resumen_underparis}\\n\")\n",
        "\n",
        "print(f\"Resumen Joker: \\n {resumen_joker}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      },
      "source": [
        "Adicionalmente, Joaquín sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustaría tener mayor información al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gráfico que muestre los personajes de la película con más apariciones en la misma.\n",
        "4. Genere una tabla en pandas con los 3 personajes que más aparecen, indicando el nombre del actor y su edad actual más uno (ojo edad + 1).\n",
        "5. Cree una función que responda preguntas sobre la película basándose en la información del texto entregado (OJO: las preguntas y salidas deben ser en español). Luego, responda las siguientes preguntas:\n",
        "* ¿Qué y quién es Lisan al-Gaib?\n",
        "* ¿Qué personaje no cree en la profecía pero es parte de ella?\n",
        "* ¿Cuál es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que más aparecen en la película, genere con el modelo LLM y utilizando el contexto del guion, las 6 estadísticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_vdMMceJZBu"
      },
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente sección, tiene que entregar un template de personajes y redicción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fIM5JVC5JWNt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ],
      "source": [
        "map_template_characters = \"\"\"\n",
        "Extract the list of characters from the following text. Include only the names of the characters and nothing else:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"\n",
        "Combine the following lists of characters into a single list without duplicates but including the times they appear on the script:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    dune2_cleaned,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the combined list of characters, including their appearances in the script, without duplicates:\n",
            "\n",
            "1. **Paul Atreides**: 17\n",
            "2. **Chani**: 24\n",
            "3. **Jessica**: 20\n",
            "4. **Stilgar**: 22\n",
            "5. **Harkonnen**: 11\n",
            "6. **Harkonnen soldier**: 8\n",
            "7. **Fremen**: 8\n",
            "8. **Rabban**: 8\n",
            "9. **Harkonnen commander**: 3\n",
            "10. **Fremen sentinel**: 1\n",
            "11. **sentinel leader**: 1\n",
            "12. **Jamis**: 4\n",
            "13. **Lisan al-Gaib**: 4\n",
            "14. **Mahdi**: 1\n",
            "15. **Oldest elder**: 1\n",
            "16. **Janis**: 1\n",
            "17. **Shishakli**: 7\n",
            "18. **Old watermaster**: 1\n",
            "19. **Fedaykin fighter**: 1\n",
            "20. **Muad’Dib**: 11\n",
            "21. **Usul**: 4\n",
            "22. **Sihaya**: 1\n",
            "23. **Baron Harkonnen**: 7\n",
            "24. **Shai-Hulud**: 1\n",
            "25. **She**: 1\n",
            "26. **You**: 1\n",
            "27. **Our mother**: 1\n",
            "28. **They**: 1\n",
            "29. **Your people**: 1\n",
            "30. **Emperor**: 4\n",
            "31. **Princess Irulan**: 4\n",
            "32. **Reverend Mother**: 5\n",
            "33. **Reverend Mother Mohiam**: 5\n",
            "34. **Feyd-Rautha Harkonnen**: 8\n",
            "35. **na-Baron**: 3\n",
            "36. **Bene Gesserit**: 2\n",
            "37. **Bene Gesserit sister 1**: 1\n",
            "38. **slave master**: 1\n",
            "39. **gladiator arena announcer**: 1\n",
            "40. **Atreides**: 1\n",
            "41. **Lady Margot Fenring**: 3\n",
            "42. **Gurney**: 8\n",
            "43. **man 1**: 1\n",
            "44. **man 2**: 1\n",
            "45. **Commander (Harkonnen)**: 1\n",
            "46. **Translator**: 1\n",
            "47. **Maker Keeper (Chakobsa)**: 1\n",
            "48. **Ancient Voices (Chakobsa)**: 1\n",
            "49. **Alia**: 1\n",
            "50. **Leto Atreides**: 4\n",
            "51. **Bashar**: 2\n",
            "52. **Denis Villeneuve**: 1\n",
            "53. **Ezra**: 1\n",
            "54. **Max**: 1\n",
            "55. **Jenna**: 1\n",
            "56. **All of Us Strangers**: 1\n",
            "57. **Mahito**: 1 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(answer_character_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  answer_character_list = answer_character_list.split('\\n')\n",
        "  pattern = r'\\*\\*([^*]+)\\*\\*' # Expresión regular para obtener los nombres de los personajes que se encuentran entre ** ** de la forma en que es entregado por el modelo\n",
        "  num_pattern = r'\\*\\*[^*]+\\*\\*|\\b(\\d+)\\b' # Expresión regular para extraer el número de apariciones de los personajes\n",
        "  characters = {}\n",
        "\n",
        "  for item in answer_character_list:\n",
        "        matches = re.findall(pattern, item) # Se realizan los matches para los personajes\n",
        "        matches_num = re.findall(num_pattern, item) # Se realizan los matches para los números\n",
        "        matches_num = [num for num in matches_num if num.isdigit()] # Se limpia el match de los números para obtener solo el valor que se necesita de las apariciones\n",
        "        \n",
        "        if matches and matches_num: # Se confirma que existan los valores\n",
        "            clean_match = re.sub(r':', '', matches[0]) # Se eliminan los : de los nombres de los personajes\n",
        "            characters[clean_match.strip()] = int(matches_num[0]) #Se crea el diccionario con los nombres y número de apariciones\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame(list(characters.items()), columns=['Character', 'Appearances'])\n",
        "\n",
        "  # Graficar datos\n",
        "  fig = px.bar(df, x='Character', y='Appearances', title='Character Appearances', \n",
        "                 labels={'Character': 'Character', 'Appearances': 'Number of Appearances'})\n",
        "  fig.show()\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "alignmentgroup": "True",
                  "hovertemplate": "Character=%{x}<br>Number of Appearances=%{y}<extra></extra>",
                  "legendgroup": "",
                  "marker": {
                    "color": "#636efa",
                    "pattern": {
                      "shape": ""
                    }
                  },
                  "name": "",
                  "offsetgroup": "",
                  "orientation": "v",
                  "showlegend": false,
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    "Paul Atreides",
                    "Chani",
                    "Jessica",
                    "Stilgar",
                    "Harkonnen",
                    "Harkonnen soldier",
                    "Fremen",
                    "Rabban",
                    "Harkonnen commander",
                    "Fremen sentinel",
                    "sentinel leader",
                    "Jamis",
                    "Lisan al-Gaib",
                    "Mahdi",
                    "Oldest elder",
                    "Janis",
                    "Shishakli",
                    "Old watermaster",
                    "Fedaykin fighter",
                    "Muad’Dib",
                    "Usul",
                    "Sihaya",
                    "Baron Harkonnen",
                    "Shai-Hulud",
                    "She",
                    "You",
                    "Our mother",
                    "They",
                    "Your people",
                    "Emperor",
                    "Princess Irulan",
                    "Reverend Mother",
                    "Reverend Mother Mohiam",
                    "Feyd-Rautha Harkonnen",
                    "na-Baron",
                    "Bene Gesserit",
                    "Bene Gesserit sister 1",
                    "slave master",
                    "gladiator arena announcer",
                    "Atreides",
                    "Lady Margot Fenring",
                    "Gurney",
                    "man 1",
                    "man 2",
                    "Commander (Harkonnen)",
                    "Translator",
                    "Maker Keeper (Chakobsa)",
                    "Ancient Voices (Chakobsa)",
                    "Alia",
                    "Leto Atreides",
                    "Bashar",
                    "Denis Villeneuve",
                    "Ezra",
                    "Max",
                    "Jenna",
                    "All of Us Strangers",
                    "Mahito"
                  ],
                  "xaxis": "x",
                  "y": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49,
                    50,
                    51,
                    52,
                    53,
                    54,
                    55,
                    56,
                    57
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "barmode": "relative",
                "legend": {
                  "tracegroupgap": 0
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Character Appearances"
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Character"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Number of Appearances"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "characters = plot_characters(answer_character_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G2dx0XoLis4"
      },
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja información de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar búsquedas que nos ayuden a completar la información consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "outputs": [],
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "outputs": [],
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = load_tools([\"google-serper\"], llm=llm)\n",
        "  agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.OPENAI_FUNCTIONS)\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"\n",
        "  Get the name of the actor who played {character} in Dune 2 and their age. Structured like [name,age].\n",
        "  \"\"\"\n",
        "\n",
        "  # Crear prompt y usar agente para la búsqueda.\n",
        "  prompt = query_template.format(character=character)\n",
        "  response = agent.run(prompt)\n",
        "  response = response.strip().strip('[]').split(',')\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "  data = {'Name': [response[0]],\n",
        "          'Age': [int(response[1]) + 1]}\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Character</th>\n",
              "      <th>Appearances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Paul Atreides</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chani</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jessica</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Character  Appearances\n",
              "0  Paul Atreides           26\n",
              "1          Chani           24\n",
              "2        Jessica           21"
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se revisa cuales son los 3 personajes con más apariciones\n",
        "characters.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se aplica la función para esos personajes\n",
        "top1_actor = get_actors_and_age(\"Paul Atreides\")\n",
        "top2_actor = get_actors_and_age(\"Chani\")\n",
        "top3_actor = get_actors_and_age(\"Jessica\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Character</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Timothée Chalamet</td>\n",
              "      <td>28</td>\n",
              "      <td>Paul Atreides</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zendaya</td>\n",
              "      <td>28</td>\n",
              "      <td>Chani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rebecca Ferguson</td>\n",
              "      <td>39</td>\n",
              "      <td>Jessica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name  Age      Character\n",
              "0  Timothée Chalamet   28  Paul Atreides\n",
              "0            Zendaya   28          Chani\n",
              "0   Rebecca Ferguson   39        Jessica"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se crea un dataframe con los 3 personajes, sus actores y edades\n",
        "top3_characters = characters.head(3)[\"Character\"]\n",
        "df = pd.concat([top1_actor, top2_actor, top3_actor])\n",
        "df[\"Character\"] = top3_characters.to_list()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpf9H61qMxal"
      },
      "source": [
        "**Explicar metodología utilizada**\n",
        "\n",
        "Se utiliza la API de google serper como herramienta, para luego usar como agente OPENAI ya que este pudo proporcionar las edades de los actores exitosamente, mientras que otras como ZERO_SHOT_REACT_DESCRIPTION solo se lograba obtener el nombre de los actores. De este modo se solicitó en la query que se entregaran los nombres y edades de la forma [nombre, edad] para poder manejarlos con mayor facilidad. Luego de esto se aplicó este prompt y se convirtió la respuesta en una lista con el nombre y la edad, cosa que se convirtió a un dataframe sumándole 1 a la edad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQqA40sM09E"
      },
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estadísticas basandonos en una búsqueda por map/reduce.\n",
        "\n",
        "Tras la búsqueda, la idea es tener una función de Python que nos permita generar el gráfico deseado y tener el resumen de los personajes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducción.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un máximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "outputs": [],
      "source": [
        "# Escriba su respuesta acá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "outputs": [],
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "outputs": [],
      "source": [
        "print(final_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "outputs": [],
      "source": [
        "# Función para gráficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_APhHBPXQXTX"
      },
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodología y secuencia lógica de cada una de las respuestas. Además responda:\n",
        "\n",
        "* ¿Qué otras tareas se podría realizar? De dos ejemplos con la metodología asociada.\n",
        "\n",
        "* ¿Cual es la importancia de los prompt y como estos afectan al desempeño de los LLM?\n",
        "\n",
        "* ¿Alguna de sus respuestas fue una 'alucinación'? ¿Por qué sucede esto?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta sección van a usar métodos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "8445bc8e-2de6-4342-f789-1c3ce6d18cdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\n"
          ]
        }
      ],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaquín es fanático del Blackjack, por lo que en esta subsección implementarán métodos de RL y así generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **2.1.1 Descripción de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripción sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "En un Proceso de Decisión de Markov se tienen 3 elementos: estados (información que obtiene el agente del ambiente), acciones (set de acciones posibles a realizar por el agente) y recompensas (feedback otorgado al agente al ejecutar una acción a en un estado s). En el caso de Blackjack se tiene que:\n",
        "\n",
        "* El estado está compuesto de 3 variables: la suma actual del jugador, el valor de la única carta que muestra el crupier (1-10 donde 1 es el as) y si el jugador tiene un as utilizable (0 o 1).\n",
        "* Hay 2 acciones posibles: 0 o stick (mantener su mano actual y pasar el turno al crupier) y 1 o hit (tomar carta adicional).\n",
        "* Existen 4 recompensas: ganar juego (+1), perder juego (-1), empate (0) y ganar juego con blackjack natural (+1.5 si natural es verdadero y +1 si natural es falso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Discrete(2)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiDiscrete([32 11  2])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([15, 10,  0]), 0.0, False, False, {})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reset()\n",
        "env.step(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulación 5000 veces y reporte el promedio y desviación de las recompensas.\n",
        "* ¿Cómo calificaría el performance de esta política?\n",
        "* ¿Cómo podría interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RHCfKN7NGi1K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio de Recompensa: -0.3968\n",
            "Desviación Estándar: 0.8947344634024107\n"
          ]
        }
      ],
      "source": [
        "# número de simulaciones\n",
        "num_simulations = 5000\n",
        "\n",
        "# lista para almacenar las recompensas\n",
        "rewards = []\n",
        "\n",
        "# aimular acciones aleatorias\n",
        "for _ in range(num_simulations):\n",
        "    # Reiniciar el entorno y obtener el estado inicial\n",
        "    observation, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = env.action_space.sample()  # elegimos una acción aleatoria\n",
        "        observation, reward, terminated, truncated, info = env.step(action)   # ejecutar la acción en el entorno\n",
        "        total_reward += reward   # sumamos la recompensa\n",
        "        done = terminated or truncated   # el episodio se considera terminado si `terminated` o `truncated` es True\n",
        "    # agregar la recompensa total de la simulación a la lista\n",
        "    rewards.append(total_reward)\n",
        "\n",
        "# calcular el promedio y la desviación estándar\n",
        "average_reward = np.mean(rewards)\n",
        "std_deviation = np.std(rewards)\n",
        "\n",
        "print(f\"Promedio de Recompensa: {average_reward}\")\n",
        "print(f\"Desviación Estándar: {std_deviation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estos resultados provienen de ejecutar 5000 simulaciones con una política que escoge acciones de manera aleatoria en el entorno de Blackjack. Un promedio de recompensa negativo indica que, en general, la política aleatoria tiende a perder más de lo que gana. Este valor negativo sugiere que el agente pierde en promedio cerca de 0.4 puntos por simulación. Considerando que en Blackjack la idea es maximizar las ganancias, o al menos minimizar las pérdidas, este rendimiento es subóptimo. Sin embargo, la política aleatoria no considera las probabilidades ni las estrategias óptimas, por lo que no se espera que tenga un buen rendimiento.\n",
        "\n",
        "En cuanto a la desviación estándar, su valor muestra una variabilidad considerable en las recompensas obtenidas. Esto significa que aunque el promedio es negativo, algunas partidas pueden tener recompensas positivas, y otras pueden tener pérdidas mayores. Esta alta variabilidad es esperada en políticas que no siguen ninguna estrategia específica y se basan en decisiones aleatorias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0sp8XWsGg4P"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta acá\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **2.1.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* ¿Cómo es el performance de su agente?\n",
        "* ¿Es mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7jdmnTwGePD"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una función que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta función para entregar la acción escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* ¿Son coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¿A que clase de python pertenecen los estados? Pruebe a usar el método `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lssdp7AvGaRh"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la sección 2.1, en esta sección usted se encargará de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **2.2.1 Descripción de MDP (0.2 puntos)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvAVq1wQIjLc"
      },
      "source": [
        "Comencemos preparando el ambiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el parámetro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNERH-m8JYQb"
      },
      "source": [
        "* Entregue una breve descripción sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* ¿Como se distinguen las acciones de este ambiente en comparación a `Blackjack`?\n",
        "* En la preparación del ambiente se especifica el parámetro `continuous = True`. ¿Que implicancias tiene esto sobre el ambiente?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpGahPcHAje"
      },
      "source": [
        "`Escriba su respuesta acá`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 10 veces y reporte el promedio y desviación de las recompensas.\n",
        "* ¿Cómo calificaría el performance de esta política?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNMT_GORIreW"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg0epSnLKfy6"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **2.2.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWVY1a39KeRs"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **2.2.5 Optimización de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parámetros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la función `export_gif` entregada para estudiar el comportamiento de su agente en la resolución del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, además, adjuntan el gif en el markdown tendrán un bonus de 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag-QIrmhLIY_"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  función que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "outputs": [],
      "source": [
        "# escriba su respuesta acá"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
