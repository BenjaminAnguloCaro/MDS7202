{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5c0d2440b3e4995a794ded565213150",
        "deepnote_cell_type": "markdown",
        "id": "_Mql1uRoI5v5"
      },
      "source": [
        "<h1><center>Laboratorio 9: Optimización de modelos 💯</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
        "deepnote_cell_type": "markdown",
        "id": "FAPGIlEAI5v8"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
        "- Auxiliares: Catherine Benavides y Consuelo Rojas\n",
        "- Ayudante: Nicolás Ojeda, Eduardo Moya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
        "deepnote_cell_type": "markdown",
        "id": "8NozgbkZI5v9"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
        "\n",
        "- Nombre de alumno 1: Vanessa González\n",
        "- Nombre de alumno 2: Benjamín Angulo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
        "deepnote_cell_type": "markdown",
        "id": "vHU9DI6wI5v9"
      },
      "source": [
        "### Temas a tratar\n",
        "\n",
        "- Predicción de demanda usando `xgboost`\n",
        "- Búsqueda del modelo óptimo de clasificación usando `optuna`\n",
        "- Uso de pipelines.\n",
        "\n",
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- Código que no se pueda ejecutar, no será revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Optimizar modelos usando `optuna`\n",
        "- Recurrir a técnicas de *prunning*\n",
        "- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n",
        "- Fijar un pipeline con un modelo base que luego se irá optimizando.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f38c8342f5164aa992a97488dd5590bf",
        "deepnote_cell_type": "markdown",
        "id": "3Ceri_rbI5v9"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `http://....`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
        "deepnote_cell_type": "markdown",
        "id": "U_-sNOuOI5v9"
      },
      "source": [
        "# Importamos librerias útiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "51afe4d2df42442b9e5402ffece60ead",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4957,
        "execution_start": 1699544354044,
        "id": "ekHbM85NI5v9",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "!pip install -qq xgboost optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hJXpLCSspz"
      },
      "source": [
        "# El emprendimiento de Fiu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44d227389a734ac59189c5e0005bc68a",
        "deepnote_cell_type": "markdown",
        "id": "b0bDalAOI5v-"
      },
      "source": [
        "Tras liderar de manera exitosa la implementación de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corpóreo **Fiu** se anima y decide levantar su propio negocio de consultoría en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterización de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
        "\n",
        "Para comenzar, cargue el dataset señalado y visualice a través de un `.head` los atributos que posee el dataset.\n",
        "\n",
        "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempeño en el proyecto de caracterización de datos</p></i>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 92,
        "execution_start": 1699544359006,
        "id": "QvMPOqHuI5v-",
        "outputId": "659e7a12-d74d-45d6-d3c2-33a6cd338585",
        "source_hash": null
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Vanessa\\AppData\\Local\\Temp\\ipykernel_17180\\3184305967.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['date'] = pd.to_datetime(df['date'])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>pop</th>\n",
              "      <th>shop</th>\n",
              "      <th>brand</th>\n",
              "      <th>container</th>\n",
              "      <th>capacity</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.96</td>\n",
              "      <td>13280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.86</td>\n",
              "      <td>6727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.87</td>\n",
              "      <td>9848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>20050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.39</td>\n",
              "      <td>25696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id       date    city       lat      long     pop    shop        brand  \\\n",
              "0   0 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "1   1 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "2   2 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "3   3 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "4   4 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "\n",
              "  container capacity  price  quantity  \n",
              "0     glass    500ml   0.96     13280  \n",
              "1   plastic    1.5lt   2.86      6727  \n",
              "2       can    330ml   0.87      9848  \n",
              "3     glass    500ml   1.00     20050  \n",
              "4       can    330ml   0.39     25696  "
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv('sales.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
        "deepnote_cell_type": "markdown",
        "id": "pk4ru76pI5v_"
      },
      "source": [
        "## 1 Generando un Baseline (0.5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
        "</p>\n",
        "\n",
        "Antes de entrenar un algoritmo, usted recuerda los apuntes de su magíster en ciencia de datos y recuerda que debe seguir una serie de *buenas prácticas* para entrenar correcta y debidamente su modelo. Después de un par de vueltas, llega a las siguientes tareas:\n",
        "\n",
        "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n",
        "2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n",
        "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. Use `OneHotEncoder` para las variables categóricas.\n",
        "4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n",
        "5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación. ¿Cómo se interpreta esta métrica para el contexto del negocio?\n",
        "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`?\n",
        "7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.- Se obtiene un MAE de 13546.49. En este contexto, un MAE menor implica que las predicciones están más cerca de los valores reales de demanda, o bien, implica una mejor precisión del modelo.\n",
        "\n",
        "6.- Con XGBReressor, el MAE obtenido es de 2391.15. Es decir, en este caso el MAE es mejor y las predicciones están bastante más cerca de los valores reales de demanda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "cell_id": "1482c992d9494e5582b23dbd3431dbfd",
        "deepnote_cell_type": "code",
        "id": "sfnN7HubI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE del DummyRegressor: 13546.494391911923\n",
            "MAE del XGBRegressor: 2391.1526059023413\n"
          ]
        }
      ],
      "source": [
        "# Inserte su código acá\n",
        "\n",
        "# 1. separar datos en conjuntos train, val, test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size = 0.1, random_state = 42)\n",
        "train_data, val_data = train_test_split(train_data, test_size = 0.2222, random_state = 42)\n",
        "\n",
        "X_train, y_train = train_data.drop(columns=['quantity']), train_data['quantity']\n",
        "X_val, y_val = val_data.drop(columns=['quantity']), val_data['quantity']\n",
        "X_test, y_test = test_data.drop(columns=['quantity']), test_data['quantity']\n",
        "\n",
        "# 2. FuctionTransformer para extraer día, mes y año\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def extract_date_features(df):\n",
        "    df['day'] = df['date'].dt.day.astype('category')\n",
        "    df['month'] = df['date'].dt.month.astype('category')\n",
        "    df['year'] = df['date'].dt.year.astype('category')\n",
        "    return df\n",
        "\n",
        "date_transformer = FunctionTransformer(extract_date_features)\n",
        "\n",
        "# 3. ColumnTransformer para procesar datos numéricos y categóricos\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "categorical_features = ['day', 'month', 'year', 'city', 'shop', 'brand', 'container', 'capacity']  # se considera que date ya fue transformado, capacity lo dejamos acá porque solo puede ser '500ml', '1.5lt', '330ml'\n",
        "numerical_features = ['lat', 'long', 'pop', 'price']\n",
        "\n",
        "col_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4. guardar pasos anteriores en un pipeline incluyendo DummyRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "dummy_pipeline = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', col_transformer),\n",
        "    ('regressor', DummyRegressor(strategy='mean'))\n",
        "])\n",
        "\n",
        "# 5. entrenar el pipeline anterior y reportar la métrica `mean_absolute_error` sobre los datos de validación\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "dummy_pipeline.fit(X_train, y_train)\n",
        "\n",
        "val_predictions = dummy_pipeline.predict(X_val)\n",
        "mae_dummy = mean_absolute_error(y_val, val_predictions)\n",
        "print(f'MAE del DummyRegressor: {mae_dummy}')\n",
        "\n",
        "# 6. volver a entrenar pipeline con XGBRegressor y reportar la métrica `mean_absolute_error` sobre los datos de validación\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb_pipeline = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', col_transformer),\n",
        "    ('regressor', XGBRegressor(objective='reg:squarederror'))\n",
        "])\n",
        "\n",
        "xgb_pipeline.fit(X_train, y_train)\n",
        "val_predictions_xgb = xgb_pipeline.predict(X_val)\n",
        "mae_xgb = mean_absolute_error(y_val, val_predictions_xgb)\n",
        "print(f'MAE del XGBRegressor: {mae_xgb}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgb_pipeline.pkl']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. guardar ambos modelos\n",
        "import joblib\n",
        "\n",
        "joblib.dump(dummy_pipeline, 'dummy_pipeline.pkl')\n",
        "joblib.dump(xgb_pipeline, 'xgb_pipeline.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7e17e46063774ec28226fe300d42ffe0",
        "deepnote_cell_type": "markdown",
        "id": "wnyMINdKI5v_"
      },
      "source": [
        "## 2. Forzando relaciones entre parámetros con XGBoost (1.0 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
        "</p>\n",
        "\n",
        "Un colega aficionado a la economía le *sopla* que la demanda guarda una relación inversa con el precio del producto. Motivado para impresionar al querido corpóreo, se propone hacer uso de esta información para mejorar su modelo realizando las siguientes tareas:\n",
        "\n",
        "1. Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relación monótona negativa entre el precio y la cantidad. Para aplicar esta restricción apóyese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentación</a>. Hint: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser así, probablemente le sea útil **mantener el formato de pandas** antes del step de entrenamiento.\n",
        "\n",
        "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validación.\n",
        "\n",
        "3. ¿Cómo cambia el error al incluir esta relación? ¿Tenía razón su amigo?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.- El MAE obtenido en este caso es de 2519.22. Dado que este valor es un poco mayor que el obtenido anteriormente con xgboost sin la relación monótona, nuestro amigo nos sopló mal, pues nuestro modelo ahora tiene un error más grande."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE del XGBRegressor con restricción de monotonicidad: 2519.222899080682\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = train_data.drop(columns=['quantity']), train_data['quantity']\n",
        "X_val, y_val = val_data.drop(columns=['quantity']), val_data['quantity']\n",
        "X_test, y_test = test_data.drop(columns=['quantity']), test_data['quantity']\n",
        "\n",
        "\n",
        "# 1. entrenar nuevo pipeline con las restricciones de monotonicidad y que mantiene formato pandas hasta antes del step de entrenamiento\n",
        "def to_dataframe(X):\n",
        "    return pd.DataFrame(X.toarray(), columns=col_transformer.get_feature_names_out())\n",
        "\n",
        "pandas_transformer = FunctionTransformer(to_dataframe)\n",
        "\n",
        "xgb_pipeline_monotone = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', col_transformer),\n",
        "    ('pandas_transformer', pandas_transformer),\n",
        "    ('regressor', XGBRegressor(objective='reg:squarederror', monotone_constraints={'num__price': -1}))\n",
        "])\n",
        "\n",
        "xgb_pipeline_monotone.fit(X_train, y_train)\n",
        "\n",
        "# 2. reportar MAE sobre conjunto de validación\n",
        "val_predictions_xgb_monotone = xgb_pipeline_monotone.predict(X_val)\n",
        "mae_xgb_monotone = mean_absolute_error(y_val, val_predictions_xgb_monotone)\n",
        "print(f'MAE del XGBRegressor con restricción de monotonicidad: {mae_xgb_monotone}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e59ef80ed20b4de8921f24da74e87374",
        "deepnote_cell_type": "markdown",
        "id": "5D5-tX4dI5v_"
      },
      "source": [
        "## 3. Optimización de Hiperparámetros con Optuna (2.0 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
        "</p>\n",
        "\n",
        "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun más* su modelo. En particular, le comenta de la optimización de hiperparámetros con metodologías bayesianas a través del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
        "\n",
        "A partir de la mejor configuración obtenida en la sección anterior, utilice `optuna` para optimizar sus hiperparámetros. En particular, se le pide:\n",
        "\n",
        "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
        "- Utilice `TPESampler` como método de muestreo\n",
        "- De `XGBRegressor`, optimice los siguientes hiperparámetros:\n",
        "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
        "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
        "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
        "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
        "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
        "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
        "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
        "- De `OneHotEncoder`, optimice el hiperparámetro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
        "- Explique cada hiperparámetro y su rol en el modelo. ¿Hacen sentido los rangos de optimización indicados?\n",
        "- Fije el tiempo de entrenamiento a 5 minutos\n",
        "- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n",
        "- Guardar su modelo en un archivo .pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación se explica cada hiperparámetro:\n",
        "\n",
        "1. `learning_rate:` Controla la tasa de aprendizaje del modelo. Un valor más bajo puede hacer que el modelo aprenda más lentamente, pero podría mejorar la precisión. Los valores entre 0.001 y 0.1 son comunes y razonables. Un learning_rate muy bajo (cerca de 0.001) permite ajustes muy precisos, pero puede requerir más iteraciones, mientras que valores cercanos a 0.1 permiten un aprendizaje más rápido. Valores fuera de este rango podrían resultar en un aprendizaje demasiado lento o demasiado rápido, causando overfitting o underfitting, respectivamente.\n",
        "\n",
        "2. `n_estimators:` Número de árboles en el modelo. Más árboles pueden aumentar la capacidad del modelo, pero también el riesgo de overfitting. El rango de 50 a 1000 es apropiado, pues menos de 50 árboles pueden no ser suficientes para captar la complejidad del modelo, mientras que más de 1000 pueden causar overfitting y aumentar demasiado el tiempo de cómputo sin que esto implique mejores resultados.\n",
        "\n",
        "3. `max_depth:` Profundidad máxima de los árboles. Controla la complejidad de cada árbol. Un rango de 3 a 10 es razonable, ya que valores por debajo de 3 pueden hacer que los árboles sean demasiado simples para captar patrones complejos, mientras valores superiores a 10 pueden hacer que los árboles se vuelvan demasiado complejos y produzcan overfitting.\n",
        "\n",
        "4. `max_leaves:` Número máximo de hojas por árbol. Permite controlar la complejidad de cada árbol, pero de una manera un poco más directa que max_depth. El rango de 0 a 100 es amplio y flexible, permitir hasta 100 hojas proporciona suficiente capacidad para captar patrones complejos sin sobreajustar en la mayoría de los casos.\n",
        "\n",
        "5. `min_child_weight:` Peso mínimo que debe tener una hoja. Ayuda a evitar que el modelo cree hojas con muy pocos datos. El rango de 1 a 5 es adecuado, ya que un valor más bajo (1) permite mayor flexibilidad para crear hojas pequeñas, mientras que un valor más alto (hasta 5) fuerza al modelo a tener hojas con mayor número de ejemplos, lo que puede ayudar a evitar el overfitting.\n",
        "\n",
        "6. `reg_alpha:` Regularización L1. Ayuda a hacer que el modelo sea más sencillo y puede ayudar a prevenir el overfitting. Un rango de 0 a 1 es común y sensato, ya que valores cercanos a 0 significan poca regularización, mientras que valores cercanos a 1 implican una fuerte regularización. Esto permite explorar desde ningún efecto de regularización hasta una regularización fuerte.\n",
        "\n",
        "7. `reg_lambda:` Regularización L2. Similar a reg_alpha, pero penaliza el tamaño de los coeficientes del modelo. Similar a reg_alpha, un rango de 0 a 1 es apropiado, ya que permite explorar desde ningún efecto de regularización hasta una regularización fuerte.\n",
        "\n",
        "8. `min_frequency:` n el OneHotEncoder, este parámetro ayuda a ignorar categorías poco frecuentes para evitar ruido en los datos categóricos. El rango de 0.0 a 1.0 es correcto, ya que cubre desde no ignorar ninguna categoría (0.0) hasta ignorar todas las categorías (1.0). \n",
        "\n",
        "En cuanto al número de trials, se tienen 196, y con los mejores hiperparámetros el MAE es de 1922.33. Considerando que el MAE del mejor modelo anterior es de 2391.15, se tiene que los resultados luego de hiperparámetros mejoran bastante.\n",
        "\n",
        "Lo anterior se puede deber a una combinación de ajustes precisos en los distintos hiperparámetros abordados. La metodología de búsqueda bayesiana, sumada a los rangos de valores escogidos que nos permiten la exploración suficiente del espacio de hiperparámetros, encuentran una configuración que optimiza el rendimiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
        "deepnote_cell_type": "code",
        "id": "kMXXi1ckI5v_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-29 21:37:29,731] A new study created in memory with name: no-name-7f555541-1457-4c45-bea1-8ed6fbd0eab1\n",
            "[I 2024-05-29 21:37:31,324] Trial 0 finished with value: 9749.174034768506 and parameters: {'learning_rate': 0.03807947176588889, 'n_estimators': 954, 'max_depth': 8, 'max_leaves': 60, 'min_child_weight': 1, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'min_frequency': 0.8661761457749352}. Best is trial 0 with value: 9749.174034768506.\n",
            "[I 2024-05-29 21:37:31,915] Trial 1 finished with value: 5757.241405136549 and parameters: {'learning_rate': 0.06051038616257767, 'n_estimators': 723, 'max_depth': 3, 'max_leaves': 97, 'min_child_weight': 5, 'reg_alpha': 0.21233911067827616, 'reg_lambda': 0.18182496720710062, 'min_frequency': 0.18340450985343382}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:32,689] Trial 2 finished with value: 8966.786244812625 and parameters: {'learning_rate': 0.03111998205299424, 'n_estimators': 549, 'max_depth': 6, 'max_leaves': 29, 'min_child_weight': 4, 'reg_alpha': 0.13949386065204183, 'reg_lambda': 0.29214464853521815, 'min_frequency': 0.3663618432936917}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:33,427] Trial 3 finished with value: 5813.638579851505 and parameters: {'learning_rate': 0.04615092843748656, 'n_estimators': 796, 'max_depth': 4, 'max_leaves': 51, 'min_child_weight': 3, 'reg_alpha': 0.046450412719997725, 'reg_lambda': 0.6075448519014384, 'min_frequency': 0.17052412368729153}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:34,985] Trial 4 finished with value: 9034.394314454436 and parameters: {'learning_rate': 0.0074401077055426725, 'n_estimators': 952, 'max_depth': 10, 'max_leaves': 81, 'min_child_weight': 2, 'reg_alpha': 0.09767211400638387, 'reg_lambda': 0.6842330265121569, 'min_frequency': 0.4401524937396013}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:35,353] Trial 5 finished with value: 8707.184649891537 and parameters: {'learning_rate': 0.013081785249633104, 'n_estimators': 520, 'max_depth': 3, 'max_leaves': 91, 'min_child_weight': 2, 'reg_alpha': 0.662522284353982, 'reg_lambda': 0.31171107608941095, 'min_frequency': 0.5200680211778108}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:35,890] Trial 6 finished with value: 9184.023770553005 and parameters: {'learning_rate': 0.05512431765498469, 'n_estimators': 225, 'max_depth': 10, 'max_leaves': 78, 'min_child_weight': 5, 'reg_alpha': 0.8948273504276488, 'reg_lambda': 0.5978999788110851, 'min_frequency': 0.9218742350231168}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:36,130] Trial 7 finished with value: 9166.99227461121 and parameters: {'learning_rate': 0.00976075770314003, 'n_estimators': 236, 'max_depth': 3, 'max_leaves': 32, 'min_child_weight': 2, 'reg_alpha': 0.2713490317738959, 'reg_lambda': 0.8287375091519293, 'min_frequency': 0.3567533266935893}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:36,615] Trial 8 finished with value: 5698.762707183859 and parameters: {'learning_rate': 0.028812516459050697, 'n_estimators': 566, 'max_depth': 4, 'max_leaves': 81, 'min_child_weight': 1, 'reg_alpha': 0.9868869366005173, 'reg_lambda': 0.7722447692966574, 'min_frequency': 0.1987156815341724}. Best is trial 8 with value: 5698.762707183859.\n",
            "[I 2024-05-29 21:37:38,113] Trial 9 finished with value: 7506.077063946177 and parameters: {'learning_rate': 0.0015466895952366377, 'n_estimators': 825, 'max_depth': 8, 'max_leaves': 73, 'min_child_weight': 4, 'reg_alpha': 0.07404465173409036, 'reg_lambda': 0.3584657285442726, 'min_frequency': 0.11586905952512971}. Best is trial 8 with value: 5698.762707183859.\n",
            "[I 2024-05-29 21:37:38,393] Trial 10 finished with value: 13546.494419642857 and parameters: {'learning_rate': 0.0945685178788083, 'n_estimators': 55, 'max_depth': 5, 'max_leaves': 1, 'min_child_weight': 1, 'reg_alpha': 0.907664795282518, 'reg_lambda': 0.9657999152312998, 'min_frequency': 0.6764178475687505}. Best is trial 8 with value: 5698.762707183859.\n",
            "[I 2024-05-29 21:37:39,187] Trial 11 finished with value: 2304.2935717331334 and parameters: {'learning_rate': 0.07472142904562282, 'n_estimators': 574, 'max_depth': 5, 'max_leaves': 95, 'min_child_weight': 5, 'reg_alpha': 0.4343562717564112, 'reg_lambda': 0.06782026776262084, 'min_frequency': 0.022779612782324016}. Best is trial 11 with value: 2304.2935717331334.\n",
            "[I 2024-05-29 21:37:39,915] Trial 12 finished with value: 2268.563423919166 and parameters: {'learning_rate': 0.07559807824175671, 'n_estimators': 533, 'max_depth': 5, 'max_leaves': 97, 'min_child_weight': 4, 'reg_alpha': 0.4473531654099191, 'reg_lambda': 0.7856239838024551, 'min_frequency': 0.05035180753379226}. Best is trial 12 with value: 2268.563423919166.\n",
            "[I 2024-05-29 21:37:40,703] Trial 13 finished with value: 2217.55814591324 and parameters: {'learning_rate': 0.07742047722562706, 'n_estimators': 387, 'max_depth': 6, 'max_leaves': 100, 'min_child_weight': 4, 'reg_alpha': 0.44784472747300386, 'reg_lambda': 0.4381301674911344, 'min_frequency': 0.004520026322682995}. Best is trial 13 with value: 2217.55814591324.\n",
            "[I 2024-05-29 21:37:41,617] Trial 14 finished with value: 2087.52391038942 and parameters: {'learning_rate': 0.08295842385492615, 'n_estimators': 382, 'max_depth': 7, 'max_leaves': 100, 'min_child_weight': 4, 'reg_alpha': 0.524280384813821, 'reg_lambda': 0.4621147584011281, 'min_frequency': 0.0016622958476193933}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:42,609] Trial 15 finished with value: 2166.233968917673 and parameters: {'learning_rate': 0.099902158307922, 'n_estimators': 360, 'max_depth': 7, 'max_leaves': 63, 'min_child_weight': 3, 'reg_alpha': 0.6144093625372589, 'reg_lambda': 0.48011047785603345, 'min_frequency': 0.0024139568548372237}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:43,394] Trial 16 finished with value: 7048.5132713599305 and parameters: {'learning_rate': 0.09459357199463239, 'n_estimators': 350, 'max_depth': 8, 'max_leaves': 64, 'min_child_weight': 3, 'reg_alpha': 0.6544691128072077, 'reg_lambda': 0.46361027315685355, 'min_frequency': 0.2815897372059905}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:43,949] Trial 17 finished with value: 9283.68126860119 and parameters: {'learning_rate': 0.09919695494893246, 'n_estimators': 376, 'max_depth': 7, 'max_leaves': 31, 'min_child_weight': 3, 'reg_alpha': 0.6635226910976346, 'reg_lambda': 0.5409495149359591, 'min_frequency': 0.5996408444196241}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:44,223] Trial 18 finished with value: 8902.246728089893 and parameters: {'learning_rate': 0.08503354756578933, 'n_estimators': 72, 'max_depth': 7, 'max_leaves': 43, 'min_child_weight': 4, 'reg_alpha': 0.5682926483932309, 'reg_lambda': 0.17163146637436183, 'min_frequency': 0.791175131433183}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:44,467] Trial 19 finished with value: 6653.472352466033 and parameters: {'learning_rate': 0.06463966796978622, 'n_estimators': 239, 'max_depth': 9, 'max_leaves': 4, 'min_child_weight': 3, 'reg_alpha': 0.30945242808634793, 'reg_lambda': 0.4069095432478356, 'min_frequency': 0.3027316230161766}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:45,073] Trial 20 finished with value: 5829.693570971729 and parameters: {'learning_rate': 0.08543365227872257, 'n_estimators': 434, 'max_depth': 9, 'max_leaves': 20, 'min_child_weight': 3, 'reg_alpha': 0.7790645407184047, 'reg_lambda': 0.2523130069952787, 'min_frequency': 0.09937023920664073}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:45,800] Trial 21 finished with value: 2245.687583836351 and parameters: {'learning_rate': 0.0838131655561784, 'n_estimators': 320, 'max_depth': 6, 'max_leaves': 85, 'min_child_weight': 4, 'reg_alpha': 0.5299828818840583, 'reg_lambda': 0.47309386330307196, 'min_frequency': 0.05060382715532571}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:46,622] Trial 22 finished with value: 2109.958327274847 and parameters: {'learning_rate': 0.07270225304055998, 'n_estimators': 449, 'max_depth': 7, 'max_leaves': 69, 'min_child_weight': 4, 'reg_alpha': 0.37088901906588323, 'reg_lambda': 0.42382979514400526, 'min_frequency': 0.0002380543151967087}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:47,305] Trial 23 finished with value: 6880.960851534991 and parameters: {'learning_rate': 0.06345749401645846, 'n_estimators': 445, 'max_depth': 7, 'max_leaves': 66, 'min_child_weight': 5, 'reg_alpha': 0.3383476804320819, 'reg_lambda': 0.5215755161080551, 'min_frequency': 0.2463819135552211}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:47,689] Trial 24 finished with value: 5753.984241058329 and parameters: {'learning_rate': 0.06921508824921373, 'n_estimators': 144, 'max_depth': 7, 'max_leaves': 54, 'min_child_weight': 4, 'reg_alpha': 0.5863503466690212, 'reg_lambda': 0.6405301333656301, 'min_frequency': 0.11598471181112427}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:48,933] Trial 25 finished with value: 2081.1913168463907 and parameters: {'learning_rate': 0.09047951831461229, 'n_estimators': 658, 'max_depth': 8, 'max_leaves': 71, 'min_child_weight': 3, 'reg_alpha': 0.3836728428695413, 'reg_lambda': 0.3819996117906489, 'min_frequency': 0.0009887216450606285}. Best is trial 25 with value: 2081.1913168463907.\n",
            "[I 2024-05-29 21:37:50,151] Trial 26 finished with value: 6553.7847711267605 and parameters: {'learning_rate': 0.08977105251557031, 'n_estimators': 705, 'max_depth': 9, 'max_leaves': 72, 'min_child_weight': 2, 'reg_alpha': 0.3811470757712544, 'reg_lambda': 0.20031693221569855, 'min_frequency': 0.12800469789111604}. Best is trial 25 with value: 2081.1913168463907.\n",
            "[I 2024-05-29 21:37:50,997] Trial 27 finished with value: 7073.327880204403 and parameters: {'learning_rate': 0.07114653764310133, 'n_estimators': 650, 'max_depth': 8, 'max_leaves': 42, 'min_child_weight': 4, 'reg_alpha': 0.22731375258208175, 'reg_lambda': 0.3757058963115211, 'min_frequency': 0.25753460623234187}. Best is trial 25 with value: 2081.1913168463907.\n",
            "[I 2024-05-29 21:37:51,954] Trial 28 finished with value: 2042.3670024705525 and parameters: {'learning_rate': 0.08043082865713093, 'n_estimators': 471, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.38105833488850255, 'reg_lambda': 0.3463081592628539, 'min_frequency': 0.07751617886057621}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:53,122] Trial 29 finished with value: 6239.520148560635 and parameters: {'learning_rate': 0.04948537425244419, 'n_estimators': 620, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.5011429354099811, 'reg_lambda': 0.3286432524207901, 'min_frequency': 0.0931266982717998}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:54,495] Trial 30 finished with value: 6647.133102897987 and parameters: {'learning_rate': 0.07960508430434043, 'n_estimators': 882, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 2, 'reg_alpha': 0.19562692990337233, 'reg_lambda': 0.042745180079641565, 'min_frequency': 0.18040407322174376}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:55,281] Trial 31 finished with value: 2063.34984581971 and parameters: {'learning_rate': 0.09005109191357132, 'n_estimators': 444, 'max_depth': 8, 'max_leaves': 72, 'min_child_weight': 3, 'reg_alpha': 0.3777294647782796, 'reg_lambda': 0.3929442711647019, 'min_frequency': 0.06641644780200913}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:56,172] Trial 32 finished with value: 2036.3781592550092 and parameters: {'learning_rate': 0.09236604994325416, 'n_estimators': 487, 'max_depth': 8, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.4129883901450435, 'reg_lambda': 0.2733707317865236, 'min_frequency': 0.07310172100167087}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:56,907] Trial 33 finished with value: 7231.864807845282 and parameters: {'learning_rate': 0.09125751002385779, 'n_estimators': 488, 'max_depth': 9, 'max_leaves': 57, 'min_child_weight': 3, 'reg_alpha': 0.28900323808542494, 'reg_lambda': 0.11982927019994927, 'min_frequency': 0.2077401109083835}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:58,170] Trial 34 finished with value: 6530.301446046068 and parameters: {'learning_rate': 0.09003245707053742, 'n_estimators': 670, 'max_depth': 8, 'max_leaves': 76, 'min_child_weight': 2, 'reg_alpha': 0.40694439804792026, 'reg_lambda': 0.24918193472640549, 'min_frequency': 0.14737619001712438}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:59,250] Trial 35 finished with value: 9543.702605607605 and parameters: {'learning_rate': 0.0388049209169903, 'n_estimators': 728, 'max_depth': 10, 'max_leaves': 60, 'min_child_weight': 3, 'reg_alpha': 0.005458575377312869, 'reg_lambda': 0.2646692310007239, 'min_frequency': 0.3844960575953111}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:59,891] Trial 36 finished with value: 7134.923806019712 and parameters: {'learning_rate': 0.09412242099201551, 'n_estimators': 302, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.15902710124239258, 'reg_lambda': 0.19872722167220735, 'min_frequency': 0.32256308394755967}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:00,958] Trial 37 finished with value: 7079.195162020299 and parameters: {'learning_rate': 0.05556809463606735, 'n_estimators': 611, 'max_depth': 8, 'max_leaves': 78, 'min_child_weight': 2, 'reg_alpha': 0.2541360123838059, 'reg_lambda': 0.36970088351585706, 'min_frequency': 0.2326502163093811}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:01,871] Trial 38 finished with value: 2174.7841451377535 and parameters: {'learning_rate': 0.08036969527994621, 'n_estimators': 490, 'max_depth': 9, 'max_leaves': 71, 'min_child_weight': 2, 'reg_alpha': 0.3637618068585596, 'reg_lambda': 0.2983455152049972, 'min_frequency': 0.08056721651301402}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:02,782] Trial 39 finished with value: 9799.725359972334 and parameters: {'learning_rate': 0.08801279809336786, 'n_estimators': 737, 'max_depth': 10, 'max_leaves': 47, 'min_child_weight': 3, 'reg_alpha': 0.4521287306387438, 'reg_lambda': 0.5810106362207283, 'min_frequency': 0.44029982330249195}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:04,223] Trial 40 finished with value: 6759.413233797315 and parameters: {'learning_rate': 0.09813084012584607, 'n_estimators': 789, 'max_depth': 9, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.32288296985868986, 'reg_lambda': 0.12677254593379284, 'min_frequency': 0.164396436309788}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:05,183] Trial 41 finished with value: 2125.5748830548396 and parameters: {'learning_rate': 0.08537209248815977, 'n_estimators': 426, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.492988510754365, 'reg_lambda': 0.33233759918174444, 'min_frequency': 0.054316673448236555}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:06,111] Trial 42 finished with value: 2082.201794097921 and parameters: {'learning_rate': 0.08117269065852861, 'n_estimators': 512, 'max_depth': 7, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5393279416115107, 'reg_lambda': 0.4072535296981334, 'min_frequency': 0.06937991567617773}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:06,783] Trial 43 finished with value: 9475.287877656565 and parameters: {'learning_rate': 0.06780297905091535, 'n_estimators': 503, 'max_depth': 6, 'max_leaves': 94, 'min_child_weight': 2, 'reg_alpha': 0.38842473952888223, 'reg_lambda': 0.41422080662122557, 'min_frequency': 0.9927304376988992}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:07,954] Trial 44 finished with value: 2325.4433131995097 and parameters: {'learning_rate': 0.02167295234709339, 'n_estimators': 585, 'max_depth': 8, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.4799628535883345, 'reg_lambda': 0.3716804862512477, 'min_frequency': 0.07344304973974128}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:08,816] Trial 45 finished with value: 6236.412017024019 and parameters: {'learning_rate': 0.0786099617970131, 'n_estimators': 528, 'max_depth': 7, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.5574701216639798, 'reg_lambda': 0.5496900151019826, 'min_frequency': 0.15112571345808007}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:09,545] Trial 46 finished with value: 7153.106282470212 and parameters: {'learning_rate': 0.09326831550198958, 'n_estimators': 553, 'max_depth': 6, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.41882218261444876, 'reg_lambda': 0.28230272214290525, 'min_frequency': 0.21044204340310685}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:10,527] Trial 47 finished with value: 2119.772840165996 and parameters: {'learning_rate': 0.0881538379640335, 'n_estimators': 472, 'max_depth': 8, 'max_leaves': 78, 'min_child_weight': 3, 'reg_alpha': 0.7386239719822634, 'reg_lambda': 0.229204793096295, 'min_frequency': 0.04874314891344802}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:11,270] Trial 48 finished with value: 9377.18690856074 and parameters: {'learning_rate': 0.056143119319426095, 'n_estimators': 412, 'max_depth': 7, 'max_leaves': 68, 'min_child_weight': 2, 'reg_alpha': 0.2562335562084859, 'reg_lambda': 0.33270777474019286, 'min_frequency': 0.7608742277359258}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:11,912] Trial 49 finished with value: 9600.43947473906 and parameters: {'learning_rate': 0.09589952761758018, 'n_estimators': 305, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 3, 'reg_alpha': 0.12788584175674295, 'reg_lambda': 0.6919198144499181, 'min_frequency': 0.5616787381338312}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:13,866] Trial 50 finished with value: 6559.497377330388 and parameters: {'learning_rate': 0.07501455601231649, 'n_estimators': 989, 'max_depth': 8, 'max_leaves': 74, 'min_child_weight': 2, 'reg_alpha': 0.33019539142416515, 'reg_lambda': 0.4970847321573678, 'min_frequency': 0.12009933186108918}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:14,738] Trial 51 finished with value: 2120.742726214055 and parameters: {'learning_rate': 0.07953636476648202, 'n_estimators': 402, 'max_depth': 7, 'max_leaves': 98, 'min_child_weight': 4, 'reg_alpha': 0.5259430717989301, 'reg_lambda': 0.40480385091450066, 'min_frequency': 0.03838667561677165}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:15,337] Trial 52 finished with value: 2242.384755145456 and parameters: {'learning_rate': 0.0826355887373552, 'n_estimators': 340, 'max_depth': 6, 'max_leaves': 94, 'min_child_weight': 5, 'reg_alpha': 0.623888775356082, 'reg_lambda': 0.46396621052730425, 'min_frequency': 0.0077010695879077}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:16,398] Trial 53 finished with value: 6283.1029313904255 and parameters: {'learning_rate': 0.08296266262220331, 'n_estimators': 589, 'max_depth': 7, 'max_leaves': 99, 'min_child_weight': 4, 'reg_alpha': 0.445530492147152, 'reg_lambda': 0.4349208161062156, 'min_frequency': 0.10362799093261617}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:17,066] Trial 54 finished with value: 2125.622426289508 and parameters: {'learning_rate': 0.08712662059878402, 'n_estimators': 269, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.7109256549544944, 'reg_lambda': 0.3003397830695185, 'min_frequency': 0.07325358064105013}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:17,972] Trial 55 finished with value: 6387.3485163913165 and parameters: {'learning_rate': 0.09684874518391791, 'n_estimators': 523, 'max_depth': 7, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5374629542134307, 'reg_lambda': 0.5130691311769847, 'min_frequency': 0.1697920835341144}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:18,902] Trial 56 finished with value: 2031.3380058999833 and parameters: {'learning_rate': 0.09279435339347142, 'n_estimators': 462, 'max_depth': 8, 'max_leaves': 85, 'min_child_weight': 4, 'reg_alpha': 0.47245164716996413, 'reg_lambda': 0.37856132458784153, 'min_frequency': 0.04055017228450605}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:19,880] Trial 57 finished with value: 2065.795437173824 and parameters: {'learning_rate': 0.09123411084184559, 'n_estimators': 472, 'max_depth': 8, 'max_leaves': 62, 'min_child_weight': 3, 'reg_alpha': 0.472753223372882, 'reg_lambda': 0.9881136084991532, 'min_frequency': 0.04399680690664873}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:20,725] Trial 58 finished with value: 2087.3268297938675 and parameters: {'learning_rate': 0.09132864312410234, 'n_estimators': 460, 'max_depth': 8, 'max_leaves': 65, 'min_child_weight': 4, 'reg_alpha': 0.48359886258678625, 'reg_lambda': 0.9400927133746524, 'min_frequency': 0.023220957866065366}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:21,857] Trial 59 finished with value: 6438.524085921781 and parameters: {'learning_rate': 0.09953570616398587, 'n_estimators': 651, 'max_depth': 9, 'max_leaves': 61, 'min_child_weight': 1, 'reg_alpha': 0.41453105910938415, 'reg_lambda': 0.8837027014251868, 'min_frequency': 0.13351201821409714}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:22,801] Trial 60 finished with value: 2112.7533187405684 and parameters: {'learning_rate': 0.09303067158226795, 'n_estimators': 563, 'max_depth': 10, 'max_leaves': 55, 'min_child_weight': 4, 'reg_alpha': 0.357476628774539, 'reg_lambda': 0.6788463848380946, 'min_frequency': 0.03071085487132868}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:23,780] Trial 61 finished with value: 2056.4919063534853 and parameters: {'learning_rate': 0.0894896443323035, 'n_estimators': 506, 'max_depth': 8, 'max_leaves': 70, 'min_child_weight': 3, 'reg_alpha': 0.4697064045949561, 'reg_lambda': 0.3322567309504248, 'min_frequency': 0.07706163153124948}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:24,718] Trial 62 finished with value: 6310.319110627305 and parameters: {'learning_rate': 0.08809984180902583, 'n_estimators': 466, 'max_depth': 8, 'max_leaves': 69, 'min_child_weight': 3, 'reg_alpha': 0.4628066038283119, 'reg_lambda': 0.3597603018248962, 'min_frequency': 0.10624989252139087}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:25,564] Trial 63 finished with value: 2105.5414343155285 and parameters: {'learning_rate': 0.09614206577455721, 'n_estimators': 405, 'max_depth': 8, 'max_leaves': 79, 'min_child_weight': 3, 'reg_alpha': 0.4126119951156862, 'reg_lambda': 0.2243578762266409, 'min_frequency': 0.04120260687851207}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:26,376] Trial 64 finished with value: 6262.740335568096 and parameters: {'learning_rate': 0.0914279127677374, 'n_estimators': 383, 'max_depth': 9, 'max_leaves': 73, 'min_child_weight': 3, 'reg_alpha': 0.28478867023745247, 'reg_lambda': 0.15277460439609067, 'min_frequency': 0.18960605454476484}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:26,945] Trial 65 finished with value: 2499.4891450755313 and parameters: {'learning_rate': 0.0769868510494625, 'n_estimators': 545, 'max_depth': 4, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.5866446987580349, 'reg_lambda': 0.33144251340102776, 'min_frequency': 0.0006014771058407281}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:27,943] Trial 66 finished with value: 2223.2390562450223 and parameters: {'learning_rate': 0.04045549186463308, 'n_estimators': 490, 'max_depth': 8, 'max_leaves': 67, 'min_child_weight': 3, 'reg_alpha': 0.3875249319777445, 'reg_lambda': 0.9985364655754747, 'min_frequency': 0.07975506497847659}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:28,956] Trial 67 finished with value: 10069.630498813192 and parameters: {'learning_rate': 0.08636505002835773, 'n_estimators': 618, 'max_depth': 9, 'max_leaves': 72, 'min_child_weight': 3, 'reg_alpha': 0.3517384291504589, 'reg_lambda': 0.26911544180604424, 'min_frequency': 0.6452518464743974}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:29,756] Trial 68 finished with value: 6141.98176837719 and parameters: {'learning_rate': 0.09441494039865712, 'n_estimators': 357, 'max_depth': 8, 'max_leaves': 61, 'min_child_weight': 4, 'reg_alpha': 0.5029664598173147, 'reg_lambda': 0.38120593770312755, 'min_frequency': 0.10173989081577614}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:30,181] Trial 69 finished with value: 5755.818461796168 and parameters: {'learning_rate': 0.09988889724342617, 'n_estimators': 440, 'max_depth': 3, 'max_leaves': 52, 'min_child_weight': 5, 'reg_alpha': 0.42789505951032647, 'reg_lambda': 0.788450240837348, 'min_frequency': 0.13826562102483805}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:30,936] Trial 70 finished with value: 7108.812037017024 and parameters: {'learning_rate': 0.08994753942368602, 'n_estimators': 434, 'max_depth': 8, 'max_leaves': 57, 'min_child_weight': 3, 'reg_alpha': 0.29313694737614865, 'reg_lambda': 0.44030912304679415, 'min_frequency': 0.28389844746094306}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:32,006] Trial 71 finished with value: 2088.517171387701 and parameters: {'learning_rate': 0.08207063154719685, 'n_estimators': 508, 'max_depth': 7, 'max_leaves': 64, 'min_child_weight': 3, 'reg_alpha': 0.4676376602548536, 'reg_lambda': 0.40049395732868176, 'min_frequency': 0.06313642440917713}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:33,270] Trial 72 finished with value: 2007.251881733107 and parameters: {'learning_rate': 0.0850325610067192, 'n_estimators': 530, 'max_depth': 8, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.5405698128762041, 'reg_lambda': 0.30312820042416544, 'min_frequency': 0.07084571662946766}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:34,551] Trial 73 finished with value: 2019.2545754671257 and parameters: {'learning_rate': 0.08514861390206259, 'n_estimators': 685, 'max_depth': 8, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.5056315299092229, 'reg_lambda': 0.31210666777631074, 'min_frequency': 0.03279112164846229}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:36,231] Trial 74 finished with value: 2019.902726744582 and parameters: {'learning_rate': 0.0844170367327648, 'n_estimators': 843, 'max_depth': 8, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.6090322516408901, 'reg_lambda': 0.3123797454345109, 'min_frequency': 0.03731121883067844}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:37,694] Trial 75 finished with value: 7655.664279930069 and parameters: {'learning_rate': 0.08428493658414868, 'n_estimators': 820, 'max_depth': 9, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.6192313956439035, 'reg_lambda': 0.3117509538812796, 'min_frequency': 0.22829658766822672}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:39,390] Trial 76 finished with value: 6658.028704535153 and parameters: {'learning_rate': 0.0859005335598063, 'n_estimators': 895, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.5863847334948917, 'reg_lambda': 0.3358638256741392, 'min_frequency': 0.09414125442259928}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:41,019] Trial 77 finished with value: 6442.831482875115 and parameters: {'learning_rate': 0.07480988884193172, 'n_estimators': 752, 'max_depth': 8, 'max_leaves': 84, 'min_child_weight': 2, 'reg_alpha': 0.65537579948844, 'reg_lambda': 0.23523730875811633, 'min_frequency': 0.1534565562730366}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:42,372] Trial 78 finished with value: 6452.207627929032 and parameters: {'learning_rate': 0.07299704719922265, 'n_estimators': 708, 'max_depth': 9, 'max_leaves': 80, 'min_child_weight': 4, 'reg_alpha': 0.8274676899026039, 'reg_lambda': 0.28016991654118534, 'min_frequency': 0.12505546793623346}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:43,736] Trial 79 finished with value: 6598.280958210199 and parameters: {'learning_rate': 0.07073050822657093, 'n_estimators': 891, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.5636237258722232, 'reg_lambda': 0.18803976247415466, 'min_frequency': 0.1779091488629827}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:45,006] Trial 80 finished with value: 1990.4285711010857 and parameters: {'learning_rate': 0.07798717411126144, 'n_estimators': 778, 'max_depth': 8, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.6297449149174699, 'reg_lambda': 0.35211083877103205, 'min_frequency': 0.028152836171907336}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:46,661] Trial 81 finished with value: 2026.403295587326 and parameters: {'learning_rate': 0.06711232445886121, 'n_estimators': 787, 'max_depth': 8, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.694277992323062, 'reg_lambda': 0.3542111263218868, 'min_frequency': 0.030665228498072794}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:48,294] Trial 82 finished with value: 2022.4141921843561 and parameters: {'learning_rate': 0.06624784192742358, 'n_estimators': 865, 'max_depth': 8, 'max_leaves': 78, 'min_child_weight': 3, 'reg_alpha': 0.6872351138144958, 'reg_lambda': 0.3456898249320064, 'min_frequency': 0.027465261933340472}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:50,085] Trial 83 finished with value: 2064.75456318641 and parameters: {'learning_rate': 0.06521024181915175, 'n_estimators': 860, 'max_depth': 8, 'max_leaves': 75, 'min_child_weight': 3, 'reg_alpha': 0.696076148768955, 'reg_lambda': 0.30950430440804033, 'min_frequency': 0.022075165506829343}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:51,768] Trial 84 finished with value: 2048.8742528412663 and parameters: {'learning_rate': 0.05781240986986408, 'n_estimators': 805, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 3, 'reg_alpha': 0.7676434894721719, 'reg_lambda': 0.2556565261876471, 'min_frequency': 0.02319623038874431}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:53,202] Trial 85 finished with value: 2076.448151146462 and parameters: {'learning_rate': 0.06072397178471906, 'n_estimators': 767, 'max_depth': 7, 'max_leaves': 77, 'min_child_weight': 3, 'reg_alpha': 0.6745463028684944, 'reg_lambda': 0.21735332944594093, 'min_frequency': 0.052717610437092055}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:55,420] Trial 86 finished with value: 2016.49510523427 and parameters: {'learning_rate': 0.049847781566672494, 'n_estimators': 929, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.6017900449544757, 'reg_lambda': 0.36292875263902014, 'min_frequency': 0.023795757084424368}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:56,380] Trial 87 finished with value: 2276.89315073383 and parameters: {'learning_rate': 0.04589776825733551, 'n_estimators': 931, 'max_depth': 7, 'max_leaves': 23, 'min_child_weight': 3, 'reg_alpha': 0.6401606393401804, 'reg_lambda': 0.3636804519828505, 'min_frequency': 0.02756081352874301}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:57,267] Trial 88 finished with value: 2156.5980988469883 and parameters: {'learning_rate': 0.06616318301700963, 'n_estimators': 849, 'max_depth': 5, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.688850252227489, 'reg_lambda': 0.2903946728618221, 'min_frequency': 0.0011586018163942113}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:58,898] Trial 89 finished with value: 10066.685615647008 and parameters: {'learning_rate': 0.05159828016159543, 'n_estimators': 935, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.8094079010657278, 'reg_lambda': 0.35156617321972905, 'min_frequency': 0.4448139829440017}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:00,638] Trial 90 finished with value: 6466.851437564187 and parameters: {'learning_rate': 0.06121071553619703, 'n_estimators': 840, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 2, 'reg_alpha': 0.6028174737235105, 'reg_lambda': 0.4387900806666756, 'min_frequency': 0.09555381548829434}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:02,294] Trial 91 finished with value: 2041.2966221810027 and parameters: {'learning_rate': 0.07722809254738305, 'n_estimators': 790, 'max_depth': 8, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.7311116684266322, 'reg_lambda': 0.3120826043218728, 'min_frequency': 0.06219334176018328}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:04,028] Trial 92 finished with value: 2055.9212860168827 and parameters: {'learning_rate': 0.05151130897595823, 'n_estimators': 790, 'max_depth': 8, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.7148222097858561, 'reg_lambda': 0.3105018282294275, 'min_frequency': 0.055415045548170665}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:05,372] Trial 93 finished with value: 2118.458344140363 and parameters: {'learning_rate': 0.04681838496690633, 'n_estimators': 688, 'max_depth': 8, 'max_leaves': 80, 'min_child_weight': 3, 'reg_alpha': 0.7671430923098126, 'reg_lambda': 0.2535822969220564, 'min_frequency': 0.02596711927216669}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:06,974] Trial 94 finished with value: 6570.348897584727 and parameters: {'learning_rate': 0.0772564407818643, 'n_estimators': 871, 'max_depth': 8, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.7267573392624119, 'reg_lambda': 0.27607917016087236, 'min_frequency': 0.12422574150594712}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:08,881] Trial 95 finished with value: 2029.5752863535379 and parameters: {'learning_rate': 0.06920981188555539, 'n_estimators': 761, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.6482419176662041, 'reg_lambda': 0.3842066185351492, 'min_frequency': 0.056732650242521436}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:10,335] Trial 96 finished with value: 5713.017277493083 and parameters: {'learning_rate': 0.0693442470893889, 'n_estimators': 766, 'max_depth': 7, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.6368571054349889, 'reg_lambda': 0.3896887127148943, 'min_frequency': 0.08479164845170432}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:12,190] Trial 97 finished with value: 2036.5221706213845 and parameters: {'learning_rate': 0.07336700108454694, 'n_estimators': 932, 'max_depth': 8, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.5544711543121293, 'reg_lambda': 0.007221564026530791, 'min_frequency': 0.040394142935799425}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:13,851] Trial 98 finished with value: 2025.3935162079247 and parameters: {'learning_rate': 0.06228510419057586, 'n_estimators': 825, 'max_depth': 9, 'max_leaves': 77, 'min_child_weight': 3, 'reg_alpha': 0.6739510256416539, 'reg_lambda': 0.48205268840431714, 'min_frequency': 0.017265084344299485}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:14,428] Trial 99 finished with value: 2856.0290569916897 and parameters: {'learning_rate': 0.06215491018390985, 'n_estimators': 829, 'max_depth': 9, 'max_leaves': 7, 'min_child_weight': 3, 'reg_alpha': 0.6732864269651005, 'reg_lambda': 0.4775736557191253, 'min_frequency': 0.020694369360434183}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:16,253] Trial 100 finished with value: 6434.780128525056 and parameters: {'learning_rate': 0.05869081089874839, 'n_estimators': 904, 'max_depth': 9, 'max_leaves': 78, 'min_child_weight': 4, 'reg_alpha': 0.6013952280061101, 'reg_lambda': 0.4239674866142701, 'min_frequency': 0.10747429983608622}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:18,122] Trial 101 finished with value: 2018.3160027875588 and parameters: {'learning_rate': 0.07160718825164283, 'n_estimators': 979, 'max_depth': 10, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.6417069782080993, 'reg_lambda': 0.3637867061853043, 'min_frequency': 0.04972482579477503}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:20,321] Trial 102 finished with value: 1982.9660043594902 and parameters: {'learning_rate': 0.06629552450539578, 'n_estimators': 974, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.6466758687599294, 'reg_lambda': 0.35384820180824145, 'min_frequency': 0.04466022090730562}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:22,480] Trial 103 finished with value: 1985.3604155859637 and parameters: {'learning_rate': 0.06754682751707426, 'n_estimators': 970, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.6565096360450242, 'reg_lambda': 0.35640380646172737, 'min_frequency': 3.506063717770985e-05}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:24,701] Trial 104 finished with value: 1989.4338747327715 and parameters: {'learning_rate': 0.06270333286277815, 'n_estimators': 998, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.6916418899941336, 'reg_lambda': 0.35514398423620763, 'min_frequency': 0.02556531818061914}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:26,855] Trial 105 finished with value: 1986.6323026046907 and parameters: {'learning_rate': 0.0641132412452484, 'n_estimators': 993, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.6282108385178541, 'reg_lambda': 0.4578299361688255, 'min_frequency': 0.007494926832427293}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:28,828] Trial 106 finished with value: 10279.709237521483 and parameters: {'learning_rate': 0.05877851081449284, 'n_estimators': 995, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.6264069749385289, 'reg_lambda': 0.44578565927957187, 'min_frequency': 0.7929536559547455}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:31,094] Trial 107 finished with value: 1946.5140930216717 and parameters: {'learning_rate': 0.06391160440606931, 'n_estimators': 968, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5096236151219821, 'reg_lambda': 0.4149382442287357, 'min_frequency': 0.003769466053934231}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:33,263] Trial 108 finished with value: 2022.4669485009013 and parameters: {'learning_rate': 0.06413030285039709, 'n_estimators': 972, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5138763815222352, 'reg_lambda': 0.4134586961993429, 'min_frequency': 0.007558332870994961}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:35,313] Trial 109 finished with value: 2008.202214589621 and parameters: {'learning_rate': 0.05334136554539767, 'n_estimators': 963, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.6013404876595635, 'reg_lambda': 0.5437249741537393, 'min_frequency': 0.00010467674987169051}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:37,332] Trial 110 finished with value: 6474.726586570202 and parameters: {'learning_rate': 0.05271041749825219, 'n_estimators': 967, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5687403359445601, 'reg_lambda': 0.5463693070207283, 'min_frequency': 0.08884716266104507}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:39,399] Trial 111 finished with value: 1987.3437249473402 and parameters: {'learning_rate': 0.05422063026770763, 'n_estimators': 947, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.6002381476350309, 'reg_lambda': 0.45460529847419434, 'min_frequency': 0.0032048799835985575}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:41,512] Trial 112 finished with value: 1965.572479800679 and parameters: {'learning_rate': 0.04890586330049225, 'n_estimators': 952, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5915263188349426, 'reg_lambda': 0.5753341736162155, 'min_frequency': 0.0001637384116934676}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:43,558] Trial 113 finished with value: 2041.583911836907 and parameters: {'learning_rate': 0.042332089293308686, 'n_estimators': 914, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5460177773601608, 'reg_lambda': 0.5621718496174704, 'min_frequency': 0.008603161219399635}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:45,706] Trial 114 finished with value: 1992.8482155956572 and parameters: {'learning_rate': 0.05407999537434156, 'n_estimators': 954, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5853154960106168, 'reg_lambda': 0.6295794490092899, 'min_frequency': 0.061985997133459786}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:47,788] Trial 115 finished with value: 1968.2225221445863 and parameters: {'learning_rate': 0.05418021403620389, 'n_estimators': 953, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5792578556921456, 'reg_lambda': 0.6096793760682254, 'min_frequency': 0.001932182159235251}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:50,049] Trial 116 finished with value: 2038.8941995069374 and parameters: {'learning_rate': 0.05368004978474338, 'n_estimators': 950, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5738881296040497, 'reg_lambda': 0.6292423003152039, 'min_frequency': 0.0048936894931227055}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:52,309] Trial 117 finished with value: 1994.8299913412768 and parameters: {'learning_rate': 0.04705421542687779, 'n_estimators': 1000, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5743132160478511, 'reg_lambda': 0.5923365129282995, 'min_frequency': 0.07153173409658432}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:54,723] Trial 118 finished with value: 1986.6427903357646 and parameters: {'learning_rate': 0.04804670733200467, 'n_estimators': 950, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5784529477684622, 'reg_lambda': 0.6032805380372633, 'min_frequency': 0.06854649791183955}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:57,224] Trial 119 finished with value: 1993.5321933226967 and parameters: {'learning_rate': 0.046666373467213376, 'n_estimators': 997, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5871604130424358, 'reg_lambda': 0.5906756738451439, 'min_frequency': 0.05906520398559374}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:59,708] Trial 120 finished with value: 1986.1954870499035 and parameters: {'learning_rate': 0.05652912391998122, 'n_estimators': 955, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5851849543569314, 'reg_lambda': 0.651773165516976, 'min_frequency': 0.05221734961925658}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:01,930] Trial 121 finished with value: 2001.7557013631267 and parameters: {'learning_rate': 0.056017975081674, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.6587168109527357, 'reg_lambda': 0.6818000464814806, 'min_frequency': 0.05520009834917532}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:03,731] Trial 122 finished with value: 6265.582429472669 and parameters: {'learning_rate': 0.03392544894996936, 'n_estimators': 982, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.6243921502795865, 'reg_lambda': 0.6569197959882614, 'min_frequency': 0.1115311558045498}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:05,617] Trial 123 finished with value: 5372.924837599818 and parameters: {'learning_rate': 0.04309155080766932, 'n_estimators': 952, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5926552858492016, 'reg_lambda': 0.7290669857356042, 'min_frequency': 0.0846420991291305}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:07,888] Trial 124 finished with value: 2022.721621395037 and parameters: {'learning_rate': 0.04838488916489854, 'n_estimators': 910, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5344087269274489, 'reg_lambda': 0.6405896352807567, 'min_frequency': 0.04347782475173349}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:09,823] Trial 125 finished with value: 1979.4239004993503 and parameters: {'learning_rate': 0.05723608612270437, 'n_estimators': 975, 'max_depth': 10, 'max_leaves': 99, 'min_child_weight': 3, 'reg_alpha': 0.5225441135951776, 'reg_lambda': 0.5719942134917254, 'min_frequency': 0.06761217153954492}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:11,687] Trial 126 finished with value: 6540.188080877845 and parameters: {'learning_rate': 0.057975697103834184, 'n_estimators': 916, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5269593564615107, 'reg_lambda': 0.6107434642508145, 'min_frequency': 0.13804652986778929}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:13,420] Trial 127 finished with value: 10085.81214729785 and parameters: {'learning_rate': 0.05432240139398303, 'n_estimators': 960, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5565064475828723, 'reg_lambda': 0.514573991389249, 'min_frequency': 0.3412259951757662}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:15,432] Trial 128 finished with value: 6547.392088861293 and parameters: {'learning_rate': 0.055760742333792884, 'n_estimators': 978, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.6356289934145072, 'reg_lambda': 0.6088673795189804, 'min_frequency': 0.08978455704824473}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:17,392] Trial 129 finished with value: 1977.2482021032445 and parameters: {'learning_rate': 0.05912864845801704, 'n_estimators': 942, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.514286958150364, 'reg_lambda': 0.6615757288839166, 'min_frequency': 0.0021036460305425414}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:19,426] Trial 130 finished with value: 1964.3256118743711 and parameters: {'learning_rate': 0.06323361006493651, 'n_estimators': 885, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5167048494597041, 'reg_lambda': 0.7087846799023871, 'min_frequency': 0.003073074395478912}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:21,759] Trial 131 finished with value: 1968.0301478467156 and parameters: {'learning_rate': 0.0634280215015592, 'n_estimators': 940, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5200282395907316, 'reg_lambda': 0.7057312024427385, 'min_frequency': 0.016566932368817573}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:23,715] Trial 132 finished with value: 1922.3255411374496 and parameters: {'learning_rate': 0.06352493662365062, 'n_estimators': 938, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5076832949274352, 'reg_lambda': 0.7313463054648354, 'min_frequency': 5.177230606046718e-05}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:25,913] Trial 133 finished with value: 1958.2454417258762 and parameters: {'learning_rate': 0.060196056492095674, 'n_estimators': 936, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.4913269320162787, 'reg_lambda': 0.7312764951073958, 'min_frequency': 0.0007343364605218242}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:27,649] Trial 134 finished with value: 1975.0215754160379 and parameters: {'learning_rate': 0.059301350713674164, 'n_estimators': 892, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.4989663957089083, 'reg_lambda': 0.7067462080161594, 'min_frequency': 0.043194873267003095}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:29,487] Trial 135 finished with value: 2020.5623069471517 and parameters: {'learning_rate': 0.06070797032777531, 'n_estimators': 884, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.4956899109198786, 'reg_lambda': 0.722577191211561, 'min_frequency': 0.00033126881982106175}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:30,695] Trial 136 finished with value: 2045.4470555428927 and parameters: {'learning_rate': 0.06473964988337662, 'n_estimators': 918, 'max_depth': 10, 'max_leaves': 37, 'min_child_weight': 3, 'reg_alpha': 0.44468470917900416, 'reg_lambda': 0.716903398379573, 'min_frequency': 0.0428200559958003}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:32,448] Trial 137 finished with value: 2011.4167562340187 and parameters: {'learning_rate': 0.058329862471465, 'n_estimators': 897, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.5149190540594223, 'reg_lambda': 0.7672045597058421, 'min_frequency': 0.01834818721409675}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:34,339] Trial 138 finished with value: 1969.1015266403106 and parameters: {'learning_rate': 0.06002566452624512, 'n_estimators': 929, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.49167257444846296, 'reg_lambda': 0.7564095069543224, 'min_frequency': 0.00029823050055827194}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:36,263] Trial 139 finished with value: 2023.3941490741322 and parameters: {'learning_rate': 0.0596258729542936, 'n_estimators': 872, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.4917757892200319, 'reg_lambda': 0.7565405582263269, 'min_frequency': 0.04066643177452554}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:38,244] Trial 140 finished with value: 1987.1030070396337 and parameters: {'learning_rate': 0.05671920407123014, 'n_estimators': 930, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5255972992606317, 'reg_lambda': 0.8345282352196217, 'min_frequency': 0.041310976429826396}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:40,332] Trial 141 finished with value: 1974.7334848937373 and parameters: {'learning_rate': 0.06773328299491826, 'n_estimators': 971, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.4937867836866894, 'reg_lambda': 0.7410286187486144, 'min_frequency': 0.0157730266476482}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:42,305] Trial 142 finished with value: 2000.5719541860537 and parameters: {'learning_rate': 0.06865673470010314, 'n_estimators': 970, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.483576727161653, 'reg_lambda': 0.6967535110108822, 'min_frequency': 0.0011322949706516136}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:44,829] Trial 143 finished with value: 1967.4054712388918 and parameters: {'learning_rate': 0.06752397192825371, 'n_estimators': 939, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5037935967571752, 'reg_lambda': 0.8026905516091446, 'min_frequency': 0.02110969574453146}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:46,872] Trial 144 finished with value: 2018.3384617601441 and parameters: {'learning_rate': 0.06742087790156523, 'n_estimators': 932, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.4656353753295903, 'reg_lambda': 0.8025789157785005, 'min_frequency': 0.02110737063372889}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:48,633] Trial 145 finished with value: 10140.009519355717 and parameters: {'learning_rate': 0.06367130428912464, 'n_estimators': 901, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.44026420065118954, 'reg_lambda': 0.7580720602409516, 'min_frequency': 0.5276571541058537}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:50,591] Trial 146 finished with value: 1968.2688628515887 and parameters: {'learning_rate': 0.06013342398879294, 'n_estimators': 927, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5070286467870426, 'reg_lambda': 0.7409535470520511, 'min_frequency': 0.025057154821070817}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:52,542] Trial 147 finished with value: 2005.7166612959004 and parameters: {'learning_rate': 0.060565960304282816, 'n_estimators': 888, 'max_depth': 10, 'max_leaves': 88, 'min_child_weight': 3, 'reg_alpha': 0.5079985438654606, 'reg_lambda': 0.7189580522365197, 'min_frequency': 0.028316812911693766}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:54,586] Trial 148 finished with value: 1998.819527025434 and parameters: {'learning_rate': 0.06149604928682125, 'n_estimators': 921, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.4568563749819211, 'reg_lambda': 0.7461809950009409, 'min_frequency': 0.03624236095756793}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:56,595] Trial 149 finished with value: 2003.0524807372883 and parameters: {'learning_rate': 0.06587233483854855, 'n_estimators': 938, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.48993498709993305, 'reg_lambda': 0.8192451455491196, 'min_frequency': 0.06678611969899649}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:58,614] Trial 150 finished with value: 2131.165517191692 and parameters: {'learning_rate': 0.06341511300335707, 'n_estimators': 909, 'max_depth': 10, 'max_leaves': 99, 'min_child_weight': 1, 'reg_alpha': 0.5163311022240176, 'reg_lambda': 0.7843191933146657, 'min_frequency': 0.020740724969582156}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:00,714] Trial 151 finished with value: 1982.082972771525 and parameters: {'learning_rate': 0.0681107726904285, 'n_estimators': 971, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5347531587302058, 'reg_lambda': 0.7001164707803241, 'min_frequency': 0.00045899229042244686}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:02,937] Trial 152 finished with value: 1968.7811935087086 and parameters: {'learning_rate': 0.059416498706803295, 'n_estimators': 972, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5480625067315731, 'reg_lambda': 0.6991958061653415, 'min_frequency': 0.01711577781453889}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:03,411] Trial 153 finished with value: 2496.7078476719694 and parameters: {'learning_rate': 0.05951909315015552, 'n_estimators': 139, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5462026616666668, 'reg_lambda': 0.6980184752910218, 'min_frequency': 0.02257538681963114}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:05,054] Trial 154 finished with value: 10236.590493154237 and parameters: {'learning_rate': 0.06970346942859744, 'n_estimators': 940, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.5323277696020753, 'reg_lambda': 0.7099113139347171, 'min_frequency': 0.40414626336822324}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:07,442] Trial 155 finished with value: 1969.4812547157949 and parameters: {'learning_rate': 0.0621705046588055, 'n_estimators': 980, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5022773026118803, 'reg_lambda': 0.6732382049599439, 'min_frequency': 0.03802531753371247}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:09,787] Trial 156 finished with value: 2085.753382600289 and parameters: {'learning_rate': 0.062194689920265035, 'n_estimators': 925, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.4811661847494052, 'reg_lambda': 0.6744186494978895, 'min_frequency': 0.08141605891573228}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:11,848] Trial 157 finished with value: 2014.358542694972 and parameters: {'learning_rate': 0.0599313123271591, 'n_estimators': 864, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5014935534899833, 'reg_lambda': 0.7427522634318517, 'min_frequency': 0.021027416328320062}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:13,874] Trial 158 finished with value: 2035.6855699627451 and parameters: {'learning_rate': 0.05771296202721229, 'n_estimators': 892, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.4609487016768758, 'reg_lambda': 0.6639115849731921, 'min_frequency': 0.05348874814422786}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:16,331] Trial 159 finished with value: 1977.2339870931316 and parameters: {'learning_rate': 0.05083764626851269, 'n_estimators': 985, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5528979197270658, 'reg_lambda': 0.7320267122516991, 'min_frequency': 0.037683264978394145}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:18,481] Trial 160 finished with value: 1992.9452607572518 and parameters: {'learning_rate': 0.05087767901339599, 'n_estimators': 943, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.4265219541134599, 'reg_lambda': 0.8552906921593364, 'min_frequency': 0.03437019479862525}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:20,787] Trial 161 finished with value: 1989.2230579112697 and parameters: {'learning_rate': 0.06258959364546869, 'n_estimators': 984, 'max_depth': 10, 'max_leaves': 99, 'min_child_weight': 3, 'reg_alpha': 0.5146024064555403, 'reg_lambda': 0.7354556424154702, 'min_frequency': 0.01533665573530448}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:22,827] Trial 162 finished with value: 1976.241870657539 and parameters: {'learning_rate': 0.06479747879623382, 'n_estimators': 965, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.552549839356632, 'reg_lambda': 0.7768596056176509, 'min_frequency': 0.04300178403146148}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:25,139] Trial 163 finished with value: 1974.0342399448775 and parameters: {'learning_rate': 0.06498631079655084, 'n_estimators': 957, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5579338270466082, 'reg_lambda': 0.7798147296387296, 'min_frequency': 0.04492595482501924}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:26,873] Trial 164 finished with value: 10206.711657313674 and parameters: {'learning_rate': 0.06513158449415096, 'n_estimators': 958, 'max_depth': 10, 'max_leaves': 88, 'min_child_weight': 3, 'reg_alpha': 0.5482364430328093, 'reg_lambda': 0.7661158037130453, 'min_frequency': 0.9150305890885966}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:28,939] Trial 165 finished with value: 1965.1030407706658 and parameters: {'learning_rate': 0.07205207328203124, 'n_estimators': 1000, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5594315422160812, 'reg_lambda': 0.782945199897471, 'min_frequency': 0.05640659712846184}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:30,970] Trial 166 finished with value: 1990.8931952718917 and parameters: {'learning_rate': 0.0720732257673287, 'n_estimators': 916, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.5584295242848267, 'reg_lambda': 0.8015227199516163, 'min_frequency': 0.05466316312888789}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:33,050] Trial 167 finished with value: 6569.374801216151 and parameters: {'learning_rate': 0.06472895875512141, 'n_estimators': 960, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.4841762089299348, 'reg_lambda': 0.8407692651931793, 'min_frequency': 0.09031853686047811}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:35,105] Trial 168 finished with value: 1984.839111164382 and parameters: {'learning_rate': 0.07094144936131892, 'n_estimators': 998, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.49880296341685953, 'reg_lambda': 0.7868347490212404, 'min_frequency': 0.021281130682252205}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:37,350] Trial 169 finished with value: 2026.8466010909206 and parameters: {'learning_rate': 0.06657631512581716, 'n_estimators': 928, 'max_depth': 9, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.47050340314140265, 'reg_lambda': 0.8644704917690731, 'min_frequency': 0.045003277666603045}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:39,400] Trial 170 finished with value: 1972.4918295580776 and parameters: {'learning_rate': 0.06348868094782892, 'n_estimators': 909, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5622433860091649, 'reg_lambda': 0.8146326888956225, 'min_frequency': 0.07215873655379504}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:41,735] Trial 171 finished with value: 1994.5448848691105 and parameters: {'learning_rate': 0.06305078485232199, 'n_estimators': 900, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5625855108580481, 'reg_lambda': 0.815049105262525, 'min_frequency': 0.06848479771801215}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:43,930] Trial 172 finished with value: 4174.490414164676 and parameters: {'learning_rate': 0.0028920225918008524, 'n_estimators': 962, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5336481300230299, 'reg_lambda': 0.7768891242337608, 'min_frequency': 0.03230261382668462}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:46,285] Trial 173 finished with value: 1966.1418737031565 and parameters: {'learning_rate': 0.062138368966600424, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.5644216513784167, 'reg_lambda': 0.8017275186630838, 'min_frequency': 0.016258083257330205}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:48,088] Trial 174 finished with value: 1978.9829501095112 and parameters: {'learning_rate': 0.06133249427963818, 'n_estimators': 878, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.5101028001153496, 'reg_lambda': 0.7526737423894961, 'min_frequency': 0.012021153873372966}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:50,660] Trial 175 finished with value: 2243.864390280485 and parameters: {'learning_rate': 0.01649865573322437, 'n_estimators': 939, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.940347092407221, 'reg_lambda': 0.8046526085763707, 'min_frequency': 0.0008860160599408837}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:52,585] Trial 176 finished with value: 1966.049067189596 and parameters: {'learning_rate': 0.060541005083227364, 'n_estimators': 911, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.564469964748006, 'reg_lambda': 0.6795070862563699, 'min_frequency': 0.06233611247847916}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:54,434] Trial 177 finished with value: 6609.369159946659 and parameters: {'learning_rate': 0.06829799285759783, 'n_estimators': 918, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5752347237204144, 'reg_lambda': 0.7392035745893629, 'min_frequency': 0.11289587402575924}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:56,581] Trial 178 finished with value: 1993.099026286626 and parameters: {'learning_rate': 0.0625469165976422, 'n_estimators': 982, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5383056227602061, 'reg_lambda': 0.6824963730712101, 'min_frequency': 0.0760336043955529}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:58,564] Trial 179 finished with value: 2000.1897214995704 and parameters: {'learning_rate': 0.0659386577342462, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5667365722649254, 'reg_lambda': 0.8959452495468507, 'min_frequency': 0.019437224773172154}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:00,682] Trial 180 finished with value: 1979.0494999620116 and parameters: {'learning_rate': 0.07347407520153346, 'n_estimators': 911, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.5273402955339169, 'reg_lambda': 0.7610421057157286, 'min_frequency': 0.06001070749689523}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:02,586] Trial 181 finished with value: 1980.5968039683412 and parameters: {'learning_rate': 0.06039877129976985, 'n_estimators': 884, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.49928212686544965, 'reg_lambda': 0.7017811350721052, 'min_frequency': 0.0363994061071912}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:04,456] Trial 182 finished with value: 2021.76575091827 and parameters: {'learning_rate': 0.059800499304474716, 'n_estimators': 853, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.4874110942238305, 'reg_lambda': 0.7163491402456584, 'min_frequency': 0.01826488554998937}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:06,871] Trial 183 finished with value: 1982.650587935163 and parameters: {'learning_rate': 0.06352481082702305, 'n_estimators': 1000, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.4481966293315192, 'reg_lambda': 0.6817799941954786, 'min_frequency': 0.05060828386849106}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:08,757] Trial 184 finished with value: 6470.731002551769 and parameters: {'learning_rate': 0.05695191799521975, 'n_estimators': 929, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5474156007471148, 'reg_lambda': 0.795569988532369, 'min_frequency': 0.09368503116893169}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:11,322] Trial 185 finished with value: 1968.2924799775215 and parameters: {'learning_rate': 0.07000507163885226, 'n_estimators': 900, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5199365712879197, 'reg_lambda': 0.7348102054327859, 'min_frequency': 0.021716331040331157}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:13,381] Trial 186 finished with value: 1965.3243587501572 and parameters: {'learning_rate': 0.06933523610744195, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5702091532222217, 'reg_lambda': 0.7360469853681408, 'min_frequency': 0.001279849707549005}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:15,421] Trial 187 finished with value: 1973.8706139833794 and parameters: {'learning_rate': 0.07050137401424059, 'n_estimators': 946, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5643577556876205, 'reg_lambda': 0.7741563018164123, 'min_frequency': 0.0013965408770832996}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:17,472] Trial 188 finished with value: 2010.6108855280117 and parameters: {'learning_rate': 0.07026345838186836, 'n_estimators': 904, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.609091751616836, 'reg_lambda': 0.7251603186078878, 'min_frequency': 0.006253926015618754}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:19,367] Trial 189 finished with value: 1947.6591895120725 and parameters: {'learning_rate': 0.0729573949818271, 'n_estimators': 931, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.591865367649707, 'reg_lambda': 0.8173064870870721, 'min_frequency': 0.001587516039336677}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:21,494] Trial 190 finished with value: 1984.0787013749161 and parameters: {'learning_rate': 0.061966360598879125, 'n_estimators': 924, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.5834150875242146, 'reg_lambda': 0.8286899294232954, 'min_frequency': 0.022000013534340584}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:23,433] Trial 191 finished with value: 2016.9321388945652 and parameters: {'learning_rate': 0.07482980682967343, 'n_estimators': 944, 'max_depth': 10, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.5718804725245196, 'reg_lambda': 0.7511449126150332, 'min_frequency': 0.0020303534101333313}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:25,403] Trial 192 finished with value: 2013.610650065759 and parameters: {'learning_rate': 0.07195794778221426, 'n_estimators': 933, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.6081774042259356, 'reg_lambda': 0.6303898878975844, 'min_frequency': 0.0022089139693836457}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:27,410] Trial 193 finished with value: 1976.830153446722 and parameters: {'learning_rate': 0.07345588575325943, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5294178749734242, 'reg_lambda': 0.8188910630924502, 'min_frequency': 0.030229197874525982}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:28,502] Trial 194 finished with value: 2170.110628861057 and parameters: {'learning_rate': 0.07068926317059084, 'n_estimators': 910, 'max_depth': 5, 'max_leaves': 88, 'min_child_weight': 3, 'reg_alpha': 0.5176787528192917, 'reg_lambda': 0.8522183378087598, 'min_frequency': 0.00047076999872232295}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:30,033] Trial 195 finished with value: 2067.3945450044016 and parameters: {'learning_rate': 0.06872569981623773, 'n_estimators': 976, 'max_depth': 10, 'max_leaves': 47, 'min_child_weight': 3, 'reg_alpha': 0.5681067255542168, 'reg_lambda': 0.791647875027662, 'min_frequency': 0.02734412475009998}. Best is trial 132 with value: 1922.3255411374496.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de trials: 196\n",
            "MAE del mejor trial: 1922.3255411374496\n",
            "Mejores hiperparámetros: {'learning_rate': 0.06352493662365062, 'n_estimators': 938, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5076832949274352, 'reg_lambda': 0.7313463054648354, 'min_frequency': 5.177230606046718e-05}\n",
            "MAE final del modelo optimizado: 1922.3255411374496\n"
          ]
        }
      ],
      "source": [
        "# Inserte su código acá\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# separación de datos\n",
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2222, random_state=42)\n",
        "\n",
        "X_train, y_train = train_data.drop(columns=['quantity']), train_data['quantity']\n",
        "X_val, y_val = val_data.drop(columns=['quantity']), val_data['quantity']\n",
        "X_test, y_test = test_data.drop(columns=['quantity']), test_data['quantity']\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # hiperparámetros a optimizar\n",
        "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n",
        "    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n",
        "    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
        "    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
        "    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n",
        "    \n",
        "    # pipeline\n",
        "    date_transformer = FunctionTransformer(extract_date_features)\n",
        "    col_transformer = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numerical_features),\n",
        "            ('cat', OneHotEncoder(min_frequency = min_frequency), categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    xgb_pipeline = Pipeline(steps=[\n",
        "        ('date_transformer', date_transformer),\n",
        "        ('col_transformer', col_transformer),\n",
        "        ('regressor', XGBRegressor(\n",
        "            objective = 'reg:squarederror',\n",
        "            learning_rate = learning_rate,\n",
        "            n_estimators = n_estimators,\n",
        "            max_depth = max_depth,\n",
        "            max_leaves = max_leaves,\n",
        "            min_child_weight = min_child_weight,\n",
        "            reg_alpha = reg_alpha,\n",
        "            reg_lambda = reg_lambda,\n",
        "            random_state = 42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    xgb_pipeline.fit(X_train, y_train)\n",
        "    val_predictions_xgb = xgb_pipeline.predict(X_val)\n",
        "    mae_xgb = mean_absolute_error(y_val, val_predictions_xgb)\n",
        "    \n",
        "    return mae_xgb\n",
        "\n",
        "# estudio de optuna\n",
        "study = optuna.create_study(direction = 'minimize', sampler = TPESampler(seed = 42))\n",
        "study.optimize(objective, timeout=300)  # 5 minutos\n",
        "\n",
        "# mejores hiperparámetros\n",
        "best_params = study.best_params\n",
        "best_trial = study.best_trial\n",
        "\n",
        "print(f'Número de trials: {len(study.trials)}')\n",
        "print(f'MAE del mejor trial: {best_trial.value}')\n",
        "print(f'Mejores hiperparámetros: {best_params}')\n",
        "\n",
        "# entrenar el modelo final con los mejores hiperparámetros\n",
        "final_pipeline = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numerical_features),\n",
        "            ('cat', OneHotEncoder(min_frequency = best_params['min_frequency']), categorical_features)\n",
        "        ]\n",
        "    )),\n",
        "    ('regressor', XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        learning_rate = best_params['learning_rate'],\n",
        "        n_estimators = best_params['n_estimators'],\n",
        "        max_depth = best_params['max_depth'],\n",
        "        max_leaves = best_params['max_leaves'],\n",
        "        min_child_weight = best_params['min_child_weight'],\n",
        "        reg_alpha = best_params['reg_alpha'],\n",
        "        reg_lambda = best_params['reg_lambda'],\n",
        "        random_state = 42\n",
        "    ))\n",
        "])\n",
        "\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# guardar modelo final\n",
        "joblib.dump(final_pipeline, 'xgb_pipeline_optimized.pkl')\n",
        "\n",
        "# evaluar en el conjunto de validación\n",
        "val_predictions_final = final_pipeline.predict(X_val)\n",
        "mae_final = mean_absolute_error(y_val, val_predictions_final)\n",
        "print(f'MAE final del modelo optimizado: {mae_final}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
        "deepnote_cell_type": "markdown",
        "id": "ZglyD_QWI5wA"
      },
      "source": [
        "## 4. Optimización de Hiperparámetros con Optuna y Prunners (1.7)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
        "</p>\n",
        "\n",
        "Después de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en sí mismo. Después de leer un par de post de personas de dudosa reputación en la *deepweb*, usted llega a la conclusión que puede cumplir este objetivo mediante la implementación de **Prunning**.\n",
        "\n",
        "Vuelva a optimizar los mismos hiperparámetros que la sección pasada, pero esta vez utilizando **Prunning** en la optimización. En particular, usted debe:\n",
        "\n",
        "- Responder: ¿Qué es prunning? ¿De qué forma debería impactar en el entrenamiento?\n",
        "- Utilizar `optuna.integration.XGBoostPruningCallback` como método de **Prunning**\n",
        "- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n",
        "- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n",
        "- Guardar su modelo en un archivo .pkl\n",
        "\n",
        "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
        "\n",
        "```\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "```\n",
        "\n",
        "De implementar la opción anterior, pueden especificar `show_progress_bar = True` en el método `optimize` para *más sabor*.\n",
        "\n",
        "Hint: Si quieren especificar parámetros del método .fit() del modelo a través del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
        "\n",
        "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "eeaa967cd8f6426d8c54f276c17dce79",
        "deepnote_cell_type": "code",
        "id": "sST6Wtj5I5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su código acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a081778cc704fc6bed05393a5419327",
        "deepnote_cell_type": "markdown",
        "id": "ZMiiVaCUI5wA"
      },
      "source": [
        "## 5. Visualizaciones (0.5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
        "\n",
        "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
        "\n",
        "1. Gráfico de historial de optimización\n",
        "2. Gráfico de coordenadas paralelas\n",
        "3. Gráfico de importancia de hiperparámetros\n",
        "\n",
        "Comente sus resultados:\n",
        "\n",
        "4. ¿Desde qué *trial* se empiezan a observar mejoras notables en sus resultados?\n",
        "5. ¿Qué tendencias puede observar a partir del gráfico de coordenadas paralelas?\n",
        "6. ¿Cuáles son los hiperparámetros con mayor importancia para la optimización de su modelo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
        "deepnote_cell_type": "code",
        "id": "xjxAEENAI5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su código acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
        "deepnote_cell_type": "markdown",
        "id": "EoW32TA9I5wA"
      },
      "source": [
        "## 6. Síntesis de resultados (0.3)\n",
        "\n",
        "Finalmente:\n",
        "\n",
        "1. Genere una tabla resumen del MAE obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning.\n",
        "2. Compare los resultados de la tabla y responda, ¿qué modelo obtiene el mejor rendimiento?\n",
        "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE.\n",
        "4. ¿Existen diferencias con respecto a las métricas obtenidas en el conjunto de validación? ¿Porqué puede ocurrir esto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq5C6cDnJg9h"
      },
      "outputs": [],
      "source": [
        "# Inserte su código acá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
        "deepnote_cell_type": "markdown",
        "id": "E_19tgBEI5wA"
      },
      "source": [
        "# Conclusión\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5025de06759f4903a26916c80323bf25",
        "deepnote_cell_type": "markdown",
        "id": "Kq2cFix1I5wA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "rAp9UxwiI5wA"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
    "deepnote_persisted_session": {
      "createdAt": "2023-11-09T16:18:30.203Z"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
