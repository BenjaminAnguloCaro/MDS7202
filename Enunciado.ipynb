{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5c0d2440b3e4995a794ded565213150",
        "deepnote_cell_type": "markdown",
        "id": "_Mql1uRoI5v5"
      },
      "source": [
        "<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
        "deepnote_cell_type": "markdown",
        "id": "FAPGIlEAI5v8"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
        "- Auxiliares: Catherine Benavides y Consuelo Rojas\n",
        "- Ayudante: Nicol치s Ojeda, Eduardo Moya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
        "deepnote_cell_type": "markdown",
        "id": "8NozgbkZI5v9"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
        "\n",
        "- Nombre de alumno 1: Vanessa Gonz치lez\n",
        "- Nombre de alumno 2: Benjam칤n Angulo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
        "deepnote_cell_type": "markdown",
        "id": "vHU9DI6wI5v9"
      },
      "source": [
        "### Temas a tratar\n",
        "\n",
        "- Predicci칩n de demanda usando `xgboost`\n",
        "- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n",
        "- Uso de pipelines.\n",
        "\n",
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C칩digo que no se pueda ejecutar, no ser치 revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Optimizar modelos usando `optuna`\n",
        "- Recurrir a t칠cnicas de *prunning*\n",
        "- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n",
        "- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f38c8342f5164aa992a97488dd5590bf",
        "deepnote_cell_type": "markdown",
        "id": "3Ceri_rbI5v9"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `http://....`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
        "deepnote_cell_type": "markdown",
        "id": "U_-sNOuOI5v9"
      },
      "source": [
        "# Importamos librerias 칰tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "51afe4d2df42442b9e5402ffece60ead",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4957,
        "execution_start": 1699544354044,
        "id": "ekHbM85NI5v9",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "!pip install -qq xgboost optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hJXpLCSspz"
      },
      "source": [
        "# El emprendimiento de Fiu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44d227389a734ac59189c5e0005bc68a",
        "deepnote_cell_type": "markdown",
        "id": "b0bDalAOI5v-"
      },
      "source": [
        "Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterizaci칩n de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
        "\n",
        "Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n",
        "\n",
        "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 92,
        "execution_start": 1699544359006,
        "id": "QvMPOqHuI5v-",
        "outputId": "659e7a12-d74d-45d6-d3c2-33a6cd338585",
        "source_hash": null
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Vanessa\\AppData\\Local\\Temp\\ipykernel_17180\\3184305967.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['date'] = pd.to_datetime(df['date'])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>pop</th>\n",
              "      <th>shop</th>\n",
              "      <th>brand</th>\n",
              "      <th>container</th>\n",
              "      <th>capacity</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.96</td>\n",
              "      <td>13280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.86</td>\n",
              "      <td>6727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.87</td>\n",
              "      <td>9848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>20050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2012-01-31</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.39</td>\n",
              "      <td>25696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id       date    city       lat      long     pop    shop        brand  \\\n",
              "0   0 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "1   1 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "2   2 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "3   3 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "4   4 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "\n",
              "  container capacity  price  quantity  \n",
              "0     glass    500ml   0.96     13280  \n",
              "1   plastic    1.5lt   2.86      6727  \n",
              "2       can    330ml   0.87      9848  \n",
              "3     glass    500ml   1.00     20050  \n",
              "4       can    330ml   0.39     25696  "
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv('sales.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
        "deepnote_cell_type": "markdown",
        "id": "pk4ru76pI5v_"
      },
      "source": [
        "## 1 Generando un Baseline (0.5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
        "</p>\n",
        "\n",
        "Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n",
        "\n",
        "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n",
        "2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n",
        "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas.\n",
        "4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n",
        "5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio?\n",
        "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`?\n",
        "7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.- Se obtiene un MAE de 13546.49. En este contexto, un MAE menor implica que las predicciones est치n m치s cerca de los valores reales de demanda, o bien, implica una mejor precisi칩n del modelo.\n",
        "\n",
        "6.- Con XGBReressor, el MAE obtenido es de 2391.15. Es decir, en este caso el MAE es mejor y las predicciones est치n bastante m치s cerca de los valores reales de demanda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "cell_id": "1482c992d9494e5582b23dbd3431dbfd",
        "deepnote_cell_type": "code",
        "id": "sfnN7HubI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE del DummyRegressor: 13546.494391911923\n",
            "MAE del XGBRegressor: 2391.1526059023413\n"
          ]
        }
      ],
      "source": [
        "# Inserte su c칩digo ac치\n",
        "\n",
        "# 1. separar datos en conjuntos train, val, test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size = 0.1, random_state = 42)\n",
        "train_data, val_data = train_test_split(train_data, test_size = 0.2222, random_state = 42)\n",
        "\n",
        "X_train, y_train = train_data.drop(columns=['quantity']), train_data['quantity']\n",
        "X_val, y_val = val_data.drop(columns=['quantity']), val_data['quantity']\n",
        "X_test, y_test = test_data.drop(columns=['quantity']), test_data['quantity']\n",
        "\n",
        "# 2. FuctionTransformer para extraer d칤a, mes y a침o\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def extract_date_features(df):\n",
        "    df['day'] = df['date'].dt.day.astype('category')\n",
        "    df['month'] = df['date'].dt.month.astype('category')\n",
        "    df['year'] = df['date'].dt.year.astype('category')\n",
        "    return df\n",
        "\n",
        "date_transformer = FunctionTransformer(extract_date_features)\n",
        "\n",
        "# 3. ColumnTransformer para procesar datos num칠ricos y categ칩ricos\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "categorical_features = ['day', 'month', 'year', 'city', 'shop', 'brand', 'container', 'capacity']  # se considera que date ya fue transformado, capacity lo dejamos ac치 porque solo puede ser '500ml', '1.5lt', '330ml'\n",
        "numerical_features = ['lat', 'long', 'pop', 'price']\n",
        "\n",
        "col_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4. guardar pasos anteriores en un pipeline incluyendo DummyRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "dummy_pipeline = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', col_transformer),\n",
        "    ('regressor', DummyRegressor(strategy='mean'))\n",
        "])\n",
        "\n",
        "# 5. entrenar el pipeline anterior y reportar la m칠trica `mean_absolute_error` sobre los datos de validaci칩n\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "dummy_pipeline.fit(X_train, y_train)\n",
        "\n",
        "val_predictions = dummy_pipeline.predict(X_val)\n",
        "mae_dummy = mean_absolute_error(y_val, val_predictions)\n",
        "print(f'MAE del DummyRegressor: {mae_dummy}')\n",
        "\n",
        "# 6. volver a entrenar pipeline con XGBRegressor y reportar la m칠trica `mean_absolute_error` sobre los datos de validaci칩n\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb_pipeline = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', col_transformer),\n",
        "    ('regressor', XGBRegressor(objective='reg:squarederror'))\n",
        "])\n",
        "\n",
        "xgb_pipeline.fit(X_train, y_train)\n",
        "val_predictions_xgb = xgb_pipeline.predict(X_val)\n",
        "mae_xgb = mean_absolute_error(y_val, val_predictions_xgb)\n",
        "print(f'MAE del XGBRegressor: {mae_xgb}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgb_pipeline.pkl']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. guardar ambos modelos\n",
        "import joblib\n",
        "\n",
        "joblib.dump(dummy_pipeline, 'dummy_pipeline.pkl')\n",
        "joblib.dump(xgb_pipeline, 'xgb_pipeline.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7e17e46063774ec28226fe300d42ffe0",
        "deepnote_cell_type": "markdown",
        "id": "wnyMINdKI5v_"
      },
      "source": [
        "## 2. Forzando relaciones entre par치metros con XGBoost (1.0 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
        "</p>\n",
        "\n",
        "Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo realizando las siguientes tareas:\n",
        "\n",
        "1. Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Para aplicar esta restricci칩n ap칩yese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>. Hint: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento.\n",
        "\n",
        "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n.\n",
        "\n",
        "3. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.- El MAE obtenido en este caso es de 2519.22. Dado que este valor es un poco mayor que el obtenido anteriormente con xgboost sin la relaci칩n mon칩tona, nuestro amigo nos sopl칩 mal, pues nuestro modelo ahora tiene un error m치s grande."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE del XGBRegressor con restricci칩n de monotonicidad: 2519.222899080682\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = train_data.drop(columns=['quantity']), train_data['quantity']\n",
        "X_val, y_val = val_data.drop(columns=['quantity']), val_data['quantity']\n",
        "X_test, y_test = test_data.drop(columns=['quantity']), test_data['quantity']\n",
        "\n",
        "\n",
        "# 1. entrenar nuevo pipeline con las restricciones de monotonicidad y que mantiene formato pandas hasta antes del step de entrenamiento\n",
        "def to_dataframe(X):\n",
        "    return pd.DataFrame(X.toarray(), columns=col_transformer.get_feature_names_out())\n",
        "\n",
        "pandas_transformer = FunctionTransformer(to_dataframe)\n",
        "\n",
        "xgb_pipeline_monotone = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', col_transformer),\n",
        "    ('pandas_transformer', pandas_transformer),\n",
        "    ('regressor', XGBRegressor(objective='reg:squarederror', monotone_constraints={'num__price': -1}))\n",
        "])\n",
        "\n",
        "xgb_pipeline_monotone.fit(X_train, y_train)\n",
        "\n",
        "# 2. reportar MAE sobre conjunto de validaci칩n\n",
        "val_predictions_xgb_monotone = xgb_pipeline_monotone.predict(X_val)\n",
        "mae_xgb_monotone = mean_absolute_error(y_val, val_predictions_xgb_monotone)\n",
        "print(f'MAE del XGBRegressor con restricci칩n de monotonicidad: {mae_xgb_monotone}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e59ef80ed20b4de8921f24da74e87374",
        "deepnote_cell_type": "markdown",
        "id": "5D5-tX4dI5v_"
      },
      "source": [
        "## 3. Optimizaci칩n de Hiperpar치metros con Optuna (2.0 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
        "</p>\n",
        "\n",
        "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
        "\n",
        "A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se le pide:\n",
        "\n",
        "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
        "- Utilice `TPESampler` como m칠todo de muestreo\n",
        "- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n",
        "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
        "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
        "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
        "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
        "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
        "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
        "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
        "- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
        "- Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados?\n",
        "- Fije el tiempo de entrenamiento a 5 minutos\n",
        "- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n",
        "- Guardar su modelo en un archivo .pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci칩n se explica cada hiperpar치metro:\n",
        "\n",
        "1. `learning_rate:` Controla la tasa de aprendizaje del modelo. Un valor m치s bajo puede hacer que el modelo aprenda m치s lentamente, pero podr칤a mejorar la precisi칩n. Los valores entre 0.001 y 0.1 son comunes y razonables. Un learning_rate muy bajo (cerca de 0.001) permite ajustes muy precisos, pero puede requerir m치s iteraciones, mientras que valores cercanos a 0.1 permiten un aprendizaje m치s r치pido. Valores fuera de este rango podr칤an resultar en un aprendizaje demasiado lento o demasiado r치pido, causando overfitting o underfitting, respectivamente.\n",
        "\n",
        "2. `n_estimators:` N칰mero de 치rboles en el modelo. M치s 치rboles pueden aumentar la capacidad del modelo, pero tambi칠n el riesgo de overfitting. El rango de 50 a 1000 es apropiado, pues menos de 50 치rboles pueden no ser suficientes para captar la complejidad del modelo, mientras que m치s de 1000 pueden causar overfitting y aumentar demasiado el tiempo de c칩mputo sin que esto implique mejores resultados.\n",
        "\n",
        "3. `max_depth:` Profundidad m치xima de los 치rboles. Controla la complejidad de cada 치rbol. Un rango de 3 a 10 es razonable, ya que valores por debajo de 3 pueden hacer que los 치rboles sean demasiado simples para captar patrones complejos, mientras valores superiores a 10 pueden hacer que los 치rboles se vuelvan demasiado complejos y produzcan overfitting.\n",
        "\n",
        "4. `max_leaves:` N칰mero m치ximo de hojas por 치rbol. Permite controlar la complejidad de cada 치rbol, pero de una manera un poco m치s directa que max_depth. El rango de 0 a 100 es amplio y flexible, permitir hasta 100 hojas proporciona suficiente capacidad para captar patrones complejos sin sobreajustar en la mayor칤a de los casos.\n",
        "\n",
        "5. `min_child_weight:` Peso m칤nimo que debe tener una hoja. Ayuda a evitar que el modelo cree hojas con muy pocos datos. El rango de 1 a 5 es adecuado, ya que un valor m치s bajo (1) permite mayor flexibilidad para crear hojas peque침as, mientras que un valor m치s alto (hasta 5) fuerza al modelo a tener hojas con mayor n칰mero de ejemplos, lo que puede ayudar a evitar el overfitting.\n",
        "\n",
        "6. `reg_alpha:` Regularizaci칩n L1. Ayuda a hacer que el modelo sea m치s sencillo y puede ayudar a prevenir el overfitting. Un rango de 0 a 1 es com칰n y sensato, ya que valores cercanos a 0 significan poca regularizaci칩n, mientras que valores cercanos a 1 implican una fuerte regularizaci칩n. Esto permite explorar desde ning칰n efecto de regularizaci칩n hasta una regularizaci칩n fuerte.\n",
        "\n",
        "7. `reg_lambda:` Regularizaci칩n L2. Similar a reg_alpha, pero penaliza el tama침o de los coeficientes del modelo. Similar a reg_alpha, un rango de 0 a 1 es apropiado, ya que permite explorar desde ning칰n efecto de regularizaci칩n hasta una regularizaci칩n fuerte.\n",
        "\n",
        "8. `min_frequency:` n el OneHotEncoder, este par치metro ayuda a ignorar categor칤as poco frecuentes para evitar ruido en los datos categ칩ricos. El rango de 0.0 a 1.0 es correcto, ya que cubre desde no ignorar ninguna categor칤a (0.0) hasta ignorar todas las categor칤as (1.0). \n",
        "\n",
        "En cuanto al n칰mero de trials, se tienen 196, y con los mejores hiperpar치metros el MAE es de 1922.33. Considerando que el MAE del mejor modelo anterior es de 2391.15, se tiene que los resultados luego de hiperpar치metros mejoran bastante.\n",
        "\n",
        "Lo anterior se puede deber a una combinaci칩n de ajustes precisos en los distintos hiperpar치metros abordados. La metodolog칤a de b칰squeda bayesiana, sumada a los rangos de valores escogidos que nos permiten la exploraci칩n suficiente del espacio de hiperpar치metros, encuentran una configuraci칩n que optimiza el rendimiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
        "deepnote_cell_type": "code",
        "id": "kMXXi1ckI5v_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-29 21:37:29,731] A new study created in memory with name: no-name-7f555541-1457-4c45-bea1-8ed6fbd0eab1\n",
            "[I 2024-05-29 21:37:31,324] Trial 0 finished with value: 9749.174034768506 and parameters: {'learning_rate': 0.03807947176588889, 'n_estimators': 954, 'max_depth': 8, 'max_leaves': 60, 'min_child_weight': 1, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'min_frequency': 0.8661761457749352}. Best is trial 0 with value: 9749.174034768506.\n",
            "[I 2024-05-29 21:37:31,915] Trial 1 finished with value: 5757.241405136549 and parameters: {'learning_rate': 0.06051038616257767, 'n_estimators': 723, 'max_depth': 3, 'max_leaves': 97, 'min_child_weight': 5, 'reg_alpha': 0.21233911067827616, 'reg_lambda': 0.18182496720710062, 'min_frequency': 0.18340450985343382}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:32,689] Trial 2 finished with value: 8966.786244812625 and parameters: {'learning_rate': 0.03111998205299424, 'n_estimators': 549, 'max_depth': 6, 'max_leaves': 29, 'min_child_weight': 4, 'reg_alpha': 0.13949386065204183, 'reg_lambda': 0.29214464853521815, 'min_frequency': 0.3663618432936917}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:33,427] Trial 3 finished with value: 5813.638579851505 and parameters: {'learning_rate': 0.04615092843748656, 'n_estimators': 796, 'max_depth': 4, 'max_leaves': 51, 'min_child_weight': 3, 'reg_alpha': 0.046450412719997725, 'reg_lambda': 0.6075448519014384, 'min_frequency': 0.17052412368729153}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:34,985] Trial 4 finished with value: 9034.394314454436 and parameters: {'learning_rate': 0.0074401077055426725, 'n_estimators': 952, 'max_depth': 10, 'max_leaves': 81, 'min_child_weight': 2, 'reg_alpha': 0.09767211400638387, 'reg_lambda': 0.6842330265121569, 'min_frequency': 0.4401524937396013}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:35,353] Trial 5 finished with value: 8707.184649891537 and parameters: {'learning_rate': 0.013081785249633104, 'n_estimators': 520, 'max_depth': 3, 'max_leaves': 91, 'min_child_weight': 2, 'reg_alpha': 0.662522284353982, 'reg_lambda': 0.31171107608941095, 'min_frequency': 0.5200680211778108}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:35,890] Trial 6 finished with value: 9184.023770553005 and parameters: {'learning_rate': 0.05512431765498469, 'n_estimators': 225, 'max_depth': 10, 'max_leaves': 78, 'min_child_weight': 5, 'reg_alpha': 0.8948273504276488, 'reg_lambda': 0.5978999788110851, 'min_frequency': 0.9218742350231168}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:36,130] Trial 7 finished with value: 9166.99227461121 and parameters: {'learning_rate': 0.00976075770314003, 'n_estimators': 236, 'max_depth': 3, 'max_leaves': 32, 'min_child_weight': 2, 'reg_alpha': 0.2713490317738959, 'reg_lambda': 0.8287375091519293, 'min_frequency': 0.3567533266935893}. Best is trial 1 with value: 5757.241405136549.\n",
            "[I 2024-05-29 21:37:36,615] Trial 8 finished with value: 5698.762707183859 and parameters: {'learning_rate': 0.028812516459050697, 'n_estimators': 566, 'max_depth': 4, 'max_leaves': 81, 'min_child_weight': 1, 'reg_alpha': 0.9868869366005173, 'reg_lambda': 0.7722447692966574, 'min_frequency': 0.1987156815341724}. Best is trial 8 with value: 5698.762707183859.\n",
            "[I 2024-05-29 21:37:38,113] Trial 9 finished with value: 7506.077063946177 and parameters: {'learning_rate': 0.0015466895952366377, 'n_estimators': 825, 'max_depth': 8, 'max_leaves': 73, 'min_child_weight': 4, 'reg_alpha': 0.07404465173409036, 'reg_lambda': 0.3584657285442726, 'min_frequency': 0.11586905952512971}. Best is trial 8 with value: 5698.762707183859.\n",
            "[I 2024-05-29 21:37:38,393] Trial 10 finished with value: 13546.494419642857 and parameters: {'learning_rate': 0.0945685178788083, 'n_estimators': 55, 'max_depth': 5, 'max_leaves': 1, 'min_child_weight': 1, 'reg_alpha': 0.907664795282518, 'reg_lambda': 0.9657999152312998, 'min_frequency': 0.6764178475687505}. Best is trial 8 with value: 5698.762707183859.\n",
            "[I 2024-05-29 21:37:39,187] Trial 11 finished with value: 2304.2935717331334 and parameters: {'learning_rate': 0.07472142904562282, 'n_estimators': 574, 'max_depth': 5, 'max_leaves': 95, 'min_child_weight': 5, 'reg_alpha': 0.4343562717564112, 'reg_lambda': 0.06782026776262084, 'min_frequency': 0.022779612782324016}. Best is trial 11 with value: 2304.2935717331334.\n",
            "[I 2024-05-29 21:37:39,915] Trial 12 finished with value: 2268.563423919166 and parameters: {'learning_rate': 0.07559807824175671, 'n_estimators': 533, 'max_depth': 5, 'max_leaves': 97, 'min_child_weight': 4, 'reg_alpha': 0.4473531654099191, 'reg_lambda': 0.7856239838024551, 'min_frequency': 0.05035180753379226}. Best is trial 12 with value: 2268.563423919166.\n",
            "[I 2024-05-29 21:37:40,703] Trial 13 finished with value: 2217.55814591324 and parameters: {'learning_rate': 0.07742047722562706, 'n_estimators': 387, 'max_depth': 6, 'max_leaves': 100, 'min_child_weight': 4, 'reg_alpha': 0.44784472747300386, 'reg_lambda': 0.4381301674911344, 'min_frequency': 0.004520026322682995}. Best is trial 13 with value: 2217.55814591324.\n",
            "[I 2024-05-29 21:37:41,617] Trial 14 finished with value: 2087.52391038942 and parameters: {'learning_rate': 0.08295842385492615, 'n_estimators': 382, 'max_depth': 7, 'max_leaves': 100, 'min_child_weight': 4, 'reg_alpha': 0.524280384813821, 'reg_lambda': 0.4621147584011281, 'min_frequency': 0.0016622958476193933}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:42,609] Trial 15 finished with value: 2166.233968917673 and parameters: {'learning_rate': 0.099902158307922, 'n_estimators': 360, 'max_depth': 7, 'max_leaves': 63, 'min_child_weight': 3, 'reg_alpha': 0.6144093625372589, 'reg_lambda': 0.48011047785603345, 'min_frequency': 0.0024139568548372237}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:43,394] Trial 16 finished with value: 7048.5132713599305 and parameters: {'learning_rate': 0.09459357199463239, 'n_estimators': 350, 'max_depth': 8, 'max_leaves': 64, 'min_child_weight': 3, 'reg_alpha': 0.6544691128072077, 'reg_lambda': 0.46361027315685355, 'min_frequency': 0.2815897372059905}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:43,949] Trial 17 finished with value: 9283.68126860119 and parameters: {'learning_rate': 0.09919695494893246, 'n_estimators': 376, 'max_depth': 7, 'max_leaves': 31, 'min_child_weight': 3, 'reg_alpha': 0.6635226910976346, 'reg_lambda': 0.5409495149359591, 'min_frequency': 0.5996408444196241}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:44,223] Trial 18 finished with value: 8902.246728089893 and parameters: {'learning_rate': 0.08503354756578933, 'n_estimators': 72, 'max_depth': 7, 'max_leaves': 43, 'min_child_weight': 4, 'reg_alpha': 0.5682926483932309, 'reg_lambda': 0.17163146637436183, 'min_frequency': 0.791175131433183}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:44,467] Trial 19 finished with value: 6653.472352466033 and parameters: {'learning_rate': 0.06463966796978622, 'n_estimators': 239, 'max_depth': 9, 'max_leaves': 4, 'min_child_weight': 3, 'reg_alpha': 0.30945242808634793, 'reg_lambda': 0.4069095432478356, 'min_frequency': 0.3027316230161766}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:45,073] Trial 20 finished with value: 5829.693570971729 and parameters: {'learning_rate': 0.08543365227872257, 'n_estimators': 434, 'max_depth': 9, 'max_leaves': 20, 'min_child_weight': 3, 'reg_alpha': 0.7790645407184047, 'reg_lambda': 0.2523130069952787, 'min_frequency': 0.09937023920664073}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:45,800] Trial 21 finished with value: 2245.687583836351 and parameters: {'learning_rate': 0.0838131655561784, 'n_estimators': 320, 'max_depth': 6, 'max_leaves': 85, 'min_child_weight': 4, 'reg_alpha': 0.5299828818840583, 'reg_lambda': 0.47309386330307196, 'min_frequency': 0.05060382715532571}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:46,622] Trial 22 finished with value: 2109.958327274847 and parameters: {'learning_rate': 0.07270225304055998, 'n_estimators': 449, 'max_depth': 7, 'max_leaves': 69, 'min_child_weight': 4, 'reg_alpha': 0.37088901906588323, 'reg_lambda': 0.42382979514400526, 'min_frequency': 0.0002380543151967087}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:47,305] Trial 23 finished with value: 6880.960851534991 and parameters: {'learning_rate': 0.06345749401645846, 'n_estimators': 445, 'max_depth': 7, 'max_leaves': 66, 'min_child_weight': 5, 'reg_alpha': 0.3383476804320819, 'reg_lambda': 0.5215755161080551, 'min_frequency': 0.2463819135552211}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:47,689] Trial 24 finished with value: 5753.984241058329 and parameters: {'learning_rate': 0.06921508824921373, 'n_estimators': 144, 'max_depth': 7, 'max_leaves': 54, 'min_child_weight': 4, 'reg_alpha': 0.5863503466690212, 'reg_lambda': 0.6405301333656301, 'min_frequency': 0.11598471181112427}. Best is trial 14 with value: 2087.52391038942.\n",
            "[I 2024-05-29 21:37:48,933] Trial 25 finished with value: 2081.1913168463907 and parameters: {'learning_rate': 0.09047951831461229, 'n_estimators': 658, 'max_depth': 8, 'max_leaves': 71, 'min_child_weight': 3, 'reg_alpha': 0.3836728428695413, 'reg_lambda': 0.3819996117906489, 'min_frequency': 0.0009887216450606285}. Best is trial 25 with value: 2081.1913168463907.\n",
            "[I 2024-05-29 21:37:50,151] Trial 26 finished with value: 6553.7847711267605 and parameters: {'learning_rate': 0.08977105251557031, 'n_estimators': 705, 'max_depth': 9, 'max_leaves': 72, 'min_child_weight': 2, 'reg_alpha': 0.3811470757712544, 'reg_lambda': 0.20031693221569855, 'min_frequency': 0.12800469789111604}. Best is trial 25 with value: 2081.1913168463907.\n",
            "[I 2024-05-29 21:37:50,997] Trial 27 finished with value: 7073.327880204403 and parameters: {'learning_rate': 0.07114653764310133, 'n_estimators': 650, 'max_depth': 8, 'max_leaves': 42, 'min_child_weight': 4, 'reg_alpha': 0.22731375258208175, 'reg_lambda': 0.3757058963115211, 'min_frequency': 0.25753460623234187}. Best is trial 25 with value: 2081.1913168463907.\n",
            "[I 2024-05-29 21:37:51,954] Trial 28 finished with value: 2042.3670024705525 and parameters: {'learning_rate': 0.08043082865713093, 'n_estimators': 471, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.38105833488850255, 'reg_lambda': 0.3463081592628539, 'min_frequency': 0.07751617886057621}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:53,122] Trial 29 finished with value: 6239.520148560635 and parameters: {'learning_rate': 0.04948537425244419, 'n_estimators': 620, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.5011429354099811, 'reg_lambda': 0.3286432524207901, 'min_frequency': 0.0931266982717998}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:54,495] Trial 30 finished with value: 6647.133102897987 and parameters: {'learning_rate': 0.07960508430434043, 'n_estimators': 882, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 2, 'reg_alpha': 0.19562692990337233, 'reg_lambda': 0.042745180079641565, 'min_frequency': 0.18040407322174376}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:55,281] Trial 31 finished with value: 2063.34984581971 and parameters: {'learning_rate': 0.09005109191357132, 'n_estimators': 444, 'max_depth': 8, 'max_leaves': 72, 'min_child_weight': 3, 'reg_alpha': 0.3777294647782796, 'reg_lambda': 0.3929442711647019, 'min_frequency': 0.06641644780200913}. Best is trial 28 with value: 2042.3670024705525.\n",
            "[I 2024-05-29 21:37:56,172] Trial 32 finished with value: 2036.3781592550092 and parameters: {'learning_rate': 0.09236604994325416, 'n_estimators': 487, 'max_depth': 8, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.4129883901450435, 'reg_lambda': 0.2733707317865236, 'min_frequency': 0.07310172100167087}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:56,907] Trial 33 finished with value: 7231.864807845282 and parameters: {'learning_rate': 0.09125751002385779, 'n_estimators': 488, 'max_depth': 9, 'max_leaves': 57, 'min_child_weight': 3, 'reg_alpha': 0.28900323808542494, 'reg_lambda': 0.11982927019994927, 'min_frequency': 0.2077401109083835}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:58,170] Trial 34 finished with value: 6530.301446046068 and parameters: {'learning_rate': 0.09003245707053742, 'n_estimators': 670, 'max_depth': 8, 'max_leaves': 76, 'min_child_weight': 2, 'reg_alpha': 0.40694439804792026, 'reg_lambda': 0.24918193472640549, 'min_frequency': 0.14737619001712438}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:59,250] Trial 35 finished with value: 9543.702605607605 and parameters: {'learning_rate': 0.0388049209169903, 'n_estimators': 728, 'max_depth': 10, 'max_leaves': 60, 'min_child_weight': 3, 'reg_alpha': 0.005458575377312869, 'reg_lambda': 0.2646692310007239, 'min_frequency': 0.3844960575953111}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:37:59,891] Trial 36 finished with value: 7134.923806019712 and parameters: {'learning_rate': 0.09412242099201551, 'n_estimators': 302, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.15902710124239258, 'reg_lambda': 0.19872722167220735, 'min_frequency': 0.32256308394755967}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:00,958] Trial 37 finished with value: 7079.195162020299 and parameters: {'learning_rate': 0.05556809463606735, 'n_estimators': 611, 'max_depth': 8, 'max_leaves': 78, 'min_child_weight': 2, 'reg_alpha': 0.2541360123838059, 'reg_lambda': 0.36970088351585706, 'min_frequency': 0.2326502163093811}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:01,871] Trial 38 finished with value: 2174.7841451377535 and parameters: {'learning_rate': 0.08036969527994621, 'n_estimators': 490, 'max_depth': 9, 'max_leaves': 71, 'min_child_weight': 2, 'reg_alpha': 0.3637618068585596, 'reg_lambda': 0.2983455152049972, 'min_frequency': 0.08056721651301402}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:02,782] Trial 39 finished with value: 9799.725359972334 and parameters: {'learning_rate': 0.08801279809336786, 'n_estimators': 737, 'max_depth': 10, 'max_leaves': 47, 'min_child_weight': 3, 'reg_alpha': 0.4521287306387438, 'reg_lambda': 0.5810106362207283, 'min_frequency': 0.44029982330249195}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:04,223] Trial 40 finished with value: 6759.413233797315 and parameters: {'learning_rate': 0.09813084012584607, 'n_estimators': 789, 'max_depth': 9, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.32288296985868986, 'reg_lambda': 0.12677254593379284, 'min_frequency': 0.164396436309788}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:05,183] Trial 41 finished with value: 2125.5748830548396 and parameters: {'learning_rate': 0.08537209248815977, 'n_estimators': 426, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.492988510754365, 'reg_lambda': 0.33233759918174444, 'min_frequency': 0.054316673448236555}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:06,111] Trial 42 finished with value: 2082.201794097921 and parameters: {'learning_rate': 0.08117269065852861, 'n_estimators': 512, 'max_depth': 7, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5393279416115107, 'reg_lambda': 0.4072535296981334, 'min_frequency': 0.06937991567617773}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:06,783] Trial 43 finished with value: 9475.287877656565 and parameters: {'learning_rate': 0.06780297905091535, 'n_estimators': 503, 'max_depth': 6, 'max_leaves': 94, 'min_child_weight': 2, 'reg_alpha': 0.38842473952888223, 'reg_lambda': 0.41422080662122557, 'min_frequency': 0.9927304376988992}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:07,954] Trial 44 finished with value: 2325.4433131995097 and parameters: {'learning_rate': 0.02167295234709339, 'n_estimators': 585, 'max_depth': 8, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.4799628535883345, 'reg_lambda': 0.3716804862512477, 'min_frequency': 0.07344304973974128}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:08,816] Trial 45 finished with value: 6236.412017024019 and parameters: {'learning_rate': 0.0786099617970131, 'n_estimators': 528, 'max_depth': 7, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.5574701216639798, 'reg_lambda': 0.5496900151019826, 'min_frequency': 0.15112571345808007}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:09,545] Trial 46 finished with value: 7153.106282470212 and parameters: {'learning_rate': 0.09326831550198958, 'n_estimators': 553, 'max_depth': 6, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.41882218261444876, 'reg_lambda': 0.28230272214290525, 'min_frequency': 0.21044204340310685}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:10,527] Trial 47 finished with value: 2119.772840165996 and parameters: {'learning_rate': 0.0881538379640335, 'n_estimators': 472, 'max_depth': 8, 'max_leaves': 78, 'min_child_weight': 3, 'reg_alpha': 0.7386239719822634, 'reg_lambda': 0.229204793096295, 'min_frequency': 0.04874314891344802}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:11,270] Trial 48 finished with value: 9377.18690856074 and parameters: {'learning_rate': 0.056143119319426095, 'n_estimators': 412, 'max_depth': 7, 'max_leaves': 68, 'min_child_weight': 2, 'reg_alpha': 0.2562335562084859, 'reg_lambda': 0.33270777474019286, 'min_frequency': 0.7608742277359258}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:11,912] Trial 49 finished with value: 9600.43947473906 and parameters: {'learning_rate': 0.09589952761758018, 'n_estimators': 305, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 3, 'reg_alpha': 0.12788584175674295, 'reg_lambda': 0.6919198144499181, 'min_frequency': 0.5616787381338312}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:13,866] Trial 50 finished with value: 6559.497377330388 and parameters: {'learning_rate': 0.07501455601231649, 'n_estimators': 989, 'max_depth': 8, 'max_leaves': 74, 'min_child_weight': 2, 'reg_alpha': 0.33019539142416515, 'reg_lambda': 0.4970847321573678, 'min_frequency': 0.12009933186108918}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:14,738] Trial 51 finished with value: 2120.742726214055 and parameters: {'learning_rate': 0.07953636476648202, 'n_estimators': 402, 'max_depth': 7, 'max_leaves': 98, 'min_child_weight': 4, 'reg_alpha': 0.5259430717989301, 'reg_lambda': 0.40480385091450066, 'min_frequency': 0.03838667561677165}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:15,337] Trial 52 finished with value: 2242.384755145456 and parameters: {'learning_rate': 0.0826355887373552, 'n_estimators': 340, 'max_depth': 6, 'max_leaves': 94, 'min_child_weight': 5, 'reg_alpha': 0.623888775356082, 'reg_lambda': 0.46396621052730425, 'min_frequency': 0.0077010695879077}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:16,398] Trial 53 finished with value: 6283.1029313904255 and parameters: {'learning_rate': 0.08296266262220331, 'n_estimators': 589, 'max_depth': 7, 'max_leaves': 99, 'min_child_weight': 4, 'reg_alpha': 0.445530492147152, 'reg_lambda': 0.4349208161062156, 'min_frequency': 0.10362799093261617}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:17,066] Trial 54 finished with value: 2125.622426289508 and parameters: {'learning_rate': 0.08712662059878402, 'n_estimators': 269, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.7109256549544944, 'reg_lambda': 0.3003397830695185, 'min_frequency': 0.07325358064105013}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:17,972] Trial 55 finished with value: 6387.3485163913165 and parameters: {'learning_rate': 0.09684874518391791, 'n_estimators': 523, 'max_depth': 7, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5374629542134307, 'reg_lambda': 0.5130691311769847, 'min_frequency': 0.1697920835341144}. Best is trial 32 with value: 2036.3781592550092.\n",
            "[I 2024-05-29 21:38:18,902] Trial 56 finished with value: 2031.3380058999833 and parameters: {'learning_rate': 0.09279435339347142, 'n_estimators': 462, 'max_depth': 8, 'max_leaves': 85, 'min_child_weight': 4, 'reg_alpha': 0.47245164716996413, 'reg_lambda': 0.37856132458784153, 'min_frequency': 0.04055017228450605}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:19,880] Trial 57 finished with value: 2065.795437173824 and parameters: {'learning_rate': 0.09123411084184559, 'n_estimators': 472, 'max_depth': 8, 'max_leaves': 62, 'min_child_weight': 3, 'reg_alpha': 0.472753223372882, 'reg_lambda': 0.9881136084991532, 'min_frequency': 0.04399680690664873}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:20,725] Trial 58 finished with value: 2087.3268297938675 and parameters: {'learning_rate': 0.09132864312410234, 'n_estimators': 460, 'max_depth': 8, 'max_leaves': 65, 'min_child_weight': 4, 'reg_alpha': 0.48359886258678625, 'reg_lambda': 0.9400927133746524, 'min_frequency': 0.023220957866065366}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:21,857] Trial 59 finished with value: 6438.524085921781 and parameters: {'learning_rate': 0.09953570616398587, 'n_estimators': 651, 'max_depth': 9, 'max_leaves': 61, 'min_child_weight': 1, 'reg_alpha': 0.41453105910938415, 'reg_lambda': 0.8837027014251868, 'min_frequency': 0.13351201821409714}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:22,801] Trial 60 finished with value: 2112.7533187405684 and parameters: {'learning_rate': 0.09303067158226795, 'n_estimators': 563, 'max_depth': 10, 'max_leaves': 55, 'min_child_weight': 4, 'reg_alpha': 0.357476628774539, 'reg_lambda': 0.6788463848380946, 'min_frequency': 0.03071085487132868}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:23,780] Trial 61 finished with value: 2056.4919063534853 and parameters: {'learning_rate': 0.0894896443323035, 'n_estimators': 506, 'max_depth': 8, 'max_leaves': 70, 'min_child_weight': 3, 'reg_alpha': 0.4697064045949561, 'reg_lambda': 0.3322567309504248, 'min_frequency': 0.07706163153124948}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:24,718] Trial 62 finished with value: 6310.319110627305 and parameters: {'learning_rate': 0.08809984180902583, 'n_estimators': 466, 'max_depth': 8, 'max_leaves': 69, 'min_child_weight': 3, 'reg_alpha': 0.4628066038283119, 'reg_lambda': 0.3597603018248962, 'min_frequency': 0.10624989252139087}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:25,564] Trial 63 finished with value: 2105.5414343155285 and parameters: {'learning_rate': 0.09614206577455721, 'n_estimators': 405, 'max_depth': 8, 'max_leaves': 79, 'min_child_weight': 3, 'reg_alpha': 0.4126119951156862, 'reg_lambda': 0.2243578762266409, 'min_frequency': 0.04120260687851207}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:26,376] Trial 64 finished with value: 6262.740335568096 and parameters: {'learning_rate': 0.0914279127677374, 'n_estimators': 383, 'max_depth': 9, 'max_leaves': 73, 'min_child_weight': 3, 'reg_alpha': 0.28478867023745247, 'reg_lambda': 0.15277460439609067, 'min_frequency': 0.18960605454476484}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:26,945] Trial 65 finished with value: 2499.4891450755313 and parameters: {'learning_rate': 0.0769868510494625, 'n_estimators': 545, 'max_depth': 4, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.5866446987580349, 'reg_lambda': 0.33144251340102776, 'min_frequency': 0.0006014771058407281}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:27,943] Trial 66 finished with value: 2223.2390562450223 and parameters: {'learning_rate': 0.04045549186463308, 'n_estimators': 490, 'max_depth': 8, 'max_leaves': 67, 'min_child_weight': 3, 'reg_alpha': 0.3875249319777445, 'reg_lambda': 0.9985364655754747, 'min_frequency': 0.07975506497847659}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:28,956] Trial 67 finished with value: 10069.630498813192 and parameters: {'learning_rate': 0.08636505002835773, 'n_estimators': 618, 'max_depth': 9, 'max_leaves': 72, 'min_child_weight': 3, 'reg_alpha': 0.3517384291504589, 'reg_lambda': 0.26911544180604424, 'min_frequency': 0.6452518464743974}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:29,756] Trial 68 finished with value: 6141.98176837719 and parameters: {'learning_rate': 0.09441494039865712, 'n_estimators': 357, 'max_depth': 8, 'max_leaves': 61, 'min_child_weight': 4, 'reg_alpha': 0.5029664598173147, 'reg_lambda': 0.38120593770312755, 'min_frequency': 0.10173989081577614}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:30,181] Trial 69 finished with value: 5755.818461796168 and parameters: {'learning_rate': 0.09988889724342617, 'n_estimators': 440, 'max_depth': 3, 'max_leaves': 52, 'min_child_weight': 5, 'reg_alpha': 0.42789505951032647, 'reg_lambda': 0.788450240837348, 'min_frequency': 0.13826562102483805}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:30,936] Trial 70 finished with value: 7108.812037017024 and parameters: {'learning_rate': 0.08994753942368602, 'n_estimators': 434, 'max_depth': 8, 'max_leaves': 57, 'min_child_weight': 3, 'reg_alpha': 0.29313694737614865, 'reg_lambda': 0.44030912304679415, 'min_frequency': 0.28389844746094306}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:32,006] Trial 71 finished with value: 2088.517171387701 and parameters: {'learning_rate': 0.08207063154719685, 'n_estimators': 508, 'max_depth': 7, 'max_leaves': 64, 'min_child_weight': 3, 'reg_alpha': 0.4676376602548536, 'reg_lambda': 0.40049395732868176, 'min_frequency': 0.06313642440917713}. Best is trial 56 with value: 2031.3380058999833.\n",
            "[I 2024-05-29 21:38:33,270] Trial 72 finished with value: 2007.251881733107 and parameters: {'learning_rate': 0.0850325610067192, 'n_estimators': 530, 'max_depth': 8, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.5405698128762041, 'reg_lambda': 0.30312820042416544, 'min_frequency': 0.07084571662946766}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:34,551] Trial 73 finished with value: 2019.2545754671257 and parameters: {'learning_rate': 0.08514861390206259, 'n_estimators': 685, 'max_depth': 8, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.5056315299092229, 'reg_lambda': 0.31210666777631074, 'min_frequency': 0.03279112164846229}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:36,231] Trial 74 finished with value: 2019.902726744582 and parameters: {'learning_rate': 0.0844170367327648, 'n_estimators': 843, 'max_depth': 8, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.6090322516408901, 'reg_lambda': 0.3123797454345109, 'min_frequency': 0.03731121883067844}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:37,694] Trial 75 finished with value: 7655.664279930069 and parameters: {'learning_rate': 0.08428493658414868, 'n_estimators': 820, 'max_depth': 9, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.6192313956439035, 'reg_lambda': 0.3117509538812796, 'min_frequency': 0.22829658766822672}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:39,390] Trial 76 finished with value: 6658.028704535153 and parameters: {'learning_rate': 0.0859005335598063, 'n_estimators': 895, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.5863847334948917, 'reg_lambda': 0.3358638256741392, 'min_frequency': 0.09414125442259928}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:41,019] Trial 77 finished with value: 6442.831482875115 and parameters: {'learning_rate': 0.07480988884193172, 'n_estimators': 752, 'max_depth': 8, 'max_leaves': 84, 'min_child_weight': 2, 'reg_alpha': 0.65537579948844, 'reg_lambda': 0.23523730875811633, 'min_frequency': 0.1534565562730366}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:42,372] Trial 78 finished with value: 6452.207627929032 and parameters: {'learning_rate': 0.07299704719922265, 'n_estimators': 708, 'max_depth': 9, 'max_leaves': 80, 'min_child_weight': 4, 'reg_alpha': 0.8274676899026039, 'reg_lambda': 0.28016991654118534, 'min_frequency': 0.12505546793623346}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:43,736] Trial 79 finished with value: 6598.280958210199 and parameters: {'learning_rate': 0.07073050822657093, 'n_estimators': 891, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.5636237258722232, 'reg_lambda': 0.18803976247415466, 'min_frequency': 0.1779091488629827}. Best is trial 72 with value: 2007.251881733107.\n",
            "[I 2024-05-29 21:38:45,006] Trial 80 finished with value: 1990.4285711010857 and parameters: {'learning_rate': 0.07798717411126144, 'n_estimators': 778, 'max_depth': 8, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.6297449149174699, 'reg_lambda': 0.35211083877103205, 'min_frequency': 0.028152836171907336}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:46,661] Trial 81 finished with value: 2026.403295587326 and parameters: {'learning_rate': 0.06711232445886121, 'n_estimators': 787, 'max_depth': 8, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.694277992323062, 'reg_lambda': 0.3542111263218868, 'min_frequency': 0.030665228498072794}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:48,294] Trial 82 finished with value: 2022.4141921843561 and parameters: {'learning_rate': 0.06624784192742358, 'n_estimators': 865, 'max_depth': 8, 'max_leaves': 78, 'min_child_weight': 3, 'reg_alpha': 0.6872351138144958, 'reg_lambda': 0.3456898249320064, 'min_frequency': 0.027465261933340472}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:50,085] Trial 83 finished with value: 2064.75456318641 and parameters: {'learning_rate': 0.06521024181915175, 'n_estimators': 860, 'max_depth': 8, 'max_leaves': 75, 'min_child_weight': 3, 'reg_alpha': 0.696076148768955, 'reg_lambda': 0.30950430440804033, 'min_frequency': 0.022075165506829343}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:51,768] Trial 84 finished with value: 2048.8742528412663 and parameters: {'learning_rate': 0.05781240986986408, 'n_estimators': 805, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 3, 'reg_alpha': 0.7676434894721719, 'reg_lambda': 0.2556565261876471, 'min_frequency': 0.02319623038874431}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:53,202] Trial 85 finished with value: 2076.448151146462 and parameters: {'learning_rate': 0.06072397178471906, 'n_estimators': 767, 'max_depth': 7, 'max_leaves': 77, 'min_child_weight': 3, 'reg_alpha': 0.6745463028684944, 'reg_lambda': 0.21735332944594093, 'min_frequency': 0.052717610437092055}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:55,420] Trial 86 finished with value: 2016.49510523427 and parameters: {'learning_rate': 0.049847781566672494, 'n_estimators': 929, 'max_depth': 8, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.6017900449544757, 'reg_lambda': 0.36292875263902014, 'min_frequency': 0.023795757084424368}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:56,380] Trial 87 finished with value: 2276.89315073383 and parameters: {'learning_rate': 0.04589776825733551, 'n_estimators': 931, 'max_depth': 7, 'max_leaves': 23, 'min_child_weight': 3, 'reg_alpha': 0.6401606393401804, 'reg_lambda': 0.3636804519828505, 'min_frequency': 0.02756081352874301}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:57,267] Trial 88 finished with value: 2156.5980988469883 and parameters: {'learning_rate': 0.06616318301700963, 'n_estimators': 849, 'max_depth': 5, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.688850252227489, 'reg_lambda': 0.2903946728618221, 'min_frequency': 0.0011586018163942113}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:38:58,898] Trial 89 finished with value: 10066.685615647008 and parameters: {'learning_rate': 0.05159828016159543, 'n_estimators': 935, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.8094079010657278, 'reg_lambda': 0.35156617321972905, 'min_frequency': 0.4448139829440017}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:00,638] Trial 90 finished with value: 6466.851437564187 and parameters: {'learning_rate': 0.06121071553619703, 'n_estimators': 840, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 2, 'reg_alpha': 0.6028174737235105, 'reg_lambda': 0.4387900806666756, 'min_frequency': 0.09555381548829434}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:02,294] Trial 91 finished with value: 2041.2966221810027 and parameters: {'learning_rate': 0.07722809254738305, 'n_estimators': 790, 'max_depth': 8, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.7311116684266322, 'reg_lambda': 0.3120826043218728, 'min_frequency': 0.06219334176018328}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:04,028] Trial 92 finished with value: 2055.9212860168827 and parameters: {'learning_rate': 0.05151130897595823, 'n_estimators': 790, 'max_depth': 8, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.7148222097858561, 'reg_lambda': 0.3105018282294275, 'min_frequency': 0.055415045548170665}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:05,372] Trial 93 finished with value: 2118.458344140363 and parameters: {'learning_rate': 0.04681838496690633, 'n_estimators': 688, 'max_depth': 8, 'max_leaves': 80, 'min_child_weight': 3, 'reg_alpha': 0.7671430923098126, 'reg_lambda': 0.2535822969220564, 'min_frequency': 0.02596711927216669}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:06,974] Trial 94 finished with value: 6570.348897584727 and parameters: {'learning_rate': 0.0772564407818643, 'n_estimators': 871, 'max_depth': 8, 'max_leaves': 85, 'min_child_weight': 3, 'reg_alpha': 0.7267573392624119, 'reg_lambda': 0.27607917016087236, 'min_frequency': 0.12422574150594712}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:08,881] Trial 95 finished with value: 2029.5752863535379 and parameters: {'learning_rate': 0.06920981188555539, 'n_estimators': 761, 'max_depth': 8, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.6482419176662041, 'reg_lambda': 0.3842066185351492, 'min_frequency': 0.056732650242521436}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:10,335] Trial 96 finished with value: 5713.017277493083 and parameters: {'learning_rate': 0.0693442470893889, 'n_estimators': 766, 'max_depth': 7, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.6368571054349889, 'reg_lambda': 0.3896887127148943, 'min_frequency': 0.08479164845170432}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:12,190] Trial 97 finished with value: 2036.5221706213845 and parameters: {'learning_rate': 0.07336700108454694, 'n_estimators': 932, 'max_depth': 8, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.5544711543121293, 'reg_lambda': 0.007221564026530791, 'min_frequency': 0.040394142935799425}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:13,851] Trial 98 finished with value: 2025.3935162079247 and parameters: {'learning_rate': 0.06228510419057586, 'n_estimators': 825, 'max_depth': 9, 'max_leaves': 77, 'min_child_weight': 3, 'reg_alpha': 0.6739510256416539, 'reg_lambda': 0.48205268840431714, 'min_frequency': 0.017265084344299485}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:14,428] Trial 99 finished with value: 2856.0290569916897 and parameters: {'learning_rate': 0.06215491018390985, 'n_estimators': 829, 'max_depth': 9, 'max_leaves': 7, 'min_child_weight': 3, 'reg_alpha': 0.6732864269651005, 'reg_lambda': 0.4775736557191253, 'min_frequency': 0.020694369360434183}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:16,253] Trial 100 finished with value: 6434.780128525056 and parameters: {'learning_rate': 0.05869081089874839, 'n_estimators': 904, 'max_depth': 9, 'max_leaves': 78, 'min_child_weight': 4, 'reg_alpha': 0.6013952280061101, 'reg_lambda': 0.4239674866142701, 'min_frequency': 0.10747429983608622}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:18,122] Trial 101 finished with value: 2018.3160027875588 and parameters: {'learning_rate': 0.07160718825164283, 'n_estimators': 979, 'max_depth': 10, 'max_leaves': 76, 'min_child_weight': 3, 'reg_alpha': 0.6417069782080993, 'reg_lambda': 0.3637867061853043, 'min_frequency': 0.04972482579477503}. Best is trial 80 with value: 1990.4285711010857.\n",
            "[I 2024-05-29 21:39:20,321] Trial 102 finished with value: 1982.9660043594902 and parameters: {'learning_rate': 0.06629552450539578, 'n_estimators': 974, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.6466758687599294, 'reg_lambda': 0.35384820180824145, 'min_frequency': 0.04466022090730562}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:22,480] Trial 103 finished with value: 1985.3604155859637 and parameters: {'learning_rate': 0.06754682751707426, 'n_estimators': 970, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.6565096360450242, 'reg_lambda': 0.35640380646172737, 'min_frequency': 3.506063717770985e-05}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:24,701] Trial 104 finished with value: 1989.4338747327715 and parameters: {'learning_rate': 0.06270333286277815, 'n_estimators': 998, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.6916418899941336, 'reg_lambda': 0.35514398423620763, 'min_frequency': 0.02556531818061914}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:26,855] Trial 105 finished with value: 1986.6323026046907 and parameters: {'learning_rate': 0.0641132412452484, 'n_estimators': 993, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.6282108385178541, 'reg_lambda': 0.4578299361688255, 'min_frequency': 0.007494926832427293}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:28,828] Trial 106 finished with value: 10279.709237521483 and parameters: {'learning_rate': 0.05877851081449284, 'n_estimators': 995, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.6264069749385289, 'reg_lambda': 0.44578565927957187, 'min_frequency': 0.7929536559547455}. Best is trial 102 with value: 1982.9660043594902.\n",
            "[I 2024-05-29 21:39:31,094] Trial 107 finished with value: 1946.5140930216717 and parameters: {'learning_rate': 0.06391160440606931, 'n_estimators': 968, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5096236151219821, 'reg_lambda': 0.4149382442287357, 'min_frequency': 0.003769466053934231}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:33,263] Trial 108 finished with value: 2022.4669485009013 and parameters: {'learning_rate': 0.06413030285039709, 'n_estimators': 972, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5138763815222352, 'reg_lambda': 0.4134586961993429, 'min_frequency': 0.007558332870994961}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:35,313] Trial 109 finished with value: 2008.202214589621 and parameters: {'learning_rate': 0.05334136554539767, 'n_estimators': 963, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.6013404876595635, 'reg_lambda': 0.5437249741537393, 'min_frequency': 0.00010467674987169051}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:37,332] Trial 110 finished with value: 6474.726586570202 and parameters: {'learning_rate': 0.05271041749825219, 'n_estimators': 967, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5687403359445601, 'reg_lambda': 0.5463693070207283, 'min_frequency': 0.08884716266104507}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:39,399] Trial 111 finished with value: 1987.3437249473402 and parameters: {'learning_rate': 0.05422063026770763, 'n_estimators': 947, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.6002381476350309, 'reg_lambda': 0.45460529847419434, 'min_frequency': 0.0032048799835985575}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:41,512] Trial 112 finished with value: 1965.572479800679 and parameters: {'learning_rate': 0.04890586330049225, 'n_estimators': 952, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5915263188349426, 'reg_lambda': 0.5753341736162155, 'min_frequency': 0.0001637384116934676}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:43,558] Trial 113 finished with value: 2041.583911836907 and parameters: {'learning_rate': 0.042332089293308686, 'n_estimators': 914, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5460177773601608, 'reg_lambda': 0.5621718496174704, 'min_frequency': 0.008603161219399635}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:45,706] Trial 114 finished with value: 1992.8482155956572 and parameters: {'learning_rate': 0.05407999537434156, 'n_estimators': 954, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5853154960106168, 'reg_lambda': 0.6295794490092899, 'min_frequency': 0.061985997133459786}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:47,788] Trial 115 finished with value: 1968.2225221445863 and parameters: {'learning_rate': 0.05418021403620389, 'n_estimators': 953, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5792578556921456, 'reg_lambda': 0.6096793760682254, 'min_frequency': 0.001932182159235251}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:50,049] Trial 116 finished with value: 2038.8941995069374 and parameters: {'learning_rate': 0.05368004978474338, 'n_estimators': 950, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5738881296040497, 'reg_lambda': 0.6292423003152039, 'min_frequency': 0.0048936894931227055}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:52,309] Trial 117 finished with value: 1994.8299913412768 and parameters: {'learning_rate': 0.04705421542687779, 'n_estimators': 1000, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5743132160478511, 'reg_lambda': 0.5923365129282995, 'min_frequency': 0.07153173409658432}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:54,723] Trial 118 finished with value: 1986.6427903357646 and parameters: {'learning_rate': 0.04804670733200467, 'n_estimators': 950, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5784529477684622, 'reg_lambda': 0.6032805380372633, 'min_frequency': 0.06854649791183955}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:57,224] Trial 119 finished with value: 1993.5321933226967 and parameters: {'learning_rate': 0.046666373467213376, 'n_estimators': 997, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5871604130424358, 'reg_lambda': 0.5906756738451439, 'min_frequency': 0.05906520398559374}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:39:59,708] Trial 120 finished with value: 1986.1954870499035 and parameters: {'learning_rate': 0.05652912391998122, 'n_estimators': 955, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5851849543569314, 'reg_lambda': 0.651773165516976, 'min_frequency': 0.05221734961925658}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:01,930] Trial 121 finished with value: 2001.7557013631267 and parameters: {'learning_rate': 0.056017975081674, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.6587168109527357, 'reg_lambda': 0.6818000464814806, 'min_frequency': 0.05520009834917532}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:03,731] Trial 122 finished with value: 6265.582429472669 and parameters: {'learning_rate': 0.03392544894996936, 'n_estimators': 982, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.6243921502795865, 'reg_lambda': 0.6569197959882614, 'min_frequency': 0.1115311558045498}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:05,617] Trial 123 finished with value: 5372.924837599818 and parameters: {'learning_rate': 0.04309155080766932, 'n_estimators': 952, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.5926552858492016, 'reg_lambda': 0.7290669857356042, 'min_frequency': 0.0846420991291305}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:07,888] Trial 124 finished with value: 2022.721621395037 and parameters: {'learning_rate': 0.04838488916489854, 'n_estimators': 910, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5344087269274489, 'reg_lambda': 0.6405896352807567, 'min_frequency': 0.04347782475173349}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:09,823] Trial 125 finished with value: 1979.4239004993503 and parameters: {'learning_rate': 0.05723608612270437, 'n_estimators': 975, 'max_depth': 10, 'max_leaves': 99, 'min_child_weight': 3, 'reg_alpha': 0.5225441135951776, 'reg_lambda': 0.5719942134917254, 'min_frequency': 0.06761217153954492}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:11,687] Trial 126 finished with value: 6540.188080877845 and parameters: {'learning_rate': 0.057975697103834184, 'n_estimators': 916, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5269593564615107, 'reg_lambda': 0.6107434642508145, 'min_frequency': 0.13804652986778929}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:13,420] Trial 127 finished with value: 10085.81214729785 and parameters: {'learning_rate': 0.05432240139398303, 'n_estimators': 960, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5565064475828723, 'reg_lambda': 0.514573991389249, 'min_frequency': 0.3412259951757662}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:15,432] Trial 128 finished with value: 6547.392088861293 and parameters: {'learning_rate': 0.055760742333792884, 'n_estimators': 978, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.6356289934145072, 'reg_lambda': 0.6088673795189804, 'min_frequency': 0.08978455704824473}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:17,392] Trial 129 finished with value: 1977.2482021032445 and parameters: {'learning_rate': 0.05912864845801704, 'n_estimators': 942, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.514286958150364, 'reg_lambda': 0.6615757288839166, 'min_frequency': 0.0021036460305425414}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:19,426] Trial 130 finished with value: 1964.3256118743711 and parameters: {'learning_rate': 0.06323361006493651, 'n_estimators': 885, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5167048494597041, 'reg_lambda': 0.7087846799023871, 'min_frequency': 0.003073074395478912}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:21,759] Trial 131 finished with value: 1968.0301478467156 and parameters: {'learning_rate': 0.0634280215015592, 'n_estimators': 940, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5200282395907316, 'reg_lambda': 0.7057312024427385, 'min_frequency': 0.016566932368817573}. Best is trial 107 with value: 1946.5140930216717.\n",
            "[I 2024-05-29 21:40:23,715] Trial 132 finished with value: 1922.3255411374496 and parameters: {'learning_rate': 0.06352493662365062, 'n_estimators': 938, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5076832949274352, 'reg_lambda': 0.7313463054648354, 'min_frequency': 5.177230606046718e-05}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:25,913] Trial 133 finished with value: 1958.2454417258762 and parameters: {'learning_rate': 0.060196056492095674, 'n_estimators': 936, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.4913269320162787, 'reg_lambda': 0.7312764951073958, 'min_frequency': 0.0007343364605218242}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:27,649] Trial 134 finished with value: 1975.0215754160379 and parameters: {'learning_rate': 0.059301350713674164, 'n_estimators': 892, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.4989663957089083, 'reg_lambda': 0.7067462080161594, 'min_frequency': 0.043194873267003095}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:29,487] Trial 135 finished with value: 2020.5623069471517 and parameters: {'learning_rate': 0.06070797032777531, 'n_estimators': 884, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.4956899109198786, 'reg_lambda': 0.722577191211561, 'min_frequency': 0.00033126881982106175}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:30,695] Trial 136 finished with value: 2045.4470555428927 and parameters: {'learning_rate': 0.06473964988337662, 'n_estimators': 918, 'max_depth': 10, 'max_leaves': 37, 'min_child_weight': 3, 'reg_alpha': 0.44468470917900416, 'reg_lambda': 0.716903398379573, 'min_frequency': 0.0428200559958003}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:32,448] Trial 137 finished with value: 2011.4167562340187 and parameters: {'learning_rate': 0.058329862471465, 'n_estimators': 897, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.5149190540594223, 'reg_lambda': 0.7672045597058421, 'min_frequency': 0.01834818721409675}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:34,339] Trial 138 finished with value: 1969.1015266403106 and parameters: {'learning_rate': 0.06002566452624512, 'n_estimators': 929, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.49167257444846296, 'reg_lambda': 0.7564095069543224, 'min_frequency': 0.00029823050055827194}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:36,263] Trial 139 finished with value: 2023.3941490741322 and parameters: {'learning_rate': 0.0596258729542936, 'n_estimators': 872, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.4917757892200319, 'reg_lambda': 0.7565405582263269, 'min_frequency': 0.04066643177452554}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:38,244] Trial 140 finished with value: 1987.1030070396337 and parameters: {'learning_rate': 0.05671920407123014, 'n_estimators': 930, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5255972992606317, 'reg_lambda': 0.8345282352196217, 'min_frequency': 0.041310976429826396}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:40,332] Trial 141 finished with value: 1974.7334848937373 and parameters: {'learning_rate': 0.06773328299491826, 'n_estimators': 971, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.4937867836866894, 'reg_lambda': 0.7410286187486144, 'min_frequency': 0.0157730266476482}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:42,305] Trial 142 finished with value: 2000.5719541860537 and parameters: {'learning_rate': 0.06865673470010314, 'n_estimators': 970, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.483576727161653, 'reg_lambda': 0.6967535110108822, 'min_frequency': 0.0011322949706516136}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:44,829] Trial 143 finished with value: 1967.4054712388918 and parameters: {'learning_rate': 0.06752397192825371, 'n_estimators': 939, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5037935967571752, 'reg_lambda': 0.8026905516091446, 'min_frequency': 0.02110969574453146}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:46,872] Trial 144 finished with value: 2018.3384617601441 and parameters: {'learning_rate': 0.06742087790156523, 'n_estimators': 932, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.4656353753295903, 'reg_lambda': 0.8025789157785005, 'min_frequency': 0.02110737063372889}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:48,633] Trial 145 finished with value: 10140.009519355717 and parameters: {'learning_rate': 0.06367130428912464, 'n_estimators': 901, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.44026420065118954, 'reg_lambda': 0.7580720602409516, 'min_frequency': 0.5276571541058537}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:50,591] Trial 146 finished with value: 1968.2688628515887 and parameters: {'learning_rate': 0.06013342398879294, 'n_estimators': 927, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5070286467870426, 'reg_lambda': 0.7409535470520511, 'min_frequency': 0.025057154821070817}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:52,542] Trial 147 finished with value: 2005.7166612959004 and parameters: {'learning_rate': 0.060565960304282816, 'n_estimators': 888, 'max_depth': 10, 'max_leaves': 88, 'min_child_weight': 3, 'reg_alpha': 0.5079985438654606, 'reg_lambda': 0.7189580522365197, 'min_frequency': 0.028316812911693766}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:54,586] Trial 148 finished with value: 1998.819527025434 and parameters: {'learning_rate': 0.06149604928682125, 'n_estimators': 921, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.4568563749819211, 'reg_lambda': 0.7461809950009409, 'min_frequency': 0.03624236095756793}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:56,595] Trial 149 finished with value: 2003.0524807372883 and parameters: {'learning_rate': 0.06587233483854855, 'n_estimators': 938, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.48993498709993305, 'reg_lambda': 0.8192451455491196, 'min_frequency': 0.06678611969899649}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:40:58,614] Trial 150 finished with value: 2131.165517191692 and parameters: {'learning_rate': 0.06341511300335707, 'n_estimators': 909, 'max_depth': 10, 'max_leaves': 99, 'min_child_weight': 1, 'reg_alpha': 0.5163311022240176, 'reg_lambda': 0.7843191933146657, 'min_frequency': 0.020740724969582156}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:00,714] Trial 151 finished with value: 1982.082972771525 and parameters: {'learning_rate': 0.0681107726904285, 'n_estimators': 971, 'max_depth': 10, 'max_leaves': 93, 'min_child_weight': 3, 'reg_alpha': 0.5347531587302058, 'reg_lambda': 0.7001164707803241, 'min_frequency': 0.00045899229042244686}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:02,937] Trial 152 finished with value: 1968.7811935087086 and parameters: {'learning_rate': 0.059416498706803295, 'n_estimators': 972, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5480625067315731, 'reg_lambda': 0.6991958061653415, 'min_frequency': 0.01711577781453889}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:03,411] Trial 153 finished with value: 2496.7078476719694 and parameters: {'learning_rate': 0.05951909315015552, 'n_estimators': 139, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5462026616666668, 'reg_lambda': 0.6980184752910218, 'min_frequency': 0.02257538681963114}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:05,054] Trial 154 finished with value: 10236.590493154237 and parameters: {'learning_rate': 0.06970346942859744, 'n_estimators': 940, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.5323277696020753, 'reg_lambda': 0.7099113139347171, 'min_frequency': 0.40414626336822324}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:07,442] Trial 155 finished with value: 1969.4812547157949 and parameters: {'learning_rate': 0.0621705046588055, 'n_estimators': 980, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5022773026118803, 'reg_lambda': 0.6732382049599439, 'min_frequency': 0.03802531753371247}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:09,787] Trial 156 finished with value: 2085.753382600289 and parameters: {'learning_rate': 0.062194689920265035, 'n_estimators': 925, 'max_depth': 10, 'max_leaves': 98, 'min_child_weight': 3, 'reg_alpha': 0.4811661847494052, 'reg_lambda': 0.6744186494978895, 'min_frequency': 0.08141605891573228}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:11,848] Trial 157 finished with value: 2014.358542694972 and parameters: {'learning_rate': 0.0599313123271591, 'n_estimators': 864, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5014935534899833, 'reg_lambda': 0.7427522634318517, 'min_frequency': 0.021027416328320062}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:13,874] Trial 158 finished with value: 2035.6855699627451 and parameters: {'learning_rate': 0.05771296202721229, 'n_estimators': 892, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.4609487016768758, 'reg_lambda': 0.6639115849731921, 'min_frequency': 0.05348874814422786}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:16,331] Trial 159 finished with value: 1977.2339870931316 and parameters: {'learning_rate': 0.05083764626851269, 'n_estimators': 985, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 3, 'reg_alpha': 0.5528979197270658, 'reg_lambda': 0.7320267122516991, 'min_frequency': 0.037683264978394145}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:18,481] Trial 160 finished with value: 1992.9452607572518 and parameters: {'learning_rate': 0.05087767901339599, 'n_estimators': 943, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.4265219541134599, 'reg_lambda': 0.8552906921593364, 'min_frequency': 0.03437019479862525}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:20,787] Trial 161 finished with value: 1989.2230579112697 and parameters: {'learning_rate': 0.06258959364546869, 'n_estimators': 984, 'max_depth': 10, 'max_leaves': 99, 'min_child_weight': 3, 'reg_alpha': 0.5146024064555403, 'reg_lambda': 0.7354556424154702, 'min_frequency': 0.01533665573530448}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:22,827] Trial 162 finished with value: 1976.241870657539 and parameters: {'learning_rate': 0.06479747879623382, 'n_estimators': 965, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.552549839356632, 'reg_lambda': 0.7768596056176509, 'min_frequency': 0.04300178403146148}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:25,139] Trial 163 finished with value: 1974.0342399448775 and parameters: {'learning_rate': 0.06498631079655084, 'n_estimators': 957, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5579338270466082, 'reg_lambda': 0.7798147296387296, 'min_frequency': 0.04492595482501924}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:26,873] Trial 164 finished with value: 10206.711657313674 and parameters: {'learning_rate': 0.06513158449415096, 'n_estimators': 958, 'max_depth': 10, 'max_leaves': 88, 'min_child_weight': 3, 'reg_alpha': 0.5482364430328093, 'reg_lambda': 0.7661158037130453, 'min_frequency': 0.9150305890885966}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:28,939] Trial 165 finished with value: 1965.1030407706658 and parameters: {'learning_rate': 0.07205207328203124, 'n_estimators': 1000, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.5594315422160812, 'reg_lambda': 0.782945199897471, 'min_frequency': 0.05640659712846184}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:30,970] Trial 166 finished with value: 1990.8931952718917 and parameters: {'learning_rate': 0.0720732257673287, 'n_estimators': 916, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.5584295242848267, 'reg_lambda': 0.8015227199516163, 'min_frequency': 0.05466316312888789}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:33,050] Trial 167 finished with value: 6569.374801216151 and parameters: {'learning_rate': 0.06472895875512141, 'n_estimators': 960, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.4841762089299348, 'reg_lambda': 0.8407692651931793, 'min_frequency': 0.09031853686047811}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:35,105] Trial 168 finished with value: 1984.839111164382 and parameters: {'learning_rate': 0.07094144936131892, 'n_estimators': 998, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.49880296341685953, 'reg_lambda': 0.7868347490212404, 'min_frequency': 0.021281130682252205}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:37,350] Trial 169 finished with value: 2026.8466010909206 and parameters: {'learning_rate': 0.06657631512581716, 'n_estimators': 928, 'max_depth': 9, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.47050340314140265, 'reg_lambda': 0.8644704917690731, 'min_frequency': 0.045003277666603045}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:39,400] Trial 170 finished with value: 1972.4918295580776 and parameters: {'learning_rate': 0.06348868094782892, 'n_estimators': 909, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5622433860091649, 'reg_lambda': 0.8146326888956225, 'min_frequency': 0.07215873655379504}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:41,735] Trial 171 finished with value: 1994.5448848691105 and parameters: {'learning_rate': 0.06305078485232199, 'n_estimators': 900, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5625855108580481, 'reg_lambda': 0.815049105262525, 'min_frequency': 0.06848479771801215}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:43,930] Trial 172 finished with value: 4174.490414164676 and parameters: {'learning_rate': 0.0028920225918008524, 'n_estimators': 962, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5336481300230299, 'reg_lambda': 0.7768891242337608, 'min_frequency': 0.03230261382668462}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:46,285] Trial 173 finished with value: 1966.1418737031565 and parameters: {'learning_rate': 0.062138368966600424, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.5644216513784167, 'reg_lambda': 0.8017275186630838, 'min_frequency': 0.016258083257330205}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:48,088] Trial 174 finished with value: 1978.9829501095112 and parameters: {'learning_rate': 0.06133249427963818, 'n_estimators': 878, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.5101028001153496, 'reg_lambda': 0.7526737423894961, 'min_frequency': 0.012021153873372966}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:50,660] Trial 175 finished with value: 2243.864390280485 and parameters: {'learning_rate': 0.01649865573322437, 'n_estimators': 939, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.940347092407221, 'reg_lambda': 0.8046526085763707, 'min_frequency': 0.0008860160599408837}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:52,585] Trial 176 finished with value: 1966.049067189596 and parameters: {'learning_rate': 0.060541005083227364, 'n_estimators': 911, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.564469964748006, 'reg_lambda': 0.6795070862563699, 'min_frequency': 0.06233611247847916}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:54,434] Trial 177 finished with value: 6609.369159946659 and parameters: {'learning_rate': 0.06829799285759783, 'n_estimators': 918, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5752347237204144, 'reg_lambda': 0.7392035745893629, 'min_frequency': 0.11289587402575924}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:56,581] Trial 178 finished with value: 1993.099026286626 and parameters: {'learning_rate': 0.0625469165976422, 'n_estimators': 982, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.5383056227602061, 'reg_lambda': 0.6824963730712101, 'min_frequency': 0.0760336043955529}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:41:58,564] Trial 179 finished with value: 2000.1897214995704 and parameters: {'learning_rate': 0.0659386577342462, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 95, 'min_child_weight': 3, 'reg_alpha': 0.5667365722649254, 'reg_lambda': 0.8959452495468507, 'min_frequency': 0.019437224773172154}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:00,682] Trial 180 finished with value: 1979.0494999620116 and parameters: {'learning_rate': 0.07347407520153346, 'n_estimators': 911, 'max_depth': 10, 'max_leaves': 91, 'min_child_weight': 3, 'reg_alpha': 0.5273402955339169, 'reg_lambda': 0.7610421057157286, 'min_frequency': 0.06001070749689523}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:02,586] Trial 181 finished with value: 1980.5968039683412 and parameters: {'learning_rate': 0.06039877129976985, 'n_estimators': 884, 'max_depth': 10, 'max_leaves': 89, 'min_child_weight': 3, 'reg_alpha': 0.49928212686544965, 'reg_lambda': 0.7017811350721052, 'min_frequency': 0.0363994061071912}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:04,456] Trial 182 finished with value: 2021.76575091827 and parameters: {'learning_rate': 0.059800499304474716, 'n_estimators': 853, 'max_depth': 10, 'max_leaves': 92, 'min_child_weight': 3, 'reg_alpha': 0.4874110942238305, 'reg_lambda': 0.7163491402456584, 'min_frequency': 0.01826488554998937}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:06,871] Trial 183 finished with value: 1982.650587935163 and parameters: {'learning_rate': 0.06352481082702305, 'n_estimators': 1000, 'max_depth': 10, 'max_leaves': 97, 'min_child_weight': 3, 'reg_alpha': 0.4481966293315192, 'reg_lambda': 0.6817799941954786, 'min_frequency': 0.05060828386849106}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:08,757] Trial 184 finished with value: 6470.731002551769 and parameters: {'learning_rate': 0.05695191799521975, 'n_estimators': 929, 'max_depth': 10, 'max_leaves': 94, 'min_child_weight': 3, 'reg_alpha': 0.5474156007471148, 'reg_lambda': 0.795569988532369, 'min_frequency': 0.09368503116893169}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:11,322] Trial 185 finished with value: 1968.2924799775215 and parameters: {'learning_rate': 0.07000507163885226, 'n_estimators': 900, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5199365712879197, 'reg_lambda': 0.7348102054327859, 'min_frequency': 0.021716331040331157}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:13,381] Trial 186 finished with value: 1965.3243587501572 and parameters: {'learning_rate': 0.06933523610744195, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5702091532222217, 'reg_lambda': 0.7360469853681408, 'min_frequency': 0.001279849707549005}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:15,421] Trial 187 finished with value: 1973.8706139833794 and parameters: {'learning_rate': 0.07050137401424059, 'n_estimators': 946, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5643577556876205, 'reg_lambda': 0.7741563018164123, 'min_frequency': 0.0013965408770832996}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:17,472] Trial 188 finished with value: 2010.6108855280117 and parameters: {'learning_rate': 0.07026345838186836, 'n_estimators': 904, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.609091751616836, 'reg_lambda': 0.7251603186078878, 'min_frequency': 0.006253926015618754}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:19,367] Trial 189 finished with value: 1947.6591895120725 and parameters: {'learning_rate': 0.0729573949818271, 'n_estimators': 931, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.591865367649707, 'reg_lambda': 0.8173064870870721, 'min_frequency': 0.001587516039336677}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:21,494] Trial 190 finished with value: 1984.0787013749161 and parameters: {'learning_rate': 0.061966360598879125, 'n_estimators': 924, 'max_depth': 10, 'max_leaves': 90, 'min_child_weight': 3, 'reg_alpha': 0.5834150875242146, 'reg_lambda': 0.8286899294232954, 'min_frequency': 0.022000013534340584}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:23,433] Trial 191 finished with value: 2016.9321388945652 and parameters: {'learning_rate': 0.07482980682967343, 'n_estimators': 944, 'max_depth': 10, 'max_leaves': 84, 'min_child_weight': 3, 'reg_alpha': 0.5718804725245196, 'reg_lambda': 0.7511449126150332, 'min_frequency': 0.0020303534101333313}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:25,403] Trial 192 finished with value: 2013.610650065759 and parameters: {'learning_rate': 0.07195794778221426, 'n_estimators': 933, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.6081774042259356, 'reg_lambda': 0.6303898878975844, 'min_frequency': 0.0022089139693836457}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:27,410] Trial 193 finished with value: 1976.830153446722 and parameters: {'learning_rate': 0.07345588575325943, 'n_estimators': 948, 'max_depth': 10, 'max_leaves': 86, 'min_child_weight': 3, 'reg_alpha': 0.5294178749734242, 'reg_lambda': 0.8188910630924502, 'min_frequency': 0.030229197874525982}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:28,502] Trial 194 finished with value: 2170.110628861057 and parameters: {'learning_rate': 0.07068926317059084, 'n_estimators': 910, 'max_depth': 5, 'max_leaves': 88, 'min_child_weight': 3, 'reg_alpha': 0.5176787528192917, 'reg_lambda': 0.8522183378087598, 'min_frequency': 0.00047076999872232295}. Best is trial 132 with value: 1922.3255411374496.\n",
            "[I 2024-05-29 21:42:30,033] Trial 195 finished with value: 2067.3945450044016 and parameters: {'learning_rate': 0.06872569981623773, 'n_estimators': 976, 'max_depth': 10, 'max_leaves': 47, 'min_child_weight': 3, 'reg_alpha': 0.5681067255542168, 'reg_lambda': 0.791647875027662, 'min_frequency': 0.02734412475009998}. Best is trial 132 with value: 1922.3255411374496.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N칰mero de trials: 196\n",
            "MAE del mejor trial: 1922.3255411374496\n",
            "Mejores hiperpar치metros: {'learning_rate': 0.06352493662365062, 'n_estimators': 938, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.5076832949274352, 'reg_lambda': 0.7313463054648354, 'min_frequency': 5.177230606046718e-05}\n",
            "MAE final del modelo optimizado: 1922.3255411374496\n"
          ]
        }
      ],
      "source": [
        "# Inserte su c칩digo ac치\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# separaci칩n de datos\n",
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2222, random_state=42)\n",
        "\n",
        "X_train, y_train = train_data.drop(columns=['quantity']), train_data['quantity']\n",
        "X_val, y_val = val_data.drop(columns=['quantity']), val_data['quantity']\n",
        "X_test, y_test = test_data.drop(columns=['quantity']), test_data['quantity']\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # hiperpar치metros a optimizar\n",
        "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n",
        "    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n",
        "    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
        "    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
        "    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n",
        "    \n",
        "    # pipeline\n",
        "    date_transformer = FunctionTransformer(extract_date_features)\n",
        "    col_transformer = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numerical_features),\n",
        "            ('cat', OneHotEncoder(min_frequency = min_frequency), categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    xgb_pipeline = Pipeline(steps=[\n",
        "        ('date_transformer', date_transformer),\n",
        "        ('col_transformer', col_transformer),\n",
        "        ('regressor', XGBRegressor(\n",
        "            objective = 'reg:squarederror',\n",
        "            learning_rate = learning_rate,\n",
        "            n_estimators = n_estimators,\n",
        "            max_depth = max_depth,\n",
        "            max_leaves = max_leaves,\n",
        "            min_child_weight = min_child_weight,\n",
        "            reg_alpha = reg_alpha,\n",
        "            reg_lambda = reg_lambda,\n",
        "            random_state = 42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    xgb_pipeline.fit(X_train, y_train)\n",
        "    val_predictions_xgb = xgb_pipeline.predict(X_val)\n",
        "    mae_xgb = mean_absolute_error(y_val, val_predictions_xgb)\n",
        "    \n",
        "    return mae_xgb\n",
        "\n",
        "# estudio de optuna\n",
        "study = optuna.create_study(direction = 'minimize', sampler = TPESampler(seed = 42))\n",
        "study.optimize(objective, timeout=300)  # 5 minutos\n",
        "\n",
        "# mejores hiperpar치metros\n",
        "best_params = study.best_params\n",
        "best_trial = study.best_trial\n",
        "\n",
        "print(f'N칰mero de trials: {len(study.trials)}')\n",
        "print(f'MAE del mejor trial: {best_trial.value}')\n",
        "print(f'Mejores hiperpar치metros: {best_params}')\n",
        "\n",
        "# entrenar el modelo final con los mejores hiperpar치metros\n",
        "final_pipeline = Pipeline(steps=[\n",
        "    ('date_transformer', date_transformer),\n",
        "    ('col_transformer', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numerical_features),\n",
        "            ('cat', OneHotEncoder(min_frequency = best_params['min_frequency']), categorical_features)\n",
        "        ]\n",
        "    )),\n",
        "    ('regressor', XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        learning_rate = best_params['learning_rate'],\n",
        "        n_estimators = best_params['n_estimators'],\n",
        "        max_depth = best_params['max_depth'],\n",
        "        max_leaves = best_params['max_leaves'],\n",
        "        min_child_weight = best_params['min_child_weight'],\n",
        "        reg_alpha = best_params['reg_alpha'],\n",
        "        reg_lambda = best_params['reg_lambda'],\n",
        "        random_state = 42\n",
        "    ))\n",
        "])\n",
        "\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# guardar modelo final\n",
        "joblib.dump(final_pipeline, 'xgb_pipeline_optimized.pkl')\n",
        "\n",
        "# evaluar en el conjunto de validaci칩n\n",
        "val_predictions_final = final_pipeline.predict(X_val)\n",
        "mae_final = mean_absolute_error(y_val, val_predictions_final)\n",
        "print(f'MAE final del modelo optimizado: {mae_final}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
        "deepnote_cell_type": "markdown",
        "id": "ZglyD_QWI5wA"
      },
      "source": [
        "## 4. Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (1.7)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
        "</p>\n",
        "\n",
        "Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n",
        "\n",
        "Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n",
        "\n",
        "- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento?\n",
        "- Utilizar `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning**\n",
        "- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n",
        "- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n",
        "- Guardar su modelo en un archivo .pkl\n",
        "\n",
        "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
        "\n",
        "```\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "```\n",
        "\n",
        "De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n",
        "\n",
        "Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
        "\n",
        "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "eeaa967cd8f6426d8c54f276c17dce79",
        "deepnote_cell_type": "code",
        "id": "sST6Wtj5I5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a081778cc704fc6bed05393a5419327",
        "deepnote_cell_type": "markdown",
        "id": "ZMiiVaCUI5wA"
      },
      "source": [
        "## 5. Visualizaciones (0.5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
        "\n",
        "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
        "\n",
        "1. Gr치fico de historial de optimizaci칩n\n",
        "2. Gr치fico de coordenadas paralelas\n",
        "3. Gr치fico de importancia de hiperpar치metros\n",
        "\n",
        "Comente sus resultados:\n",
        "\n",
        "4. 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados?\n",
        "5. 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas?\n",
        "6. 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
        "deepnote_cell_type": "code",
        "id": "xjxAEENAI5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
        "deepnote_cell_type": "markdown",
        "id": "EoW32TA9I5wA"
      },
      "source": [
        "## 6. S칤ntesis de resultados (0.3)\n",
        "\n",
        "Finalmente:\n",
        "\n",
        "1. Genere una tabla resumen del MAE obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning.\n",
        "2. Compare los resultados de la tabla y responda, 쯤u칠 modelo obtiene el mejor rendimiento?\n",
        "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE.\n",
        "4. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq5C6cDnJg9h"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
        "deepnote_cell_type": "markdown",
        "id": "E_19tgBEI5wA"
      },
      "source": [
        "# Conclusi칩n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5025de06759f4903a26916c80323bf25",
        "deepnote_cell_type": "markdown",
        "id": "Kq2cFix1I5wA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "rAp9UxwiI5wA"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
    "deepnote_persisted_session": {
      "createdAt": "2023-11-09T16:18:30.203Z"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
